# 昇腾理论考试题库修订版

## 判断题

### 1.性能优化的总体原则为:减少Device算子下发时间、减少Host算子执行时间。 答案：F

解题：性能优化的总体原则为减少**Host**算子下发时间、减少**Device**算子执行时间。和上述题目描述明显不符，具体解释如下：

[性能调优总体原则和思路\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2506.html)

![6f3a9f09fd2175cdb9edf5651dcb1ba0.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/be9ce9c7-cebe-4e5a-b760-94081bf125d6.png)

---

### 2.模型迁移所用的Tailor工具，是一个算子自动调优工具。  答案：F

解题：Tailor是一个**离线模型转换**、**性能测试**&**精度测试**、Profiling性能分析的工具，并不涉及算子自动调优。AOE才是昇腾设备上模型运行自动调优工具，AKG才是自动高性能算子生成工具，具体解释如下：

[AIGC工具tailor使用指导\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_0166.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/6bb60823-f50f-467e-a9ac-9fa3b9c85f31.png)

[迁移过程使用工具概览\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_1165.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/fb8b02a0-5d78-4272-b527-ff68fdc30eb1.png)

---

### 3.昇腾HCCL数据并行策略支持DDP模式和DP模式。 答案：F

解题：昇腾HCCL主要 **支持 DDP 模式**的训练，通过 HCCL 通信库实现跨GPU之间的高效通信，从而加速梯度同步过程。昇腾HCCL 提供了针对昇腾AI处理器优化的通信原语，如AllReduce、Broadcast等，这些原语被广泛用于DDP模式下的梯度聚合。昇腾HCCL 更多主要是为了支持跨节点和跨设备的通信设计的，对于单机多卡场景，通常使用 PyTorch 自带的 DataParallel 模块。虽然昇腾HCCL **不直接支持 DP 模式**下的通信，但在单机多卡场景下，PyTorch 的 DataParallel 会自动处理好各个GPU之间的数据并行。在昇腾平台上，你可以使用 PyTorch 的 DataParallel 模块实现DP模式的训练。但是，昇腾HCCL 仍然可以在 DP 模式下发挥作用，特别是在多节点多卡场景中，通过昇腾HCCL 实现跨节点的高效通信。**所以说，昇腾HCCL不支持DP模式，但支持单机上使用多个GPU进行模型训练（单机多卡）和多台机器上使用多个GPU进行模型训练（多机多卡）。**

---

### 4.Profiling数据采集可使用Ascend PyTorch Profiler，当采集数据量过大时，算子调用栈默认开启。答案：F

解题：在昇腾云培训教材"Profiling数据采集--Ascend PyTorch Profiler"那页胶片，有如下内容（采集数据量较大，算子调用栈默认关闭）：

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/ca239db7-ef63-4fc8-8a74-9c8d515eb1e8.png)

[（推荐）Ascend PyTorch Profiler数据采集与分析-Profiling数据采集及分析-性能调优-PyTorch 网络模型迁移和训练-模型开发（PyTorch）-CANN商用版7.0.0开发文档-昇腾社区 (hiascend.com)](https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000068.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/071d40d5-58ba-4646-8a0b-22d28823318b.png)

---

### 5.Ptdbg工具提供了模块级dump功能。答案：T

[精度比对工具说明-接口函数说明](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC1alpha001/devguide/moddevg/ptmigr/AImpug_0034.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/75534aec-322f-4edd-8bc5-a58706f36b66.png)

---

### 6.模型的超参大致可以分为学习率，batch-size，并行切分策略，学习率warm-up，模型参数，FA配置等，用户在行NPU精度和GPU精度比对前，需要保证两边的配置一致。答案：T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b398064f-5037-4a55-bce1-4d0bf4b1bc43.png)

---

### 7.MA-Advisor是一款迁移辅助工具，提供了profiling分析并给出专家调优建议，包含调度性能分析、AICPU调优、亲和api替换建议等功能。答案：F

解题：训练性能分析优化现状中，Pytorch analysis danamic shape包含二进制调优、AOE调优；Pytorch profiler包含调度性能分析、亲和api分析、AICPU等算子分析等；此两类是通过肉眼分析timeline。但目前通过ma-advisor工具代替肉眼分析timeline，**并不包含 调度性能分析 这块**

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e96b5ce2-4413-447e-a4f0-cb05fbdad8f7.png)

[自动诊断工具MA-Advisor简介\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2514.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/155e93fa-dfd0-4817-bfde-b1544aeb3c63.png)

---

### 8.分布式训练的本质是解决单设备内存不足或者单个设备计算能力不足问题。 答案：F

解题：在AI场景中，分布式训练不仅仅是为了解决单设备内存不足或单个设备计算能力不足的问题，它的本质还包括加速训练过程、处理大规模数据、增强系统可靠性以及支持新型学习范式（联邦学习）等多方面的目标。

---

### 9.集合通信中AllReduce操作是将多个线程的数据聚合再分发到每一个节点，但每个节点数据不会相同。答案：F

解题：集合通信中的AllReduce操作是将多个节点的数据聚合，然后将聚合后的结果分发到每一个节点，因此每个节点最终的数据是++**相同的**++。

[allreduce-npu\_bridge.hccl.hccl\_ops-HCCL API（Python）-集合通信接口-CANN社区版8.0.RC2.alpha001开发文档-昇腾社区 (hiascend.com)](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclpython_07_0018.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c0855896-fa90-4fa3-95fd-03aba0c21c5f.png)

---

### 10.在fp16混合精度训练场景下，如果Loss scale在连续的50个step没有持续降低，这种情况可以判定为正常溢出。答案：F

解题：Loss scale在连续的50个step没有持续降低的前提下，还需要和GPU比对溢出发生的次数，如果NPU的溢出次数明显比GPU多，还是会判定为**异常溢出**。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/6658970a-a797-4bf2-aedb-04a3ce859fe4.png)

---

### 11.单层感知机只能处理线性数据，为了解决非线性分类问题，我们可以使用多层感知机，在输入层和输出层之间多加一些隐藏层。多层感知机中添加的隐藏层数越多，整个网络的分类能力就越强，可以提取的目标特征层次也越高   答案：F

解题：在多层感知机中，适度增加隐藏层数可以提高网络的表达能力和特征提取能力，但这种提升并非无限的。网络性能的提升取决于多种因素，包括数据量、网络设计、正则化方法等。过多的隐藏层可能带来过拟合、训练困难等问题。在实际应用中，需要根据具体任务和数据特点来权衡网络深度。

---

### 12.神经网络中如果不使用激活函数(activation function)，那么每一层节点的输入都是上层输出的线性函数，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，网络的表达能力就相当有限。因此，引入非线性激活函数主要就是为了添加非线性因素，增强深层神经网络的表达能力。  答案：T

---

### 13.Transformer架构非常适合处理文本数据，在自然语言处理领域得到了广泛应用，但无法应用在计算机视觉领域，卷积神经网络仍然是计算机视觉的必然选择。 答案：F

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0ccc0ea8-510d-490e-aa74-c9780341942a.png)

---

### 14.ModelArts不支持跨站点访问OBS桶，通过OBS下载文件到Notebook中时，请确保读取的OBS桶和Notebook处于同一站点区域。答案：T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/93b12d93-033e-4972-9f63-83d4422f7817.png)

解题：来自华为云ModelArts部分的帖子

问题现象

数据已上传OBS，使用ModelArts为什么无法找到对应的OBS桶？

问题分析

在使用ModelArts各功能时，如创建训练作业、创建数据集等，涉及到需要指定OBS目录时，都需要保证此OBS桶与ModelArts在同一区域。

如果您在OBS目录指定窗口，无法选择您之前创建的OBS桶时，请前往OBS控制台，检查创建的OBS桶是否与ModelArts在同一区域或者是否属于其他账号。

处理办法

1查看OBS桶与ModelArts是否在同一区域

a查看创建的OBS桶所在区域。

b登录OBS管理控制台。进入“对象存储”界面，可在搜索框中输入已经创建的桶名称或者桶名称列表栏，找到您创建的OBS桶。在“区域栏”可查看创建的OBS桶的所在区域

2.查看ModelArts所在区域。登录ModelArts控制台，在控制台左上角可查看ModelArts所在区域。

3.比对您创建的OBS桶所在区域与ModelArts所在区域是否一致。**务必保证OBS桶与ModelArts所在区域一致**。

---

### 15.MindFormers支持ChatGLM、Llama、Baichuan、Qwen等热门的大模型系列，支持文本生成、问答、翻译、文本掩码等文本型的任务，当前还不支持如图像分割类的图像任务。  答案：F

解题：从给的学习材料来看，显示MindFormers支持图像分割类任务，但从MindSpore Transformers docs来看，支持项确实只有图像分类、图像掩码，没有图像分割。**暂时还是以给的学习材料为准---****支持图像分割类任务。**

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/4b2aa0d9-65d4-4acc-a951-6ecc8ed4eb3d.png)

[MindSpore Transformers docs](https://mindformers.readthedocs.io/zh-cn/latest/docs/model_support_list.html)

---

### 16.converter lite是Mindspore Lite提供离线转换模型工具，目前支持的输入模型类型有:Mindspore、TensorFlow Lite、Caffe、TensorFlow、PaddlePaddle、ONNX和PyTorch.   答案：F

解题：不支持**PaddlePaddle**，PaddlePaddle模型必须先自行转化为ONNX

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/1d5d4492-5e3b-41dc-87c4-c51fcfccdecb.png)

---

### 17.使用benchmark工具进行模型性能测试时，不需要设定输入数据，也不需要设置基准数据  答案：F

解题：benchmark工具可做性能测试和精度比对。在**精度比对**方面，需要设定输入数据，需要设置基准数据；但在**性能测试**方面，最简单的测试命令为**./benchmark --modelFile=/path/to/model.ms**，主要面向单次推理最短耗时、单次推理最长耗时和平均推理耗时、吞吐率，--input是可选项，不配置该参数，会自动构造输入数据，所以可以**不需要设定输入数据，也不需要设置基准数据。**

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/90a4b9c1-dd2d-4e60-961e-d9b78f8df919.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/9e23b17d-5ae9-4429-939f-aa4a41b0ead5.png)

**大部分一般情况下，benchmark工具进行模型性能测试时，需要设定输入数据，也需要设置基准数据，但不是所有，有个别简单或者特殊的情况时，可以直接进行测试时，不需要设定输入数据和基准数据。**

**如果题目是可以不需要设定输入数据，也可以不需要设置基准数据，则为T。**

---

### 18.Deepspeed分布式训练加速工具，实现了内存优化算法，最新版本DeepSpeed可以直接在Atlas 800T A2 昇腾设备上使用，无需deepspeed\_npu插件。   答案：T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d1812cea-6b11-43b8-8f2c-5db8885aaed0.png)

---

### 19.Ascend Insight提供适配昇腾平台的框架Profiing可视化呈现，可根据Memory折线图找峰值拐点附近区域的算子明细分析算子内存占用。   答案：T

解题：AscendInsight功能详解--Memory 相关章节介绍

1. 内存占用折线图 ✓ APP Reserved-进程级预留 ✓ Operators Reserved– 算子级预留 ✓ Operators Allocated—算子级占用 2. 算子内存详细信息 ✓ PyTorch ✓ GE

I. 根据折线图找峰值点 II. 框选峰值附近区域，得到算子明细

---

### 20.PyTorch Adapter支持通过pip方式安装下载后的whl包.  答案：T

```plaintext
pip3 install torch_npu-1.11.0.post8-cp38-cp38-linux_aarch64.whl
```

[PyTorch Adapter已在gitee上开源](https://gitee.com/ascend/pytorch/tree/master)

---

### 21.迁移过程的精度问题一般包括:在迁移正确的前提下，发生loss曲线与CPU/GPU差异不符合预期，下游任务评测结果准确度与CPU/GPU差异不符合预期的情况。  答案：T

解题：从下图的定位思路推断，该判断应该是正确的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/36b7997d-71b6-4340-ad45-c12478a602f4.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/68bea16a-b91c-4a70-b0ec-62faa2b7aa1b.png)

---

### 22.性能问题通常出现在算子下发和执行的异步过程中，因此性能优化的总体原则为:减少Host算子下发时间和减少Device算子执行时间。  答案：T

解题：和前面判断题类似，性能优化的总体原则为减少Host算子下发时间、减少Device算子执行时间。

---

### 23.在确定性计算中，任何微小的差异都是不符合预期的，都应该被视作问题  答案：F（存疑）

解题：从教程中的如下描述：“确定性计算是NPU的一套机制，用于保证算子的计算确定性，当分析长稳训练过程中Loss情况时，需要保证所有的算子计算结果前后完全一致可复现，如果NPU本身计算结果不确定，就难以支撑和GPU结果的多次对比”，可以推断该说法正确。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/e4e7c2cc-dc99-4e90-b9e4-45ee6fdff0a1.png)

---

### 24.使用api\_precision\_compare比对的结果中，某API最大绝对误差<0.001,余弦相似度=0.95，该API精度不达标 答案：T 

解题：从下图可知，先看预先相似度，相似度>0.99的才能进行下一步，看最大绝对误差。此判断题中预先相似度0.95，不达标。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/1e1a92db-79e8-41d5-a40e-e74f9ce7b0e5.png)

---

### 25.在机器学习中，过拟合与欠拟合都是需要避免的现象，其中过拟合指的是在训练集和测试集上的性能都较差，而欠拟合往往能较好地学习训练集数据的性质，但在测试集上的性能较差。  答案：F

解题：上述说法正好相反。过拟合往往能较好地学习训练集数据的性质，但在测试集上的性能较差，欠拟合指的是在训练集和测试集上的性能都较差。

---

### 26.精度校验是通过固定输入，对比模型推理结果和基准数据的相似度来完成的。   答案：T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/ec925889-e014-43c5-8de6-96b3667d07ef.png)

---

### 27.compare一键式全流程精度比对工具适用于TensorFlow、PyTorch和ONNX模型。答案：F

解题：从下图可知，没有PyTorch模型。PyTorch模型主要用于在PyTorch环境中进行模型开发、训练和测试。它们包含了PyTorch特定的操作和结构，与PyTorch生态系统紧密集成。ONNX模型则旨在提供一种标准化的格式，使得在不同的深度学习框架和部署环境之间转换和部署模型变得更加容易。ONNX支持多种深度学习框架，包括PyTorch、TensorFlow、Keras、MXNet等。两者不是同一种格式。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/72e716dd-5287-42e7-a678-bce1a9cd8ade.png)

---

### 28.优化器并行-ZeRO 主要思想是在训练过程中去除冗余数据。ZeRO 有三个不同优化级别，对模型状态进行不同程度的分片。  答案：F

解题：主要思想并不是为了去除冗余数据，而是为了减少在分布式训练过程中的显存开销（解决显存开销），用通讯换显存。ZeRO三个不同的优化级别为：ZeRO-1：仅将优化器状态进行了切分；ZeRO-2：仅梯度和优化器状态进行了切分；ZeRO-3：模型参数、梯度和优化器状态均进行了切分

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/7dd6b5f0-51bd-4064-aa99-1245b64b23a6.png)

---

### 29.部分算子因为数据输入类型问题或者算子实现问题，导致会在昇腾芯片的AI CPU上执行，没有充分利用AI CORE的资源。使用ma-advisor query all可获取亲和API替换调优、AI CPU调优、算子调优建议。  答案：F

解题：请看下图，具体命令为ma-advisor **analyze** all 而不是ma-advisor query all，该描述大部分都是对的，唯独故意写错执行命令，是为陷阱。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/03085cdd-05e1-47c0-bd3b-bfcad6ce36fa.png)

---

### 30.GoogleLeNet是一种经典的卷积神经网络，其中引入了Inception结构，代替单纯的卷积-池化-激活的传统操作，通过使用不同大小的卷积核来抓取不同大小的感受野，拓宽了网络的宽度。  答案：T

解题：华为昇腾教程并没有提到相关内容，但从通义千问给出的判断来看，是正确的。

---

### 31.ModelArts训练作业的运行过程中，如果需要安装第三方依赖包，可以在训练代码目录下放置安装软件，文件内容格式为“包名==版本号”，如“click==6.6”，训练后台会自动下载安装依赖包；目前不支持安装用户自己编译的whl包。答案：F

解题：从下图最低部“依赖包为whl包时”的描述来推断，目前支持安装用户自己编译的whl包。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/0d7b0560-d4c4-4b13-915a-cbf7915a6437.png)

---

### 32.ModelArts的开发环境允许用户在同一个Notebook实例中切换节点的运行规格，如从CPU环境切换到NPU环境，但切换时Notebook实例必须处于“停止”状态。 答案：F

解题：从下图可知，从cpu环境切换到npu环境，不是必须处于“停止”状态才可以，“运行中”和“启动失败”状态也行。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/4250dce4-7015-4e49-b064-8f0179a217df.png)

---

### 33.算子的数值精度是计算过程的基础，通常认为算子精度问题是大模型精度问题的来源之一。  答案：T

解题：教程中原文提到。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/1df1f602-9016-475d-ab0c-6456e57d024b.png)

---

### 34.部分NPU硬件对FP32的限制，导致混合精度问题，造成精度损失，在训练过程中避免开启混合精度方式  答案：F

解题：不是所有情况都需要避免开启混合精度。只有在以下情况下，避免开启混合精度训练是合理的：**对精度要求极高**： 某些任务（如科学计算、医疗影像分析）对精度要求非常高，即使微小的精度损失也是不可接受的。**模型对精度敏感：** 某些复杂或不稳定的模型对数值精度非常敏感，使用混合精度可能导致训练不稳定或收敛问题。**观察到精度损失：** 如果在实验中观察到混合精度训练导致模型性能显著下降，应该考虑关闭混合精度。

---

### 35.算子精度问题分析思路通过比对标杆和NPU训练过程中API的输入输出张量粒度的对比，定位出异常api。 答案：T

解题：如下图，从教程对应内容推断上述说法是正确的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a68be791-f203-4bed-8bbb-f2fccc544a18.png)

---

### 36..NPU和GPU芯片对浮点计算指令npu.exp(x)= gpu\_exp(x).  答案：F

解题：如下图，从教程对应内容推断上述说法是错误的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/374f255c-661e-4017-907d-bc555b5c4abf.png)

---

### 37.神经网络的训练过程，就是通过对训练数据集的学习，调整神经网络中每个神经元的参数，使得损失函数的值取得最高或者相对较高的值。因此，训练的目标就是要让损失函数的值尽可能的大。  答案：F

解题：损失函数（也称为成本函数或误差函数）是用来衡量神经网络预测结果与实际结果之间差距的函数。常见的损失函数包括均方误差（MSE）、交叉熵损失等。**损失函数的值越小**，说明神经网络的预测结果越接近真实结果，模型的表现越好。

---

### 38.模型容易产生过拟合的原因之一是没有太好的抗噪能力，也就是说如果输入数据经过微小的变动，就可能得到完全不一样的的结果。因此，防止模型过拟合的方法之一，就是在训练过程中加入随机噪声帮助训练。  答案：T

解题：过拟合是指模型在训练数据上表现得非常好，但在测试数据或新数据上的表现较差。过拟合的模型过于复杂，捕捉到了训练数据中的噪声和细节，而这些噪声和细节对泛化能力没有帮助。在训练过程中加入随机噪声是一种有效的正则化技术，可以帮助模型提高泛化能力。这种方法通常称为“数据增强”或“噪声注入”。通过在训练数据中加入随机噪声，模型会学习到更加鲁棒的特征，从而对未见过的数据具有更好的泛化能力。

---

### 39.CPU的架构中需要大量的空间去放置缓存单元(cache) 和控制单元(control)，相比之下计算单元(即算术逻单元 Arithmetic Logic Unit,ALU)只占据了很小的一部分，所以CPU在进行大规模并行计算方面受到限制，相对而言更长于复杂逻辑运算。  答案：T

解题：从教程中的下图推断，上述说法是正确的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/e96b1626-cb81-4ae8-a2fb-958ad3e24bd0.png)

---

### 40.AOE(Ascend Optimization Engine) 优化成功的.mindir模型，在使用时不可以删除AOE知识库，否则会影响该模型的性能。 答案：F

解题：AOE优化引擎生成的.mindir模型在使用时并不依赖于AOE知识库的存在。 下图为AOE的原理。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/23c0c27a-261c-46d0-a5bd-eb2a0b5e7c6d.png)

---

### 41.torch\_npu作为一个PyTorch"插件"，在已安装PyTorch的基础上安装后，支持在不改变PyTorch表达层的基础上，动态添加昇腾后端适配，包含增加了NPU设备、hccl等一系列能力的支持。安装后可以直接使用PyTorch的表达层来运行在NPU设备上。答案：T

解题：从如下教程截图可知，上述说法正确。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/de4909b8-45c7-4be4-9c86-4ea4d7dece38.png)

---

### 42.当神经网络非常巨大，甚至网络可能巨大到无法存放到单一计算设备中，这时候，可以采用模型并行策略省去多个设备之间的梯度AllReduce操作，从而优化梯度同步和数据通信开销。 答案：F

解题：模型并行是·把模型切分在不同的XPU上，每个设备只拥有模型的一部分，几个XPU共同维持一个模型。

模型并行确实可以减少某些AllReduce操作的规模，但通常不会完全省去这些操作。在模型并行中，仍然需要在某些层或模型部分之间同步梯度，涉及到AllReduce操作（横向并行）。

---

### 43.假设您对mindspore框架训练的大模型结构比较熟悉，知道哪些"关键算子"容易成为计算瓶颈，为"关键算子"配置合适的切分策略以获得更好的性能，您可以在初始化网络之前调用 mindspore.set\_auto\_parallel\_context(parallel\_mode=ParallelMode.SEMI\_AUTO\_PARALLEL)：设置半自动并行模式。  答案：T

解题：从教程下图红框处可以推断上述说法正确。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/ff549e92-6f81-4f6e-a9a2-57f69a0d2f83.png)

---

### 44.提前终止(early stop)是一种防止欠拟合的方法，即在模型对训练数据集完全收敛之前停止迭代来防止欠拟合。可能的做法是，在每一个Epoch结束时计算验证集的loss或准确率，发现loss上升或者准确率不再提高时，提前停止训练。  答案：F

解题：提前终止是为了防止过拟合，而不是欠拟合。

---

### 45.在使用开发环境或者训练作业时，ModelArts会挂载硬盘至"/cache"目录，用户可以使用此目录来储存文件，此目录无法扩容，不同资源规格有不同的容量，且环境重启后数据将被清空无法恢复。 答案：F

解题：主要是“此目录无法扩容”的描述不够正确：在挂载裸机物理硬盘的前提下，无法扩容；在挂载SFS(网络硬盘)的前提下，支持扩容。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/45f98c78-e30d-4168-a440-03bbec18473a.png)

---

### 46.API精度预检主要分为三步:整网dump、multi\_run\_ut、api\_precision\_compare。  答案：T

解题：从教程下图推断，该描述是正确的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/0802d1e8-3ad9-4857-a397-a4cd4f935703.png)

---

### 47.grad\_tool主要用于监控GPU和NPU训练过程中的梯度差异和监控NPU训练过程中的确定性问题。 答案：T

解题：从教程下图推断，该描述是正确的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/98b300b2-8eeb-414e-83cb-e83e33f2ac4e.png)

---

### 48.torch\_npu.npu.set\_compile\_mode(jit\_compile=False)配置下，会根据当前获得的算子信息，进行融合和优化，在线编译出运行性能更优的算子。答案：F

解题：从教程下图推断，jit\_compile=True表示直接在线编译，而it\_compile=False则表示优先使用已有的二进制算子，若该算子不存在，才进行在线编译，故与该描述有较大差异。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/dcfed9b8-74a7-4b9a-bcb5-0e952339508f.png)

---

### 49.在神经网络中，算子对应网络中层或者节点的计算逻辑，其在数学中的定义是:一个的数空间到的数空间上的映射。卷积操作conv2d最大池化操作maxpooling、大模型中常用的FlashAttention操作等，都是常见的算子:但是激活函数ReLU/softmax等等，并不能成为算子。答案：F

解题：从教程下图红框内容推断，激活函数ReLU就是常见算子。所以，上述“激活函数ReLU/softmax等等，并不能成为算子”的描述是错误的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/c921ee09-a6c3-4bf5-a091-a343c60b11f8.png)

---

### 50.使用compare tools比对性能数据，结果包含了算子在执行耗时、通信耗时、内存占用的优劣，内存使用数据分析前提是Profiling信息采集时打开profile\_memory=True开关。 答案：T

解题：从下图内容推断，该描述是正确的。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/4434f685-68be-4deb-9a4c-792a7141ef4d.png)

---

### 51.模型并行的好处是，省去了多个设备之间的梯度 AllReduce;但由于每个设备都需要完整的教据输入，数据会在多个设备之间进行广播，产生通信代价。  答案：F

解题：模型并行分为横向并行和纵向并行。在横向并行（又叫Tensor并行）的模型下，从教程下图红框可推断，并没有省去多个设备之间的的梯度AllReduce，故该描述错误，严重怀疑此题故意用数据并行的部分特点当作模型并行的来混淆。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b07633c2-5900-4771-8710-31925bb3df68.png)

---

### 52.为了在昇腾上使用PyTorch框架，当前推荐的方式是通过侵入式修改源码实现对昇腾NPU设备的支持，使用的时候需要编译安装patch后的PyTorch源码，如此可获得最好的扩展性。 答案：F

解题：从教程下图可知，pytorch1.11版本以前，推荐的方式是侵入式修改代码、重新编译安装，这之后全面推荐插件化适配。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/19252b5e-339b-4531-a9cf-cae209e0d936.png)

---

### 53.深度学习与传统机器学习算法之间的区别在于，后者无需进行手工特征提取工作，也就是说，我们建议在进行深度学习之前要首先完成特征提取的工作 答案：F

解题：传统机器学习算法通常依赖人工特征提取，这意味着需要专家来选择哪些特征对解决问题最有帮助。深度学习则能够自动从原始数据中学习特征，减少了对人工特征工程的依赖，模型自身通过多层神经网络自动发现数据中的复杂模式，估该描述不正确。

---

### 54.MindSpore支持使用面向对象编程范式，不提供纯函数式编程的支持  答案：F

解题：从教程下图可知，该描述错误。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/7f30fe4e-9840-4606-a0a1-56aa2d1b97b6.png)

---

### 55.使用Ptdbg debugger方式分析精度问题时通常需要多轮dump分析比对，直到精度完全和标杆一致。 答案：T

解题：从教程下图推断可知，通常确实需要多伦，直到不存在精度问题，故该描述正确。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/900d8784-0e94-473e-8710-e4e378a9c0e1.png)

---

### 56.CANN是华为针对A场景推出的异构计算架构，提供了多层次的编程接口，支持底层的算子开发与模型开发，但是不支持上层的AI应用开发。 答案：F

解题：从教程下图推断，该描述错误。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/cb11ee80-431d-4403-a5c6-207eb5fb46f3.png)

---

### 57.在Pytorch模型训练迁移过程中，精度对齐和性能调优是一个互相影响循环往复的过程.  答案：T

解题：在迁移过程中，通常需要先确保模型在新的平台上的精度能够与原有平台对齐，然后再逐步优化性能。这个过程中可能需要多次迭代，通过分析性能瓶颈、调整模型参数、修改算子实现等方式，不断逼近最优的精度和性能平衡点。

---

### 58.GoogLeNet是一种经典的卷积神经网络，其中引入了Inception结构，代替单纯的卷积-池化-激活的传统操作，通过使用不同大小的卷积核来抓取不同大小的图像特征，拓宽了网络的宽度。  答案：T

解题：从教程中没有找到任何依据，但从大模型给出的答案推断，该描述正确。

---

### 59.梯度裁剪是防止梯度消失与爆炸的一种方法，通常的使用方式是设置一个范围，更新梯度的时候，如果梯度超过这个阈值，那就将其强制限制在这个范围之内。答案：T

解题：教程给出的内容无法对该描述做出判断，但从大模型给出的答案推断，该描述正确，但需要明确梯度裁剪主要是用来防止梯度爆炸，限制梯度在一定范围内，也间接上有助于缓解梯度消失。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/1a96a3d0-14a1-4bee-882b-c2811df843c6.png)

---

## 单选题

### 1.对于动态分档场景，converter\_lite最多支持多少档? 答案：D

A．20

B．50

C．80

D．100

解题：从如下链接昇思平台的动态分档的配置参考动态shape配置可知，最多支持100档。

[https://www.mindspore.cn/lite/docs/zh-CN/r2.3.1/use/cloud\_infer/converter\_tool\_ascend.html](https://www.mindspore.cn/lite/docs/zh-CN/r2.3.1/use/cloud_infer/converter_tool_ascend.html)

---

### 2.模型转换工县converter \_lite支持将ONNX模型转换为MindIR模型，转换时需要指定模型的inputShape信息，假设模型有2个输入，节点名称分别为node1/node2，shape分别为(2,1024)/(2,32,256)，则inputShape参数的值应该为如下哪一项  答案：B

A．node1 2,1024/node2 2,32,256

B．node1:2,1024;node2:2,32,256

C．node1 (2,1024);node2 (2,32,256)

D．node1:(2,1024)/node2:(2,32,256)

解题：inputShape参数完整格式应该如下类似：inputShape=node1:-1,64,64,3;node2:6,128,128,3。该题答案中格式最符合的是选项B。参数--inputShape用于指定输入张量（Tensor）的形状，--inputShape=node1:-1,64,64,3;node2:6,128,128,3具体指的是两个输入张量的形状定义。node1:-1,64,64,3 表示模型的第一个输入张量（tensor）node1的形状为 (batch\_size, height, width, channels)。其中 -1 表示动态批大小（batch size），即在推理时这个维度的大小可以变化，而 64, 64 表示输入的高度和宽度分别为 64 像素，3 表示输入的通道数，通常对应于 RGB 图像的红、绿、蓝三个颜色通道。node2:6,128,128,3 则表示模型的第二个输入张量 input2 的形状为 (batch\_size, height, width, channels)。这里的 6 指定了批大小为固定值 6，而 128, 128 表示输入的高度和宽度均为 128 像素，3 同样代表了输入的通道数。

---

### 3.执行convert\_onnx\_to\_mindir.sh进行模型转换时，转换后，除了生成.mindir模型外，还生成了以下哪种模型? 答案：D

A．.pt模型

B．.pb模型

C．.pth模型

D．.om模型

解题：.pt文件一般用于保存 PyTorch 模型的完整状态，包括模型架构和参数。.pth 文件通常用于保存PyTorch 模型的权重参数，而不包含模型架构。.pb文件代表 TensorFlow 的 Protocol Buffer 文件，用于保存TensorFlow 序列化的模型。.onnx文件用于保存和共享模型，它可以包含模型的计算图、参数和其他元数据。通过使用 ONNX 格式，可以在不同的深度学习框架之间无缝转换模型，例如从 PyTorch 到 TensorFlow，从 PyTorch到昇腾。**.om文件为昇腾AI处理器的离线模型。**故该题答案选D。

在实操3 - Stable Difffusion 昇腾模型推理运行.md中，会使用到convert\_onnx\_to\_mindir.sh进行模型转换

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/80179a72-856f-4dda-b404-425a93c73ed2.png)

---

### 4.使用benchmark工具对模型进行精度测试时，二进制输入数据通过哪个参数设置? 答案：B

A．inData

B．inDataFile

C．benchmarkData

D．benchmarkDataFile

解题：从教程下图红方框内容--inDataFile=./bear.bin推断可知（文件后缀为.bin的大概率是二进制文件），该题答案选B

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/3921f986-ea49-41c3-a6e9-d95f7dc2d7af.png)

---

### 5.以下哪项不是常见的集合通信库实现 答案：D

A．OpenMPI & MPICH

B．NCCL

C．Gloo

D．cuDNN

解题：MPI（Message Passing Interface）是一种广泛使用的并行计算标准，它定义了一组函数和语义，用于在多个计算节点之间进行通信和同步。OpenMPI 和 MPICH 是 MPI 标准的实现，用于并行计算的集合通信库；NCCL 和 Gloo 是用于深度学习模型训练的集合通信库；而 cuDNN 则是一个专为深度神经网络设计的 GPU 加速库。故该题答案选D

---

### 6.以下关于数据并行说法错误的是哪项?  答案：B

A．数据并行是指将一个进程或一张卡上无法处理的大量数据拆分为多组数据，在多个进程或多张卡上同时进行计算

B．数据并行时各rank拥有不同的模型参数

C．各卡上独立完成前向传播和反向传播得到梯度

D．通过聚合再下发AllReduce操作将各卡的梯度进行平均并同步，各卡更新模型参数

解题：通过教程下图红框推断，该题答案选B。在分布式训练设置的场景下，“rank” 通常用来表示特定节点或进程在分布式系统中的唯一标识符。例如，在分布式数据并行（Distributed Data Parallel, DDP）中，每个进程会被分配一个 “rank” 用于区分和管理：主节点（Rank 0）：通常指负责协调和管理的节点。其他节点（Rank 1, Rank 2, …）：用于实际计算的工作节点。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b6d78eea-f2c4-4a9c-9f7a-a13fee48c4d0.png)

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/devaids/auxiliarydevtool/atlasprofiling\_16\_0037.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/devaids/auxiliarydevtool/atlasprofiling_16_0037.html)

---

### 7.使用Ascend PyTorch Profiler接口开启PyTorch训练时的性能数据采集，采集CANN软件栈及NPU数据的activities是什么?  答案：B

A．torch\_npu.profiler.ProfilerActivity.CPU

B．torch\_npu.profiler.ProfilerActivity.NPU

C．torch.profiler.ProfilerActivity.CPU

D．torch.profiler.ProfilerActivity.NPU

解题：从下图可推断，该题答案选B

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2e5c5d0c-5146-405e-8a98-453882003cf2.png)

---

### 8.以下不属于PyTorch原生分布式训练框架的是哪一项?  答案：D

A．nn.DataParallel (DP)

B．nn.parallel.DistributedDataParallel (DDP)

C．Fully Sharded Data Parallel (FSDP)

D．Pipeline Parallel

解题：从教程下图可推断，该题答案选D。DataParallel、DistributedDataParallel、Fully Sharded Data Parallel三项都属于数据并行，Pipeline Parallel（流水线并行）属于纵向模型并行的升级版。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/c305a744-8628-4796-850e-38df1481ad0c.png)

---

### 9.定位如千卡大集群场景的偶现性能问题时，为了减少需要分析的数据量，如下操作中应当首先尝试进行的是哪项  答案：A

A．在小集群或单节点上复现性能问题

B．采集性能异常场景大集群全量性能数据进行分析

C．将数据集、日志等文件转移到节点本地，日志等文件保存在本地，排除网络IO性能问题

D．采集性能正常场景的大集群全量性能数据作为对比

解题：题目中已经明确要求为了减少需要分析的数据量，B和D仍然强调全量采集显然不对，C的保存在本地的说法也因为数据量太过庞大很难实现，故用排除法推断该题答案选A。

---

### 10.在开启确定性计算后，NPU多次训练的Loss保持一致，但是在长稳的训练过程中，和GPU的Loss存在差异并且慢慢扩大，甚至出现Loss上扬等严重问题，以下哪项不是正确的排查思路和操作?  答案：D

A．由于已经开启了确定性计算开关，数据存在差异不再是问题，而只有到数据存在较大差异时才被判定为问题。因此高灵敏的md5不再适用，需要记录原始数据进行后续的差异分析

B．此时的监控对象从模型的权重，转变为了每次迭代步的权重梯度

C．使用梯度监控工具监控GPU和NPU训练过程中的梯度方向差异

D．使用ptdbg工具dump从训练开始到loss出现明显异常的数据

解题：从教程下图推断，该题答案选D。开启确定性计算，数据存在差异不再是问题，D项仍在强调数据差异。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/3d16911e-7500-4278-84ba-4ff68780cb17.png)

---

### 11.以下关于精度预检工具的说法错误的是哪项?  答案：B

A．支持随机生成输入和真实数据输入两种方式

B．可以获取整网中每个API的输入数据的shape、dtype、数值分布等信息

C．获取的数据会存在累积误差

D．支持标杆比对法进行精度比对

解题：从教程下图可知，获取先限定为**每个pytorch计算API**，而不是B项所说的**每个API**，这属于夸大的获取范围，故该题答案选B

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/77c55886-803f-4971-84be-1d2380b38349.png)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/664d7132-c279-4980-b5ec-b4bb4f6c4a72.png)

[https://gitee.com/ascend/mstt/blob/master/debug/accuracy\_tools/api\_accuracy\_checker/README.md](https://gitee.com/ascend/mstt/blob/master/debug/accuracy_tools/api_accuracy_checker/README.md)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/8acf1ea7-55a1-49c2-bd53-7a5b71dfb061.png)

---

### 12.以下关于集合通信原语说法错误的是哪项? 答案：B

A．broadcast是一对多操作

B．scatter是多对多操作

C．gather是多对一操作

D．ReduceScatter是多对多操作

解题：从教程下图可知，scatter是一对多操作，故该题答案选B。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/1ddbfda7-fb3b-4df0-96c1-d9fd2c04cebf.png)

---

### 13.在精度定位过程中，如果通过大量的实验后发现偏差是算法稳定性层面或者累积偏差导致的，算子的精度都是达标的，应该如何处理?   答案：B（存疑）

A．只要未达到客户合同要求的精度偏差指标，就继续投入分析

B．分析偏差扩散的路径是否合理，并同时测试下游任务，通过下游任务得分和理论分析过程和客户解析原因

C．loss是反应模型精度最真实的指标，至少应该保证loss收敛后的值满足偏差指标才能认为精度达标

D．以上都不对

解题：存疑，需要在B或D之间做选择，可以排除A和C。

---

### 14.假设我们已经有一个已经训练好的汽车分类模型，所用的大规模数据集来自专业网站上的汽车图片，包含上千种车型，均为静止状态下的高清图片。现在需要解决的场景也是汽车分类问题，但针对的是高速路上摄像头抓拍到的汽车图片，训练教据较少，但需要识别的车型类别少目均包含在之前模型的类别中，那么如下做法中比较合理的是哪一项?   答案：D

A．使用新的训练数据集重新训练一个新的模型

B．因为任务完全覆盖，可以直接使用已有模型

C．在已有模型基础上使用新数据集继续训练

D．使用新数据集对已有模型的最后几层进行微调

解题：用排除法，高速路抓拍到汽车图片训练数据较少可排除A选项，专业网站的高清图与高速路抓拍图存在差异（拍摄角度 图像质量 背景环境）可以排除B选项，使用较少的新数据集继续训练容易过拟合、如果学习率设置不当可能会破坏原模型可以排除C选项。

D选项这种做法被称为迁移学习（Transfer Learning），特别适合新数据集较小但需要识别的类别已经在先前的大规模数据集中存在的这种情形。故该题答案选D。

---

### 15.卷积神经网络(CNN)发展过程中，出现了很多各具特色的模型，其中AlexNet的问世可谓是石破天惊，在2012年lmageNet竞赛中以绝对优势一举夺冠，使得全球范围内掀起了一波深度学习热潮，如下关于这一经典模型的描述中错误的是那一项?  答案：A

A．AlexNet使用SE(Sequeeze-and-Excitation)模块学习不同通道之间的依赖关系，以提高模型的表现能力

B．AlexNet使用dropout技术在训练过程中随机失活一部分神经元，以避免模型过拟合

C．AlexNet使用ReLU代替传统的Sigmoid激活函数，训练速度更快

D．AlexNet使用局部响应归一化(Local Response Normalization，LRN)，以提高模型泛化能力

解题：SE (Squeeze-and-Excitation) 模块首次被引入并使用的模型是 SENet，不是AlexNet。故该题答案选A。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/f5c125e0-61b3-42e7-8180-364daeb45022.png)

---

### 16.循环神经网络(RNN)擅于处理序列数据，但是当序列长度过长时，普通的RNN模型会有长距离依赖(long-tenn dependencies)问题，即相关信息的间隔较大，RNN很难建模它们的关联性。针对这种长距离依赖问题，如下模型结构中不建议选择的是哪一项?  答案：D

A．LSTM (Long Short Term Memory)

B．GRU (Gate Recurrent Unit)

C．Transformer架构的模型

D．含有残差(residual)结构的卷积神经网络

解题：通过引入残差结构，卷积神经网络成功地解决了深层神经网络训练中的梯度消失和梯度爆炸问题，使得构建更深的卷积神经网络成为可能。然而，对于长距离依赖问题，卷积神经网络并不是最佳选择。处理长距离依赖通常需要使用专门为此设计的模型，如LSTM、GRU或Transformer等。LSTM（Long Short-Term Memory）网络是RNN（循环神经网络）的一种特殊形式，专门设计用来解决长距离依赖问题。GRU是LSTM的简化改进版。Transformer架构也有为了解决长距离依赖问题而设计的特性，特别适用于处理自然语言处理（NLP）任务中的序列数据。故该题答案选D。

---

### 17.如下示例代码展示的是哪一种编程范式:  答案：A

```python
class Network(nn.Module): 
  def init(self): 
    super()._init__()
    self.linear= nn.Linear(10,20)
  def forward (self, inputs): 
    return self.linear(inputs)

net = Network()
outputs = net(torch.randn(2, 10)) 
```

A．面向对象编程

B．面向过程编程

C．函数式编程

D．声明式编程

解题：面向对象编程 (Object-Oriented Programming, OOP)，使用类和对象,封装数据和方法,支持继承和多态:

```python
class Car:
    def __init__(self, brand, model):
        self.brand = brand
        self.model = model

    def display_info(self):
        print(f"This is a {self.brand} {self.model}")

my_car = Car("Toyota", "Corolla")
my_car.display_info()
```

面向过程编程 (Procedural Programming)，将程序分解为一系列的过程或函数,强调代码的顺序执行:

```python
def calculate_area(length, width):
    return length * width

def calculate_perimeter(length, width):
    return 2 * (length + width)

length = 5
width = 3
area = calculate_area(length, width)
perimeter = calculate_perimeter(length, width)

print(f"Area: {area}, Perimeter: {perimeter}")
```

函数式编程 (Functional Programming)，强调使用纯函数,避免状态变化和可变数据,使用高阶函数如map、filter和reduce，以及与之配合的匿名函数lambda 表达式:

```python
from functools import reduce

numbers = [1, 2, 3, 4, 5]

squared = list(map(lambda x: x**2, numbers))
evens = list(filter(lambda x: x % 2 == 0, numbers))
sum_all = reduce(lambda x, y: x + y, numbers)

print(f"Squared: {squared}")
print(f"Evens: {evens}")
print(f"Sum: {sum_all}")

```

声明式编程 (Declarative Programming)， 描述想要的结果,而不是详细指定如何得到结果的步骤。这个例子使用Pandas,它提供了一种声明式的方式来处理数据:

```python
import pandas as pd
data = {
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35],
    'City': ['New York', 'London', 'Paris']
}
df = pd.DataFrame(data)
# 筛选年龄大于27的人
result = df[df['Age'] > 27]
print(result)
```
---

### 18.MoXing是ModelArts自研的框架，提供了一套文件对象API，可以用来读写OBS文件，如果想要下载一个0BS文件夹sub\_dir 0到Notebook，如下哪个操作可以实现?  答案：B

A．mox.file.copy('obs://path\_of\_obs/sub\_dir\_0', 'path of notebook/sub\_ dir\_0)

B．mox.file.copy\_parallel('obs://path\_of\_obs/sub\_dir\_0', 'path\_of\_notebook/sub\_dir\_0')

C．mox.file.copy('path\_of\_notebook/sub\_dir\_0', 'obs://path\_of\_obs/sub\_dir\_0')

D．mox.file.copy\_parallel('path of notebook/sub\_dir 0', 'obs://path \_of obs/sub \_dir\_0')

解题：这个没啥好说的，就是死记硬背。记住函数名为copy\_parallel, 第一个入参为源路径，第二个入参为目标路径。

---

### 19.如果用户想要快速的体验不同AI领域的大模型推理流程，可以使用MindFormers的哪一项功能接口? 答案：A

A． Pipeline

B． Trainer

C． AutoClass

D． inference

解题：由教程下图可推断，该题答案选A

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/dc52c7d2-8d8b-4ff2-87e5-98f7dd8efceb.png)

---

### 20.昇腾云支持多种资源形态对外提供算力，如下场景描述的是哪种形态:面向云主机资源型用户，基于BMS(Bare Metal server，裸金属服务器)进行封装，并预装主流AI开发套件，兼容社区Open Stack原生接口 答案：A

A． ModeArts Lite DevServer

B． ModelArts Lite k8s Cluster

C． ModelArts Standard

D． ModelArts Edge

解题：由教程下图可知，该题答案选A。ModelArts Edge属于边缘设备部分，和该题无关。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/0eb41bd4-995f-48da-a9e3-9c2a1bf2fd07.png)

---

### 21.给定网络模型，构建包含自动调优策略生成、编译、运行环境验证的闭环反馈机制，利用AI算法在机器上不断迭代，最终得到最优的策略结果井将其写入知识库，从而达到在有限硬件资源上不断提升网络性能的效果。以上功能描述的是哪一款模型调优工具?  答案：B

A． MA Advisor

B． AOE(Ascend Optimization Engine)

C． AKG (Auto Kernel Generator)

D． Tailor

解题：由教程下图可知，该题答案选B。MA Advisor是基于专家知识库迁移性能自动诊断工具（对于Profiling ），

迁移环境问题诊断工具。AKG是高性能算子生成工具。Tailor是离线模型转换评估工具，专门针对onnx→mindspore-lite场景（模型转换 性能测试&精度测试 Profiling性能分析）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/ec09061a-6591-4cff-b962-da44da5e00ce.png)

---

### 22.AOE(Ascend Optimization Engine)模型调优过程中，根据数据切分等价原理自动搜索生成计算图的切分策略，通过切分算子来减少数据量，提升模型计算的性能，这属于哪一种性能优化方法?  答案：A

A．子图调优

B．模型裁剪

C．算子调优

D．算子切分

解题：此题提到“自动搜索生成计算图的切分策略，通过切分算子来减少数据量”，首先应该排除B和C，算子切分指的是将一个复杂的算子分解成多个简单的算子，而不涉及计算图的切分策略，故排除D。

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d6450970-bf45-4c43-a051-c0f78d88c3c8.png)

---

### 23.使用Mindspore Lite的predict接口进行模型推理，如果output的内容在显存中，可以通过如下哪个方法将数据读取到内存中使用?  答案：A

A. output.get data to numpy()

B. output.to('cpu')

C. output.move to cpu()

D. output.set('cpu')

解题：由官网下图可知，该题答案选A

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d5dccb49-9e28-4034-a543-e9f38c268e75.png)

[三方应用: https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_1159.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_1159.html)

---

### 24.使用Mindspore Lite转换工具进行模型转换时，如果出现如下报错，可能的原因是哪一项?\[ERROR\]ME(103674,7fbdc90a8ec0,python):2021-12-13-16:20:49.506.131 \[mindspore/lite/src/extendrt/session/single op session.cc:242\] CompileGraph\] Only support CustomAscend, but got Reshape, node ReshaDe 9IERRORI ME(103674,7fbdc90a8ec0,pvthon):2021-12-13-16:20:49.506.245 \[mindspore/lite/src/extendrt/cxx api/model/model impl.cc:280\] BuildByBufferlmpl\] compile graph failed.  答案：C

A. 转换工具不支持模型中的Reshape算子

B. 转换工具不支持Reshape算子中的某些参数

1.  模型转换时未指定Ascend后端
    

D. 模型文件损坏

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/cd71b4d5-0c79-4195-a43b-b477fe137e0d.png)

解题：存疑，A或者C，C的可能性更大。

[MindSpore](https://www.mindspore.cn/lite/docs/zh-CN/r2.3.1/troubleshooting_guide.html) 该链接是Mindspore Lite转换工具进行模型转换时常见的一些模型转换问题，根据文档分析，出现 api/model 最可能是C 

---

### 25.定位精度问题时，首先要保证NPU和标杆设备上的模型初始状态保持一致，最方便且有效的做法是什么?  答案：C

A 固定随机种子进行随机初始化

B 打开确定性计算开关后进行随机初始化

C 固定随机种子 打开确定性计算开关后 进行随机初始化

D 加载相同的初始权重进行初始化

解题：固定随机种子  数据集shuffle固定  模型训练相关超参数配置一致  开启inf/nan模式  确定性计算打开 运行前删除上一次运行的缓存。由此可知，答案C最接近。

### 26以下不属于模型迁移开发全流程的是哪一项?答案：C

1.  迁移评估
    
2.  模型代码迁移
    
3.  模型可视化
    
4.  精度性能调优
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/7b9b6db3-dea7-45d5-bff3-82288cbf1edb.png)

解题：模型迁移开发中全流程应该是：模型选取，模型评估，模型迁移，模型训练，模型调优、分析和调测，没有可视化。

### 27.以下哪项是昇腾异构计算中的集合通信库?C

1.  CuDNN
    
2.  NCCL
    
3.  HCCL
    
4.  Gloo
    

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclapi\_07\_0001.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclapi_07_0001.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/85b393ca-0b44-4b1e-8132-008aa9b79376.png)

### 28.请问以下哪个仓库是昇腾提供的大模型解决方案仓库?答案：B

1.  DeepSpeed
    
2.  ModelLink
    
3.  AscendSpeed
    
4.  Megatron-LM
    

[https://gitee.com/ascend/ModelLink](https://gitee.com/ascend/ModelLink)

### 29.下面哪一项负责AI Core内部数据在不同Buffer之间的读写管理及一些格式转换的操作，比如填充(padding)、转置(transpose)3D图像转2D矩阵(Img2Col)等? A

1.  存储转换引擎MTE
    
2.  总线接口单元BIU
    
3.  通用寄存器GPR
    
4.  专用寄存器SPR
    

[三方应用: https://www.hiascend.com/doc\_center/source/zh/CANNCommunityEdition/80RC2alpha001/devguide/opdevg/tbeaicpudevg/atlasopdev\_10\_0008.html](https://www.hiascend.com/doc_center/source/zh/CANNCommunityEdition/80RC2alpha001/devguide/opdevg/tbeaicpudevg/atlasopdev_10_0008.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b5cb9164-3c52-47c3-9fb3-0ec5b0aaf2b5.png)

### 30.通常来讲，算子下发瓶颈识别可以通过搜索观察哪个接口间隙来判断，间隙越多说明存在算子下发瓶颈，间隙越少说明算子下发状态良好。B

1.  Enqueue
    
2.  Dequeue
    
3.  Enstack
    
4.  Destack
    

[三方应用: https://www.hiascend.com/doc\_center/source/zh/CANNCommunityEdition/80RC1alpha001/devaids/auxiliarydevtool/atlasprofiling\_16\_0006.html](https://www.hiascend.com/doc_center/source/zh/CANNCommunityEdition/80RC1alpha001/devaids/auxiliarydevtool/atlasprofiling_16_0006.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e6120b38-5b19-43fe-bcc6-6e90ddef5da0.png)

### 31.完成精度调试的标志是什么?B（？）

1.  Loss与标杆完全对齐
    
2.  采用常规数据集评估模型分数符合社区实践评分预期
    
3.  模型在验证集上的准确率达到一定水平
    
4.  以上都不是
    

### 32.卷积神经网络(CNN)在计算机视觉领域取得了极大成功，这是因为卷积运算的两大核心思想--局部感知与参数共享--非常适合图像处理，那么如下关于这两个思想的描述中错误的是哪一项?D

1.  局部感知指的是每个神经元仅与输入层的一小块区域连接，这块局部区域称作感受野(receptive field)
    
2.  局部感知是通过小尺寸卷积核实现的，即卷积核尺寸远小于输入图像尺寸，只探索局部信息
    
3.  参数共享指的是卷积过程中卷积核的权重不会改变，通过相同的卷积核提取了不同位置的特征
    
4.  参数共亨的优点是可以减少计算量，降低内存/显存需求，而局部感知没有这个效果
    

### 33.某客户在公有云上部署了AI业务，某天的15点5分业务量暴增，15点20分用户下扩容订单，昇腾云服务在20分钟后即完成千卡资源扩容上线，保障了用户业务的平稳运行。以上案例体现的是异腾云服务的哪一项关键能力? A

1.  立等可取，即开即用
    
2.  集群优化，释放性能
    
3.  全栈优势，高效诊断
    
4.  安全可靠，上云无忧
    
5.  百模千态，一键部署
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a7c5e341-bf95-4922-869d-8a8f0ca9c651.png)

### 34.SPMD(Single Program Multiple Data，单程序多数据)是并行计算中的常用方法，如下关于SPMD流程描述错误的是哪一项? C

1.  启动一组进程，他们运行相同的程序
    
2.  切分待处理的数据，把数据分片分发给不同进程
    
3.  每个进程都处理所有的数据切片         （每个进程只处理分配给它的数据分片）
    
4.  每个进程对自己的数据分片进行所有任多的处理
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d8d05c13-a8b0-403e-8ca8-2a97c304f7be.png)

### 35.假设我们训练好的一个机器学习模型，它在训练集、验证集、测试集上的错误率分别为0.5%、15%、15%，那么如下优化措施，我们不建议使用哪一项?  D

1.  使用新的模型架构
    
2.  增加训练数据并做更多的数据增强
    
3.  尝试提前终止训练(early stopping)
    
4.  减少正则化
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/57f8dc9a-15de-4582-ad87-3db68531d046.png)

### 36.假设我们在神经网络中使用了某个激活函数(activation function)，对于某个输入得到的输出值是-0.01，那么这个激活函数可能是以下哪一个? A

1.  Leaky ReLU
    
2.  ReLU
    
3.  Sigmoid
    
4.  Softmax
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/61a7f016-1338-4502-8b7d-e6eb93363606.png)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/763dc8af-74a2-4de3-9303-34634ae1a427.png)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/3ded3ebf-e3c5-47bd-a3ba-f44d57082bd5.png)

### 37.在精度调试问题中，以下哪些操作不是确定性问题排查的手段? C

1.  使用ptdbq工具的md5 dump功能找到不确定问题首次发生的step
    
2.  使用梯度监控工具监控NPU训练过程中的确定性问题
    
3.  设置export HCCL DETERMINISTIC=TRUE
    
4.  使用ptdbq工具的dump功能导出API的tensor统计数据
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/2609ff3a-4426-44ca-994b-158d126a0dc2.png)

### 38.在使用MindFormers进行大语言模型的文本生成时，可以配置不同的采样策略，如下描述的是哪一种策略:每个时间步，按照token出现的概率由高到底排序，当概率之和大于某个阈值时，就不取后面的样本了;然后对取到的这些token的概率重新归一化后，进行采样 B

1.  贪心采样
    
2.  Top-p 采样
    
3.  Top-k 采样
    
4.  Beam Search 采样
    

贪心采样总是选择概率最高的 token。

Top-k 采样是只在概率最高的前 k 个 token 中进行采样。

Beam Search 采样则是通过维护多个候选序列来搜索最优输出。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d172d128-4e88-4f6d-a938-03ddf97d534e.png)

### 39.以下关于离线模型转换评估工具Tailor相关描述错误的是哪一项？B（）

A.Tailor是用于模型转换（ONNX到MindIR)和性能分析的辅助工具

B.Tailor的主要功能是：模型转换、性能测试&精度测试、Profiling性能分析，ONNX网络修改

C.Tailor在分析过程可以开启AOE优化

D.Tailor可以查询ONNX模型的输入输出信息

[AIGC工具tailor使用指导\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_0166.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/1dfb84b1-ba66-4f23-8c1b-91196d227dc4.png)

### 40.模型训练时，出现OOM (Out Of Memory) 错误，则如下哪个改动有助于解决问题？D （确定）

A. 数据精度由 fp16 -> bf16

B. 数据精度由 fp16 -> fp32

C. 数据精度由 bf16 -> fp32

D. 数据精度由 fp32 -> fp16

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4580315a-80d1-4c25-8764-fdff08cb8557.png)

### 41.模型脚本自动迁移时使用的是如下哪行代码？A（确定）

A.import torch\_npu; from torch\_npu.contrib import transfer\_to\_npu

B. from mist\_llm import DumpConfig, register\_hook

C.import deepspeed

D. deepspeed.init\_distributed('hccl')

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/18b7cd53-d832-4a25-87bc-695bb7661163.png)

### 42.模型训练过程中算子的高精度主要指什么？B（确定）

A.整数运算高精度

B. 浮点数运算高精度

C.FP16

D. 混合精度

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/8a29c49f-effe-4e6b-8db6-ab414a48a218.png)

### 43.以下关于分布式并行DDP的说法正确的是哪项？C

A.DDP采用单机多卡，一台机器上运行一个进程

B. DDP运行时，server要和每一个worker进行梯度传递，当server和worker不在同一台机器时，server带宽会成为瓶颈

C.DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长

D.DDP通过手机梯度到device\[0\]，在device\[0\]更新参数，然后其他设备复制到device\[0\]的参数实现各个模型同步

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/5c0fc864-fb1b-4e75-9f24-b7eefc4a3f25.png)

### 44.以下哪项不属于集合通信的最基础的操作？D（确定）

A.send

B.receive

C.copy 

D.all2all 

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0239cc7b-1752-4c82-ae1b-018559031175.png)

### 45.过拟合是机器学习中需要避免的现象，在其它条件不变的前提下，以下哪种做法容易引起过拟合问题？C（确定）

A.增加训练数据集的样本量

B.减少神经网络中隐藏层的节点数

C.减少或不做数据增强

D.使用dropout等正则化方法

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5140c04e-b18e-48c7-a931-73ed860f506f.png)

### 46.提高网络模型的抗噪能力，方法之一就是在训练过程中加入随机噪声，我们可以在网络的不同位置加入噪声，如下关于噪声注入的描述错误的是哪一项？B（确定）

A. 在输入层加入噪声，可以看做是数据增强，使网络对于输入更加鲁棒

B.我们通常无法保证数据集100%标记正确，因此可以在隐藏层增加噪声，即标签平滑

C.标签平滑主要用于分类任务中，能够防止模型过于求确切的概率而不能学习正确分类

D.dropout也是一种噪声注入方法，通常加在隐藏层中

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4b8e729a-60f1-4149-8a07-f3b9488d06c3.png)

### 47.量大小（batchsize）的设置对神经网络的训练效果有较大的影响，在训练中，我们通常将batchsize设置为2的指数倍，如32/64/128等，这么做的原因是什么？A（？）

A.内存/显存一般也是2的指数倍，方便并行化

B.梯度优化算法在2的指数倍场景下效果更好

C.损失函数（lossfunction）更容易计算，收敛更快

D.对学习率的设置更友好，更鲁棒

### 48.ModelArtsLite提供了多种场景下的存储解决方案，如下场景描述的是哪种存储配置方案：提供高可靠、高性能、规格丰富并且可弹性扩展的块存储服务，其中存放的是二进制数据，无法直接存放文件，且只能在ECS（ElasticCloudServer，弹性云服务器）、BMS（BareMetalServer，裸金属服务器）中挂载使用，不能被操作系统应用直接访问。C

A.SFS（ScalableFileService），弹性文件服务

B.SFS Turbo

C.EVS（ElasticVolumeService），云硬盘

D.OBS（ObjectStorageService），对象存储服务

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d63737a8-11ae-4f9d-9339-d1e5a42fe402.png)

### 49.MindSpore的Cell类是构建所有网络的基类，当用户需要自定义网络时，需要继承Cell类，其中网络的执行需要重写Cell类的哪个方法？A（确定）

A.construct

B.inference

C.forward

D.call

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/76df471b-d752-49cd-bb52-898e44c65a39.png)

### 50.ModelArts支持开发者使用本地IDE连接到Notebook开发环境进行远程开发，此时需要使用以下哪一项进行鉴权认证？A（确定）

A.秘钥对

B.AK/SK

C.华为账号密码

D.项目ID

[三方应用: https://support.huaweicloud.com/devtool-modelarts/devtool-modelarts\_0015.html](https://support.huaweicloud.com/devtool-modelarts/devtool-modelarts_0015.html)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/fba4f909-0af4-4c0b-b44c-be3e683cf00b.png)

### 51.一个7 B参数量的模型，使用fp16格式的数据精度进行推理，其显存占用最接近如下哪一项?  C

1.  3.5 G8
    
2.  7 GB
    
3.  14 GB
    
4.  28 GB
    

### 52.如下信息是使用哪一条命令执行得到的?+---------pu-smi23.0.rc2.2 Version:23.0.rc22|+--------U Name | Health | Power(W) Temp(C) Hugepages-Usage(page)llChipBus-ld AlCore(96) Memory-Usage(MB) HBM-Usage(M8)|+=====-===:=====H4 910B4|OK|84.239 0/01010000:81:00.0100/03170/32768|+=======p|Process id |Process name | Process memory(MB)|+=============二二二三二ニ二ニニニ二二二二二========================+ No running processes found in NPÚ 4 +=================+====================+===================+

A（？）

1.  npu-smi info
    
2.  npu-smi info watch
    
3.  npu-smi info -l
    
4.  npu-smi info -m
    

### 53.使用AOE(Ascend Optimization Engine) 进行单模型性能调优时，建议的整体操作步骤是如下哪一个? 1.制除编译续存2.删除已有的AOE知识斥3.配置文件中启用AOE自动喝优4.配置文件中关团AOE自动调优5.执行模型转换 。  C（？）

1.  1,3,5
    
2.  1,2,3,5
    
3.  1,2,3,5,1,4,5
    
4.  1,2,4,5,1,3,5
    

### 54.AIT (Ascend Inference Tool) 是昇腾推理一体化开发工具，可执行多项任务，如果需要分析昇腾推理设备对输入模型的支持度情况，包括算子支持情况、算子定义、算子输入等，应该使用如下哪一项task类型?C（确定）

1.  benchmark
    
2.  transplt
    
3.  analyze
    
4.  profile
    

原因：使用analyze task可以获取昇腾推理设备对输入模型的支持度情况。

benchmark 和 profile 测试  transplt 迁移  analyze 分析

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/0069edb7-3362-4876-a936-f7b69141b9e7.png)

### 55.下面哪一个命今可以获取NPU设备内存总的便用情况?  D（确定）

1.  midia-smi
    
2.  midia-smi info
    
3.  npu-smi
    
4.  npu-smi info
    

### 56.NPU上Flash attention中 (npu\_fusion attention) 常提到的layout排布(B、S、N、D、H)中，以下说法错识的是 ？C

1.  B表示batch size维度
    
2.  S表示序列长度
    
3.  N表示Query、Key、Value的numm\_heads数，且三者长虚必须一致（成比例关系）
    
4.  H=N\*D
    

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/700alpha002/ptmoddevg/ptmigr/ptaoplist\_246.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/700alpha002/ptmoddevg/ptmigr/ptaoplist_246.html)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/8373082b-02fa-4a42-93bc-ab4008d370f7.png)

### 57.流行的深度学习框架中有不同的数据格式，典型的有NCHW、NHWC等格式。其中，N、C、H、W分别指的是什么?  C（确定）

1.  N (NUM) 、c (Count) 、H (Height) 、w (Width)
    
2.  N (Head-Num) c (Channel) ，H (HEAD) 、W (Width)
    
3.  N (Batch) .C (Channel) 、H (Height) .w (Width)
    
4.  N (Batch) .C (Count) 、H (Height) .w (Width)
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/7c744435-d3a3-46c3-abe9-9f96df08c722.png)

### 58.以下哪项不属于算子精度问题分析流程?   D（？）

1.  溢出检测
    
2.  dump数据
    
3.  hccl检测
    
4.  通过预检工具比对数据
    

### 59.关于昇腾精度定位问题分析，以下说法正确的是。C（？）

1.  只要loss和标杆对齐(满足一定的偏差阈值)就说明精度已经没有问题了
    
2.  只要昇腾和GPU在相同输出时，API的输出结果不一致就可以认为是昇腾算子有问题
    
3.  算子的性能和精度存在此消彼长的关系，需要根据实际情况进行权衡
    
4.  GPU上同等精度输出可以作为真值参考，所以要保证所有NPU的输出需要尽可能地和GPU对齐
    

### 60.在大模型训练中，若想指定运行的NPU卡为第6和第7张卡，正确的指定方式是什么?  A（？）

1.  export ASCEND\_RT\_VISIBLE\_DEVICES=6,7
    
2.  export ASCEND\_RT\_VISIBLE DEVICES=6~7
    
3.  export ASCEND\_RT\_VISIBLE\_DEVICES=\[6,7\]
    
4.  export VISIBLE\_DEVICES=\[6,7\]
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/8093bb26-bd62-4ef7-af2a-f142f1b896c2.png)

### 61.以下哪种现象可以说明PyTorch确定性计算开关开启成功且生效:  A（？）

1.  多次运行训练脚本，loss曲线趋势保持一致(在同一时刻下降和上升，且偏差幅度始终保持一致)
    
2.  多次运行训练脚本，loss曲线的值必须保持完全一致，任何差异都是不可以接受的
    
3.  开启确定性开关前后的loss曲线趋势保持-致(在同一时刻下降和上升，且偏差幅度始终保持一致)
    
4.  由于集合通信的累加顺序不一致，因此即使打开确定性计算，也无法保证最终的输出是完全一致的
    

### 62.在卷积神经网络CNN中，卷积是最核心的操作，其输入输出都是多维向量，或是图像，或是特征图。假设某一个卷积操作中，输入图像大小为5\*5\*3(HWC，高"宽"通道数，不考虑批量大小batch size，下同)，卷积核尺寸为3“3，通道数为5，卷积步长为1，边缘不做填充，则输出的特征图大小是多少 (用HWC格式表示)?  B

1.  3\*3\*3
    
2.  3\*3\*5
    
3.  5\*5\*3
    
4.  5\*5\*5
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/45110a43-f6e7-41af-b5e1-598344b6b293.png)

[三方应用: https://www.cnblogs.com/yc096ay/p/14405724.html](https://www.cnblogs.com/yc096ay/p/14405724.html)

### 63.梯度下降算法的正确步骤是什么?1.计算预测值和真实值之间的误差2.重复迭代，直至得到网络权重的最佳值3.把输入传入网络，得到输出值4.用随机值初始化权重和偏差5.调整权重以减小误差     D（？）

1.  3,1,5,4,2
    
2.  4,1,3,5,2
    
3.  3,4,1,5,2
    
4.  4,3,1,5,2
    

### 64.数据增强是深度学习中的必要操作，相当于增加了训练数据样本，可以降低过拟合的概率，但是在不同的任务中也要注意数据增强方法的选择，不能干扰到模型对数据特征的学习。例如在0~9的手写数字识别中，哪一项数据增强方法不建议使用?  C（确定）  D

1.  图像缩放
    
2.  随机亮度变化
    
3.  随机添加噪声
    
4.  图像翻转
    
5.  图像颜色变换
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/34db0792-1b05-4688-9031-69a591d9e670.png)

### 65.在ModelArts控制台创建A应用时，如果需要使用pip方式安装某些依赖包，那么这些信息需要填写在配置文件config.json的哪个字段下?    D（？）  A

1.  dependencies
    
2.  pip-dependencies
    
3.  requirements
    
4.  pip-requirements
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/9c475fdb-cb2e-4f73-a134-2dd09d9b08f6.png)

### 66.MindSpore支持动态图和静态图两种模式，可以通过st.context接口来设置运行环境，如果需要设置为动态图运行模式，该接口的mode参数应该如何设置?   A（确定）

1.  PYNATIVE\_MODE
    
2.  GRAPH MODE
    
3.  DYNAMIC MODE
    
4.  ASCEND MODE
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b512d5bc-a33f-4300-94d3-402d7561962a.png)

### 67.采用converter\_lite工具进行模型转换时，可在配置文件中通precision\_mode参数指定精度模式，该参数的默认设置为如下哪一项? A（确定）

1.  enforce\_fp16
    
2.  enforce\_fp32
    
3.  preferred\_fp32
    
4.  enforce\_origin
    
5.  preferred\_optimal
    

 [MindSpore](https://www.mindspore.cn/lite/docs/zh-CN/r2.3.1/use/cloud_infer/converter_tool_ascend.html)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/50e62ae6-52d7-4833-9149-3a3104d472c8.png)

### 68.以下不属于DeepSpeed分布式并行技术的是哪一项?D（确定）

1.  ZeRO1-3
    
2.  3D并行
    
3.  CPU offloading
    
4.  Page Attension
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f71e9376-0570-476a-a1d6-d4df1c88a8e6.png)

### 69.以下关于梯度监控工具的level参数说法错误的是哪项?B

1.  LO：梯度特征数据，包含如下特征：("param\_name"， “MD5"，"max"，“min"， "norm"， “shape")、无梯度方向数据
    
2.  L1：梯度特征数据，包含如下特征：("param\_name"， "MD5"， interval\_O..interval\_n， "=0"， "max"，"“min"，"norm"， "shape")、有梯度方向数据
    
3.  L2：梯度特征数据，包含如下特征：("param\_name"，“MD5"， “max"，“min"， "norm"， "shape")、有梯度方向数据
    
4.  L3：梯度特征数据，包含如下特征：("param\_name"， "MD5"， interval\_O..interval\_n， "=0"， "max"， "“min"，"norm"， "shape")、有梯度方向数据
    

原因：L1：无梯度方向数据。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/ed192ade-4a1e-4481-b48b-017324800aac.png)

### 70.pytorch框架训练性能调优时，采集profiling时需要采集堆栈信息，需要配置的参数是哪项?A（确定）

1.  with stack=True
    
2.  data\_simplification=False
    
3.  aic\_metrics=torch\_npu.profiler.AiCMetrics.PipeUtilization
    
4.  record\_shapes=True
    

原因：采集profiling时需要配置with\_stack=True来采集堆栈信息。

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d0832166-6105-4a6d-9c23-964d4eba4e8e.png)

### 71.以下关于分布式数据并行DDP的说法正确的是哪项?C（确定）

1.  DDP采用单进程，一台机器上运行一个进程
    
2.  DDP通信开销大，server要和每一个worker进行梯度传输，当server和worker不在同一台机器时，server带宽会成为瓶颈
    
3.  DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长
    
4.  DDP通过收集梯度到device\[0\]，在device\[0\]更新参数，然后其他设备复制 device\[0\] 的参数实现各个模型同步
    

原因：

DDP采用单进程，一台机器上运行一个进程：这是错误的描述。DDP 实际上采用多进程的方式，在每台机器上运行多个进程，每个进程负责一部分数据并行处理。

DDP通信开销大，server要和每一个worker进行梯度传输，当server和worker不在同一台机器时，server带宽会成为瓶颈：这是错误的描述。DDP 不是基于 server-worker 模型的，而是基于 peer-to-peer 的模型，每个 worker 都与其他 worker 直接通信，无需通过中央 server。

DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长：这是正确的描述。DDP 使用 Ring AllReduce 算法来最小化通信开销。在这种算法中，每个进程只与相邻的两个进程通信，这样可以有效地减少通信的成本，并且随着节点数的增加，通信成本的增长不是线性的。

DDP通过收集梯度到device\[0\]，在device\[0\]更新参数，然后其他设备复制 device\[0\] 的参数实现各个模型同步：这是错误的描述。DDP 并不是将梯度集中到一个设备上更新参数，而是每个设备都参与参数更新的过程，并通过 AllReduce 算法同步梯度。

### 72.跨框架的大模型迁移(比如从GPU的书生迁移到NPU的modellink，网络定义不一致，但是整体结构一致)发现精度偏差较大，此时在进行精度对齐时最适合的定位手段是什么?A（？）

1.  使用精度对比工具dump所有API真值数据进行对比
    
2.  使用精度对比工具采集所有API统计信息数据进行对比
    
3.  使用精度对比工具分析网络是否有溢出
    
4.  使用精度对比工具dump两个框架网络的模块信息进行对比
    

原因：在进行精度对齐时，最适合的定位手段是使用精度对比工具dump所有API真值数据进行对比。

### 73.神经网络的训练，基本都是采用梯度下降 (gradient descent)算法，而它又分为多种方法，如下关于梯度下降算法的描述中错误的是哪一项?B（确定）

1.  全局梯度下降算法使用整个训练数据集来计算梯度，适用于样本量较小的场景
    
2.  随机梯度下降算法在每轮迭代时随机选取1个样本点，对噪声不敏感，容易收敛到极值
    
3.  小批量梯度下降算法每次随机选取一小部分训练数据参与计算，兼顾了效率和稳定性
    
4.  小批量梯度下降算法中引入了batch size的概念，成为神经网络训练中的重要超参数之一
    

原因：随机梯度下降算法对噪声敏感，容易发散，不易收敛到全局最优解。

### 74.池化(pooling)是神经网络中的常用操作，以下关于池化操作的作用描述错误的是哪一项?D（确定）

1.  池化后特征图的尺寸缩小了，可以降低模型的参数量
    
2.  最大池化操作保留了图像最显著的特征
    
3.  卷积之后接上池化，相当于获得了更大的感受野
    
4.  模型参数量的减少，可以进一步降低欠拟合的概率
    

原因：池化操作减少了模型参数量，有助于降低过拟合的风险，而非降低欠拟合的概率。

### 75.客户是一家购物平台，需要实现智能客服系统，回答顾客在售前、售中、售后等阶段的咨询问题。请问以上任务描述主要属于人工智能的哪个领域应用?B（确定）

1.  计算机视觉
    
2.  自然语言处理
    
3.  语音信号处理
    
4.  决策规划系统
    

原因：智能客服系统主要涉及自然语言处理技术。

### 76.如下关于计算图的描述，错误的是哪一项?B（不确定）

1.  动态图的核心特点是图的构建和计算同时发生
    
2.  动态图对全局的信息掌握更丰富，可做的优化也会更多
    
3.  静态图在计算阶段，根据输入数据执行编译好的图得到计算结果
    
4.  静态图无法实时拿到中间计算结果，中间过程对于用户来说是个黑盒
    

原因：静态图相比于动态图更能掌握全局信息，可做的优化更多。

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/1f92b128-aaba-474c-8b90-4f95900b43d1.png)

### 77.假如用户A和用户B不在同一个主账号下，A想要在ModelArts的开发环境中使用B的自定义镜像，正确的操作步骤是哪一项?B（确定）D(共享的不能直接使用，想被地址直接使用需要公开，自己测试一下就知道了)

1.用户A在ModelArts控制台的镜像管理页面，使用镜像的SWR(容器镜像服务)地址进行镜像注册

2.用户B在SWR(容器镜像服务)控制台中将镜像共享给A

3.用户A使用安装了容器引擎的计算机将共享镜像Pull下来

4.用户A使用安装了容器引擎的计算机将共享镜像Push到SWRR(容器镜像服务)

1.  1
    
2.  2，1
    
3.  2，4，1
    
4.  2，3，4，1
    

原因：用户B需要先将镜像共享给用户A，然后用户A在ModelArts控制台注册镜像。

### 78.提供一系列适配过昇腾算力的模型，用户可以在平台上进行部署、微调、训练等操作，也就是"模型即服务"B（确定）

1.  云化算力
    
2.  模型开发
    
3.  模型托管
    
4.  模型生态
    

原因：模型托管主要侧重于对模型的存储和管理；模型生态则更侧重于整个模型相关的生态系统，包括开发者、使用者、模型的交流与共享等方面；云化算力则主要指云计算提供的强大计算能力。而这里着重描述的是针对模型的开发相关服务，所以是模型开发。

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a39aef12-6bc2-4fb2-969a-485fb63cd9b0.png)

### 79.如下MindFormers的组件中，哪一项提供了大模型的推理加速能力?B          D

1.  MindSpore PET
    
2.  MindSpore Serving
    
3.  MindSpore Interence
    
4.  MindSpore Lite
    

原因：MindSpore Serving提供了大模型的推理加速能力。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/7505dd56-fd98-43a6-82bb-ee5ef6b01b1c.png)

### 80.混合精度(Mix Precision)训练是指在训练时，对神经网络不同的运算采用不同的数值精度，MindSpore的哪个模块提供了自动混合精度接口?B（确定）

1.  jt
    
2.  amp
    
3.  trainer
    
4.  Confiq
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b3f4c85a-67c6-4e2f-802c-88d79a053605.png)

### 81.如下场景描述的是哪一种机器学习方法:根据数据本身之间的属性对数据进行聚类，相似相近的数据聚在同一类;不相似或不相近的数据分在不同的类中。B（确定）

1.  监督学习
    
2.  无监督学习
    
3.  半监督学习
    
4.  强化学习
    

聚类是无监督学习的一种方法

### 82.在神经网络训练过程中，如果出现损失函数(loss function)在极值处不停震荡不收敛，那么最可能的原因是哪一项?B（确定）

1.  学习率(learning rate)太小
    
2.  学习率(learning rate)太大
    
3.  隐藏层层数太少
    
4.  隐藏层层数太多
    
5.  激活函数选择了线性函数
    
6.  batch size过大
    

### 83.大模型推理全量性能测试不需要覆盖下述哪个维度?A（确定）

1.  profiling-step
    
2.  batch\_size
    
3.  input\_seq\_len
    
4.  out seq\_len
    

在进行大模型推理的全量性能测试时，通常需要考虑多个维度以确保全面评估模型的性能。这些维度包括但不限于不同的批大小（`batch_size`）、输入序列长度（`input_seq_len`）、输出序列长度（`output_seq_len`）等。然而，“profiling-step”并不是一个直接用于性能测试的维度，而是性能分析（profiling）过程中的一种机制或步骤，用于收集性能数据。

### 84.使用benchmark工具对某个图片分类模型进行精度测试时，需要获取一份标准输入数据并保存成二进制文件，通常建议将什么样的数据制作成标准数据?C（确定）

1.  原始的图片数据
    
2.  使用图像处理库(如OpenCV、Image等)读取的图片数据
    
3.  经过预处理后的图片数据![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c3b5966c-5319-486f-88e3-a0a6cb6d60d4.png)
    

### 85.以下哪个命令可以检查NPU环境中PyTorch环境的基本功能是否正常?A（确定）

1.  python3 -c "import torch;import torch\_npu; a = torch.randn(3, 4).npu(); print(a + a);
    
2.  python3 -c "import torch;a = torch.randn(3, 4).npu(); print(a + a);"
    
3.  python3 -c"import torch\_npu;a = torch.randn(3, 4).npu(); print(a + a);"
    
4.  以上都不对![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/66be7ab2-6edf-4842-910c-cf2b61229513.png)
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a8b2073c-760d-4856-9777-55d42e4b1ba6.png)

### 86.以下关于梯度监控工具说法错误的是哪项?B（没有关于B的描述，B应该是api对比工具）

1.  通过 torch.nn.Module 提供的 named parameters()方法拿到所有命名参数的张量
    
2.  获取整网中每个pytorch计算API的输入真实张量数值分布
    
3.  用register\_hook给所将参数张量挂上钩子函数
    
4.  通过钩子回调函数可以访问到Module参数每一次训练选代步的梯度数据
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b21075fa-8e00-4026-a1df-f4bb747feeea.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/3cef9968-8283-4f3c-bc60-bcd04fcb5104.png)

### 87.昇腾性能比对工具compare\_to0ls支持比较GPU与NPU之间、NPU与NPU之间的性能差异，通过对训练耗时和内存占用的比对分析，定位到具体劣化的算子，帮助用户提升性能调优的效率。开启总体性能比对的参数是哪项?B（确定）

1.  enable operator compare
    
2.  enable profiling\_compare
    
3.  enable communication compare
    
4.  enable memory compare
    

[mstt: 针对训练&大模型场景，提供端到端命令行&可视化调试调优工具，帮助用户快速提高模型开发效率 - Gitee.com](https://gitee.com/ascend/mstt/tree/master/profiler/compare_tools)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b32b6d62-510b-497d-a9af-7c29fcd92124.png)

### 88.在迁移分析流程中，需要使用什么工具来分析模型在昇腾设备上的支持度? B(确定)

1.  AOE工具
    
2.  PyTorch Analyse工具
    
3.  Ptdbg Ascend工具
    
4.  Advisor工具
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/dff9068a-1eb6-4dbd-b542-cf0b87cfdf25.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e6f4c73c-a0f2-45df-a083-ee0f7618afa9.png)

### 89.pytorch框架训练性能调优时，大集群场景下profiling数据量很大，应该优先使用哪个工具进行初步分析?B（？）

1.  compare\_tools
    
2.  cluster\_analyse
    
3.  aoe
    
4.  tailor
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d5c76ee7-90eb-4c39-b486-7c992af1bec3.png)

[https://www.hiascend.com/document/detail/zh/mindstudio/70RC2/msinsightug/msascendinsightug/AscendInsight\_0101.html](https://www.hiascend.com/document/detail/zh/mindstudio/70RC2/msinsightug/msascendinsightug/AscendInsight_0101.html)

### 90.以下关于NPU融合算子说法正确的是:C（？）

1.  NPU上的融合算子性能一定比对应小算子性能更好
    
2.  NPU上的融合算子都能够找到对应的cuda融合算子进行对标
    
3.  训练场景中，使用融合算子能够缓解小算子造成的算子性能下发瓶颈
    
4.  融合算子在使用上相比于小算子来说是完全等价的，即小算子上能够支持的输入，融合算子也能够支持
    

### 91.以下不属于MindSpore原生分布式并行策略的是哪一项?D（确定）B

1.  数据并行
    
2.  算力并行
    
3.  自动并行
    
4.  半自动并行
    

[https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3.1/parallel/overview.html](https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3.1/parallel/overview.html)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/988fac46-bc59-4954-98c2-e2ba75d4d6d5.png)

### 92.昇腾性能比对工具compare\_tools支持比较GPU与NPU之间、NPU与NPU之间的性能差异，通过对训练耗时和内存占用的比对分析定位到具体劣化的算子，帮助用户提升性能调优的效率。开启总体性能比对的参数是哪项?B（确定）

1.  enable\_operator compare
    
2.  enable\_profiling\_compare
    
3.  enable\_communication\_compare
    
4.  enable\_memory\_compare
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/57db4a3f-b82f-4113-b602-f1cd55a87f31.png)

### 93、以下关于PTAdapter说法错误的是哪一项?D

1.  使用时需要在训练任务启动入口添加import torch\_npu
    
2.  基于monkey-patch的原理实现自动迁移
    
3.  可以将cuda和nccl操作映射到npu和hcdl对应操作
    
4.  可以自动迁移GPU高阶自定义融合算子
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0f5129a4-13f6-4c43-a17e-bc6bf20131f9.png)

### 94、模型脚本迁移推荐使用如下哪种方式?A

1.  自动迁移
    
2.  手动迁移
    
3.  复制粘贴
    
4.  分析工具扫描
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f6d6f8a7-d828-4bcc-ae92-68719b856053.png)

### 95、针对于常稳训练的精度问题(前期loss收敛趋势和标杆一致，后期在某几个step之后loss逐渐偏离标杆)，以下那种手段最适合进行问题定位?B（？）

1.  记录loss偏差开始的step，重新训练模型，并在对应step通过工具dump数据进行分析
    
2.  记录loss偏差开始的step，加载距离异常发生点最近的ckpt，并在对应step通过工具dump数据进行分析
    
3.  加载距离异常发生点最近的ckpt，打开确定性计算开关，观察是在哪个step稳定出现偏差，重新运行后在对应step通过工具dump数据进行分析
    
4.  打开确定性计算开关，重新训练模型，观察是在哪个step稳定出现偏差，重新运行后在对应step通过工具dump数据进行分析
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2e35658e-045d-460e-9a85-f2543c0d4f6a.png)

### 96、下述哪个方法可以用来处理神经网络中的过拟合现象?D（确定）

1.  Dropout
    
2.  Batch Normalization
    
3.  正则化
    
4.  都可以
    

### 97、在性能调优过程中，通过分析采集profiling数据的timeline发现free time呈现多次小块的特征，但是相对标杆性能耗时较大，可考虑使用什么方法进行性能调优?

1.  增大模型参数batch size
    
2.  增大模型参数number workers
    
3.  使用AOE算子调优
    
4.  将数据集文件转移至节点本地磁盘
    

### 98、定位AI CPU算子时，通过修改dtype类型消除AI CPU算子可能引起什么问题?C（？）

1.  模型显存占用问题
    
2.  数据类型转换导致下发算子变少
    
3.  数据类型转换导致的精度问题
    
4.  数据类型转换同步操作，打断异步下发
    

### 99、在卷积神经网络(CNN)中，感受野(receptive field)指的是神经网络中神经元“看到的"输入区域，越深层的神经元看到的输入区域越大。假设在某个模型中，所有卷积核的尺寸均为3"3，步长(stride)均为1，laver1是输入层，则第二层layer2中每个神经元可看到ayer1上3\*3大小的区域，那么第四层layer4中每个神经元可以看到的layer1上区域是多大? D

1.  4\*4
    
2.  5\*5
    
3.  6\*6
    
4.  7\*7
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0450aa09-ddd9-4b30-a2bb-c250c7eb97e7.png)

### 100、某客户的AI业务上线后，其业务流量曲线显示，每天18点到0点流量都有很大幅度上升，昇腾云服务通过资源共池、多种计费模式等功能，帮助客户进行了灵活的资源配置，降低了50%的资源成本。以上幸例体现的是昇腾云服务的哪一项关键能力?C

1.  立等可取，即开即用
    
2.  集群优化，释放性能
    
3.  全栈优势，高效诊断
    
4.  弹性灵活，按需使用
    
5.  安全可靠，上云无忧
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5690f3ae-1c85-4120-8d77-5e993be96487.png)

### 101、在使用ModelArts开发环境时，云硬盘的存储路径默认挂载在某个目录下，用户在Notebook实例中的所有文件读写操作都是针对该存储目录下的内容操作，该存储目录是如下哪一项?C

1.  /home/work
    
2.  /home/workspce
    
3.  /home/ma-user/work
    
4.  /home/ma-user/workspce
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/3c3842ba-044d-4ef0-ada9-905173673006.png)

### 102.使用benchmark工具对模型进行精度测试时，如果输出了如下信息，那么执行命令时设定了哪个参数?----------------------------------------------------

\------opType avg(ms) percent calledTimess opTotalTime Activation 0.006900 0.002510 100.069000 BiasAdd 0.012800 0.004657 20 0.128000 Comv2D 2.488500 0.905401 20 24.885004 MatMU1 0.137400 0.049991 20 1.374000 Nchw2Nhwc 0.017400 0.006331 20 0.174000 Pooling 0.049400 0.017973 20 0 494000 Reshape 0,.000900 0.000327 10 0.009000 shape 0.002300 0.000837 10 0.023000 SoftMax 0.013300 0.004839 10 0.133000 stack 0.009900 0.003602 10 0.099000 stridedslce 0.009700 0.003529 10 0.097000 total time :2.90800 ms, kernel cost : 2.74851 ms  A

A. timeProfiling

B. operatorProfiling

C. layerProfiling

D. benchmarkProfiling

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/487d20bf-1e72-4294-b48e-86bbd15483fd.png)

### 103.下面哪一项是昇腾AI处理器的计算核心，负责执行矩阵、向量、标量计算密集的算子任务? B（确定）

1.  AI CPU
    
2.  Al Core
    
3.  控制CPU
    
4.  任务调度器
    

### 104.NPU环境下对溢出行为的支持模式分为饱和模式和非饱和模式，其中非饱和模式是和 GPU一致的，在精度对齐阶段推荐将其打开，其打开的配置方式是什么?D（确定）

1.  eXPOrt ASCEND LAUNCH BLOCKING=1
    
2.  export HCCL DETERMINISTIC=TRUE
    
3.  exPOrt NCCL DETERMINISTIC=TRUE
    
4.  eXPOrt INF NAN\_MODE ENABLE=1
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4c3d57ae-7315-4011-b8cd-c16dbde79a04.png)

### 105.客户是一家医院，需要开发一款应用辅助医生进行医学诊断，场景是CT影像，需要识别出其中的病灶区域并测量尺寸。请问以上任务最可能使用的人工智能技术是哪一项? C（确定）

1.  图像分类
    
2.  物体检测
    
3.  图像分割
    
4.  目标跟踪
    

### 106.循环神经网络(RNN)擅长处理类似自然语言语句这样的序列数据，根据输入输出不同它可以有多种不同的结构，如one-to-one，one-t0-many;many-to-one，many-to-many等，那么针对中文命名实体识别任务，应该使用哪种RNN结构? D（？）

1.  one-to-one
    
2.  one-to-many
    
3.  many-to-one
    
4.  many-to-many
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/4aa31974-b772-44a7-a3b0-aff9cdcfaef4.png)

### 107.在ModelArts中使用自定义算法进行模型训练时，如果训练数据集包含大量小文件，整体大小在20G左右，为了提升数据读取效率，推荐的做法是如下哪一项?B（确定）

1.  将训练数据集放在代码OBS日录下，随训练代码一起加载
    
2.  将训练数据集上传至OBS，训练代码中解析输入路径参数，创建算法时配置输入管道，创建训练作业时填写数据集OBS路径
    
3.  将训练数据集在本地压缩成zip文件，上传至OBS，训练代码中使用Moxing接口从OBS下载至训练作业的/cache路径下
    
4.  将训练数据集上传至云硬盘，挂载到训练服务器或集群下![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/17ea0208-1dda-4fd9-a8ee-83217068cb2a.png)
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/18f2b984-06fd-4d92-82dc-b7d4f8b91175.png)

### 108.视频监控任务，客户希望使用工地上部署的摄像头，检测画面中的工人是否佩戴了安全帽;此时我们已经训练好了一个检测模型，客户也搜集了一些测试图片，希望测试一下模型的效果。针对以上场景，建议使用ModelArts的哪一种AI应用部署方式进行测试:A（？）

1.  在线服务
    
2.  离线服务
    
3.  边缘服务
    
4.  批量服务
    

### 109.设置CPU绑核策略的作用是什么? A

1.  指定线程与CPU核绑定，减少切换耗时，优化性能
    
2.  绑定必要核数CPU,空闲CPU分配至性能较差线程，优化卡间不同步性能问题
    
3.  对输出使用CPU进行计算验证，定位算子精度问题
    
4.  线程绑定CPU小核用于下发API，性能较强的CPU大核用于计算复杂问题，优化模型训练性能
    

### 110.以下不属于Megatron-LM分布式并行技术的是哪一项? A

1.  离线并行
    
2.  数据并行
    
3.  张量并行
    
4.  流水线并行
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a52ecef3-7369-48f0-bf36-1e17f6b9f044.png)

### 111.请问以下哪个仓库是异腾提供的大模型解决方案仓库? B

1.  DeepSpeed
    
2.  ModelLink
    
3.  AscendSpeed
    
4.  Megatron-LM
    

[三方应用: https://gitee.com/ascend/ModelLink](https://gitee.com/ascend/ModelLink)

### 112.通过工具定位到疑似有问题的API时，下述处理方案中不正确的是哪项?

1.  进行标杆等价替换(替换为同功能，无精度问题的实现)，观测替换后Loss是否正常
    
2.  等价替换后，若Loss有好转但仍不达标，则说明该API对Loss有影响但不是唯一因素，需要继续排查问题
    
3.  等价替换后，若Loss无变化，说明该API对整网精度没有产生影响
    
4.  如果没有可等价替换的API，则需要使用梯度监控工具进一步监控训练梯度查找问题根因
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b15fe22f-1763-4dbe-a2ed-c4b301288433.png)

### 113.使用Mindspore Lite进行模型推理时，如下哪个接口可以完成模型的加载与编译?D

1.  model.load\_model
    
2.  model.build\_model
    
3.  model.load\_from\_file
    
4.  model.build\_from\_file
    

[三方应用: https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud\_infer/runtime\_distributed\_multicard\_python.html?highlight=%E5%8A%A0%E8%BD%BD](https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/runtime_distributed_multicard_python.html?highlight=%E5%8A%A0%E8%BD%BD)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/81f3d8bc-4676-43c9-a821-57332e2485a6.png)

### 114.关于LLM模型训练过程中loss出现毛刺的现象，以下说法错误的是?   C

1.  可能是数据集中有脏数据
    
2.  可能是Adam优化器处于不稳定状态
    
3.  如果此时刻对应标杆的loss未出现毛刺现象，那么就可以认为是精度问题
    
4.  降低学习率可以在一定程度上缓解毛刺现象，但是缺点是训练时间会拉长
    

### 115.AI编译器中，将计算图中预先可以确定输出值的节点提前计算好，并对计算图进行一些结构简化的操作，这属于哪一种性能优化方法?D

1.  子图调优
    
2.  模型裁剪
    
3.  算子融合
    
4.  常量折叠
    

### 116.进行精度对比时，如果发现出现数据计算的溢出，则如下哪个改动有助于解决问题? C

1.  数据精度由 fp16 ->bf16
    
2.  数据精度由 fp32 ->bf16
    
3.  数据精度由 fp32 ->fp16
    
4.  数据精度由 bf16 ->fp16
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5e0546d1-7b71-4ecb-8862-c5feb810620e.png)

---

## 多选题

---

### 1.msprof命令行工具采集到的timeline数据，包含如下哪几项内容?答案：

A． 应用层数据

B． CANN数据

C． 底层NPU数据

D． 算子可选优化项

解题：

---

### 2.在模型推理性能优化分析中，性能瓶颈主要来自如下哪几项? 答案：

A． Host算子下发

B． Host算子执行

C． Host算子编译

D． Device算子下发

E． Device算子执行

F． Device算子编译

---

### 3.性能调优前，一般需要搜集哪些信息用于性能分析?答案：

A． CANN版本信息

B． Docker版本信息

C． 训练代码框架及版本信息

D． 模型信息及数据集相关信息

---

### 4.常见的浮点数精度类型有哪些? 答案：

A． 单精度浮点数(float32)

B． 双精度浮点数(float64)

C． 半精度浮点数(float16)

D． 压缩浮点数(bfloat16)

---

### 5.在昇腾推理迁移中，以下哪些手段能够提高推理的QPS？ 答案：

A． 使用高性能推理框架，比如vLLM等

B． 使用权重量化手段

C． 使用mindspore\_lite将在线推理转换为离线整图推理

D． 在推理时延满足要求的前提下，增大batch size

---

### 6.关于Ascendspeed仓，下列说法正确的是哪几项?答案：

A．AscendSpeed是基于Megatron-LM仓库做的昇腾适配

B．Ascendspeed是针对华为昇腾设备的大模型加速库

C．使用时，需要在训练脚本前增加import ascendspeed.megatron\_adaptor

D．该仓库早期也包含模型代码、下游任务评测等解决方案内容，目前该部分内容已迁移至Modellink仓库

---

### 7.NPU环境下确定性计算打开的方式是什么?  答案：

A． torch.use deterministic algorithms(True)

B． export HCCL\_DETERMINISTIC=TRUE

C． expOrt NCCL\_DETERMINISTIC=TRUE

D． export INF\_NAN\_MODE\_ENABLE=1

---

### 8.pytorch框架动态图训练，llm类模型可能涉及的并行模式有哪些? 答案：

A． 张量并行

B． 流水线并行

C． 数据并行

D． 专家并行

---

### 9.关于精度问题，以下说法正确的有哪些?答案：

A． 迁移之后的精度校验工作可以采用CPU/GPU作为标杆，前提是在迁移前模型已经在CPU/GPU环境达到预期训练效果

B． 可以通过下游任务评估来检测精度，下游任务验证符合业务需求即可认为精度正常

C． 训练过程loss和标杆loss无法做到完全对齐，只要模型正常收敛就可以认为符合预期

D． 确定性计算是用来辅助精度问题定位的，本身并不属于精度问题

---

### 10.精度问题定位过程中，梯度监控工具的用途主要有下列哪几项? 答案：

A． 检测确定性问题:监控NPU训练过程中的确定性问题

B． dump数据:提取单API的统计量数据

C． 监控梯度差异:监控GPU和NPU训练过程中的梯度差异

D． 精度数据比对:将NPU/CPU/GPU的数据做三方比对

---

### 11.图像分类是计算机视觉领域的基础问题，如下指标中可以用来评测图像分类模型的有哪些? 答案：

A．准确率 accuracy 

B．精确率 precision

C．召回率 recall

D．BLEU 评估机器翻译质量的指标

E．F1-score

---

### 12.LSTM(Long short Term Memory，长短期记忆网络)是一种特殊的循环神经网络(RNN)，通过“门”(gate)结构的设计，更好的控制信息记录。如下关于LSTM结构描述正确的有哪些?答案： 

A． 隐藏门(hidden gate)，决定什么信息需要被忽略 （没有隐藏门这个说法）

B． 输入门(input gate)，决定何时将数据读入单元 

C． 输出门(output gate)，决定从单元中输出的条目

D． 遗忘门(forget gate)，决定什么时候记忆或忽略输入信息

---

### 13.作为ModelArts系列中负责边缘部署和管理的服务，如下功能描述中，属于ModelArts Edge能力范畴的有哪几顶   答案：

A． 支持纳管多种异构算力的边缘设备，方便业务集成与运维

B． 支持进程、容器等多种格式的AI应用部署，方便应用的快速上线

C． 提供端到端的模型生产工具链，AI开发、训练、推理一站式服务

D． 提供多种调度方式，支持边云协同推理，高效利用边缘资源

---

### 14.大模型的训练是一个复杂的工程，因此多家厂商针对PyTorch推出了优化库，加速大模型的分布式训练，这些优化库大部分也有了昇腾适配，可以在昇腾云平台上使用。如下优化库中属于大模型训练分布式加速库的有哪些? 答案：

A． DeepSpeed

B． MMDetection （基于PyTorch 的目标检测开源工具箱）

C． FastText （Facebook研究团队创建的一个库，用于高效计算word representation和执行文本分类，可以在几秒内完成其他算法几天才可以完成的任务）

D． Megatron （基于PyTorch 的分布式训练框架，用来训练基于Transformer 的大型语言模型）

E． Fairseq （开源的深度学习工具库，主要用于自然语言处理任务，包括机器翻译、文本生成、问答等）

---

### 15.ModelArts支持用户将自己在其他环境开发好的模型迁移到平台上进行部署，在创建AI应用时，如下哪些文件必选包含在模型包中?答案：

A． 模型文件，如PyTorch框架的pt文件

B． 模型配置文件，固定为config.json

C． 三方依赖包安装文件，如requirements.txt

D． 模型推理代码文件，固定为customize\_servyice.py

---

### 16.神经网络模型分为训练和推理两套流程，如下关于组件和流程的描述中，属于模型推理流程的有哪些?答案： 

1.  dataset:用于获取数据，包含网络的输入，标签等
    
2.  network:网络模型实现，MindSpore中一般使用Cell包装
    
3.  loss:损失函数，用于衡量预测值与真实值差异的程度
    
4.  optimmizer:优化器，用于计算和更新网络参数
    
5.  metrics:评价指标，用于评估模型的好坏
    

---

### 17.LLM(large language model，大语言模型)兴起后，在各个领域的应用越来越多，受到越来越大的关注，但是LLM的训练是一个复杂的过程，如下关于LLM训练过程的描述正确的有哪些? 答案：

1.  预训练(Pretraining)阶段，模型通过学习大量无标签文本数据来学习语言的基础知识
    
2.  有监督微调(Supervised Finetuning)阶段，模型使用特定任务的标签数据进行训练，以更好地适应真实场景
    
3.  奖励建模(Reward Modeling)阶段，通过人工标注数据学习什么样的生成文本是“好”的文本
    
4.  强化学习(Reinforcement Learming)阶段，利用奖励模型让LLM的行为与人类“对齐“
    

---

### 18.在Transformer架构提出之前，自然语言外理领域使用最多的是各种类型的循环神经网络(RNN)，如下关于RNN与Transformer的描述正确的有哪些?答案： 

1.  虽然有LSTM/GRU等改进形态，但RNN处理长距离依赖的能力仍然不够好
    
2.  Transformer架构可以直接计算序列中任意两个位置之间的关系，使得模型能够有效地捕获长距离依赖信息
    
3.  RNN是时序结构，当前时刻的输入依赖前一时刻的输出，不太适合做并行化
    
4.  Transformer架构可以高效地并行处理整个序列，推理时也可以并行化输出完整的句子
    

---

### 19.在模型迁移前GPU上loss正常收敛，迁移到NPU后loss跑飞，可能的原因有哪些? 答案：

1.  NPU算子实现有bug
    
2.  代码迁移时未正确使用NPU相关API
    
3.  存在计算溢出问题
    
4.  代码迁移时未和GPU版本采用等价的超参设置
    

---

### 20.当使用精度工具定位到某个API计算存在较大偏差时，以下哪些方法是合理的? 答案：

1.  删除该API执行逻辑，再次观察是否还有精度问题
    
2.  将该API使用.cpu()转换到cpu上计算，再次观察是否还有精度问题
    
3.  构造单API用例，并在NPU、CPU或GPU上运行的结果进行对比
    
4.  直接将该API的名称反馈给华为侧定位
    

---

### 21.pytorch框架动态图训练，CV类型小模型例如resnet,mibilenet等存在通信的场景有哪些? 答案：

1.  反向传播过程中对多卡梯度聚合
    
2.  Relu激活函数导致多卡通信   
    
3.  dataloader加载数据时数据分发    ？
    
4.  前向传播过程中syncBatchNorm导致多卡通信
    

---

### 22.pytorch框架训练性能调优，获取到训练的profiling数据后，应该从以下哪些维度展开分析? 答案：

1.  cpu侧任务下发
    
2.  通信
    
3.  计算
    
4.  数据加载
    

---

### 23.使用benchmark工具对Mindspore lite推理模型进行性能基准测试时，会将推理得到的输出与标杆数据进行相似度度量，工具将会输出如下哪几顶度量教据?答案：

1.  平均相对误差
    
2.  最大相对误差
    
3.  余弦相似度
    
4.  相对熵
    

---

### 24.在进行模型精度校验时，如下哪些因素会影响模型在不同平台的实际效果?答案：

1.  算子实现差异
    
2.  设备性能差异
    
3.  设备通信时长
    
4.  数据类型差异
    

---

### 25.ModelArts支持训练模型过程中安装第三方依赖包，其中依赖包安装文件的命名支持以下哪几种格式?  答案：

1.  pip-requirement.txt
    
2.  pip-requirements.txt
    
3.  reguirement.txt
    
4.  reguirements.txt
    

---

### 26.在无标杆性能数据的情况下，可考虑什么方式进行性能调优?答案：

1.  使用权威网站的性能数据作为目标
    
2.  替换NPU亲和api算子
    
3.  尝试使用apex优化库
    
4.  定位ai cpu算子并尝试使能ai core
    

---

### 27.模型迁移完成后进行性能调优时，以下哪些是常用的调优方法?答案：

1.  使能NPU亲和融合API算子与优化器
    
2.  使能二进制编译调优
    
3.  打开确定性计算开关
    
4.  增大模型参数batch size
    

---

### 28.对于迁移前的训练是基于PyTorch+FSDP的场景，推荐采用哪种方式进行迁移?答案：

1.  自行编写训练脚本
    
2.  切换到PyTorch2.1及以上版本
    
3.  使用白动迁移工具进行迁移
    
4.  切换成其他框架
    

---

### 29.使用MindSporeLite转换工具进行模型转换时，如果出现如下报错，可能的原因有哪些？答案：

**WARNING LITE（11979,7fbdc90a8ecOconverter\_lite）:2021-12-13-16:20:49.506.071 \[mindspore/lite/tools/commonyprotobuf\_utilS.CC:94\] ReadProtoFromBinaryFilel Parse \*\*\*.onnx failed**

**\[ERROR LITE（11979,7fbdc90a8ecOconverter\_lite）:2021-12-13-16:20:49.506.122 \[mindspore/lite/build/tools/converter/parser/onnx/onnx\_op\_parser.cc:3079 InitOriginModel Read onnx model file failed model path: /mLaudio\_kit vocals resunet.onnx**

**\[ERROR\] LITE(119797fbdc90a8ecOconverter\_lite）:2021-12-13-16:20:49.506.131 \[mindspore/lite/build/tools/converter/parser/onnx/onnx\_op\_parser.cc:3026\] Parse\] init origin model failed.**

A.存在转换工具不支持的算子

B.转换工具不支持该算子的某种特殊属性或参数

C.模型路径错误

D.模型文件损坏

---

### 30.GPU环境下确定性计算打开的方式是什么?答案： 

A.torch.use\_deterministicalgorithmsTrue）

B.export HCCL DETERMINISTIC=TRUE

C.export NCCL\_DETERMINISTIC=TRUE

D.export INF\_NAN\_MODE\_ENABLE=1

---

### 31.关于PyTorch确定性计算，以下说法正确的是  答案： 

A.当前阶段，并不是所有的NPU和CUDA算子都支持确定性计算

B.开启确定性计算后性能会受到影响，建议只有在定位精度相关问题时再开启确定性计算

C.确定性计算是定位精度问题时首先要考虑并解决的问题

D.在精度问题位程中，确定性计算不是目的，而是手段，部分场景要在确定性计算使能的情况下，进行下一步的精度问题分定位（常稳问题）

---

### 32.pytorch框架动态图训练性能调优，对于CPU侧下发性能瓶颈，有哪些优化手段？答案：

A.使能融合算子API，减少小算子下发

B.可视化profiling，如果发现大量aclopcompile类算子，则使能二进制调优torch.npu.set\_compile\_modejit\_compile=False）

C.排查是否有频繁的张量同步到CPU的操作，如loss.item（），tensor.cpu（）等

D.增大BatchSize

---

### 33.在迁移可行性分析中如果存在平台未支持的算子，可通过下面哪些方式解决?  答案：

A.修改模型脚本，使用等价支持的算子替换

B.将CANN版本降低

C.联系华为工程师提出开发适配诉求

D.参考文档进行算子适配

---

### 34.学习率（learningrate）是机器学习模型训练中的重要超参数，学习率的选取会影响到训练性能和模型效果，如下关于学习率的描述正确的是有哪些？ 答案：

A.如果学习率设置得很小，那么训练将花费更多时间，因为每次移动的步长很小

B.如果学习率设置得很大，那么训练可能不收敛，或在极值附近震荡

C.不建议使用学习率自适应优化算法（如Adam，Adadelta等），模型不容易收敛

D.建议在一个取值范围内周期性地改变学习率，而不是将其设定为固定

---

### 35.MindFormers提供了textgenerator（文本生成）方法，在让用户能够便捷地使用生成类语言模型进行文本生成任务，该方法支持的推理能力有哪些？答案：

A.增量推理

B.Batch推理

C.流式推理

D.分布式推理

---

### 36.PyTorchAdapter使用插件化方式在线对接适配昇腾AI处理器，这样做的优势有哪些? 答案：

A.最大限度的继承GPU在PyTorch上的使用方式，移植的时候，在开发方式和代码复用方便做到最小的改动

B.最大限度的继承PyTorch原生的体系结构，保留框架本身出色的特性

C.使用方便，插件内置在PyTorch安装包中，只需要一次pip安装即可完成

D.扩展性好，对于新增的网络类型或结构，只需相关计算类算子的开发和实现

---

### 37.使用AOE (Ascend Optimization Engine) 进行单模型性能调优后，其输出的json文件主要包含如下哪些信息?   答案：

A. model\_baseline\_performance，表示调优前模型执行时间，单位为ms

B. model performanceimprovemet

C. 表示调优后模型执行时间减少的百分比

D. model\_result\_performance，表示调优后模型执行时间

E. repo\_summary，包含调优过程中使用到的知识库算子个数或者追加到知识库的算子个数

---

### 38.精度对比工具ptdbg的seed\_all接口能够固定哪些随机性?  答案：

A. 固定random模块的随机生成器种子

B. 固定numpy中随机生成器种子

C. 固定torch随机种子

D. 固定数据集dataloader加载顺序

---

### 39.大模型精度对齐场景，往往面临网络规模参数量巨大的限制，以下哪些方法可以缓解上述现象，且能够尽可能不影响原问题的定位? 答案：

A. 只dumpAPI的统计量信息进行对比

B. 减小模型层数

C. 减小输入token的序列长度

D. 减小模型的学习率

---

### 40.进行模型迁移之前，需要做以下哪些工作?   答案：

A. 选取合适的模型，在三方平台运行成功

B. 在昇腾设备上搭建环境

C. 使用迁移分析工具分析模型在昇腾设备上的支持度

D. 在昇腾设备上运行下游任务评测

---

### 41.Transformer架构提出以来，在自然语言处理(NLP)、计算机视觉(CV)等领域都得到了广泛应用，如下模型中有哪些使用了Transtormer架构?   答案：

A. BERT

B. ViT

C. DETR

D. SENet

E. GPT

---

### 42.使用ModelArts的开发环境，创建Notebook实例时需要选择一种A!引擎的镜像，可以选择的镜像类型包括如下哪几项?答案：

A. 预置在ModelArts内部的公共镜像

B. AI Gallery社区发布的镜像

C. 基于公共镜像创建的实例保存下来的自定义镜像

D. 在ECS(Elastic cloud Server)上构建的自定义镜像

---

### 43.使用ModelArts的开发环境进行模型训练时，如果需要将本地12 GB左右的数据集上传到Notebook，如下哪些操作可以实现该功能?  答案：

A. 直接将文件拖拽到Notebook窗口左边的空白处

B. 单击导航栏的Upload Files按钮，打开文件上传界面进行上传

C. 将本地文件上传至OBS桶中，然后使用ModelArts SDK从OBS下载文件至Notebook本地

D. 将本地文件上传至OBS桶中，然后使用Moxing接口从OBS下载文件至Notebook本地

---

### 44.算子融合是一种常见的模型优化方法，将多个算子融合为一个算子，可以减少内存访问和计算的开销，如下选项中哪些是常见的算子融合操作?答案：

A. conv + relu

B. conv + bn

C. conv + bn + relu

D. bias add + layer norm

E. gemm + elementwise

---

### 45.在PyTorchGPU训练迁移到NPU训练的迁移环境搭建中，需要环境具备如下哪些内容?答案：

A. 昇腾驱动、固件

B. CANN

C. PyTorch

D. 昇腾适配的PyTorch NPU

---

### 46.目前已知的不支持的迁移场景包括以下哪几项?答案：

A. Ascend Extension for PyTorch (即 torch-npu)1.11.0版本不支持单进程多卡； Ascend Extension for PyTorch(即 torch-npu))2.1.0及以上版本支持单进程多卡

B. 不支持使用DP(distributed parallel)模式的模型迁移，需要手动改为DDP接口

C. 不支持cuda接口自动迁移至npu接口

D. 不支持NCCL相关代码自动迁移至HCCL

---

### 47.以下哪些选项属于精度偏差的来源?答案：

A. 算子计算BUG

B. 算法迁移适配不当

C. 确定性计算未开启

D. 硬件差异，芯片架构差异

---

### 48.Ascend Insight是一款主要针对大模型集群场景的调优可视化工具。它支持的平台有哪些?答案：

A. windows

B. linux

C. mac

D. ModelArts

---

### 49.在进行模型迁移前，需要保证选定的模型能在已有的AI硬件上正常运行，并输出哪些方面的测试基线?答案：（？）

A. 精度

B. 功耗

C. 性能

D. 内存占用率

---

### 50.以下哪些现象代表大模型可能存在精度问题?答案：

A. 训练Loss上扬不收敛

B. 训练Loss值出现INF/NAN等异常值

C. 推理结果不正确

D. 推理响应速度很慢

---

### 51.卷积神经网络(CNN)发展过程中，研究者提出过很多经典的模型，如下关于各个模型描述正确的有哪些?答案：

A. VGGNet使用连续的3\*3卷积核替代大卷积核，通过增加网络深度提高网络学习能力

B. GoogLeNet中使用了1\*1卷积核，增加非线性特征的同时又可以达到降维的效果

C. ResNet提出的残差结构，很好的解决了深度网络的退化问题，使得网络可以通过加深提高准确率

D. DenseNet使用SE(Sequeeze-and-Excitation)模块学习不同通道之间的依赖关系，提高了模型的表现能力

---

### 52.以下哪些指标是精度对齐时需要关注的?答案：

A. loss值

B. grad norm值

C. 初始学习率

D. batch size

---

### 53.通用模型迁移适配过程可以分为哪几个阶段?答案：

A. 迁移分析

B. 迁移适配

C. 精度调试

D. 性能调优

---

### 54.开发者想在昇腾云服务上使用深度学习框架进行模型训练和推理，如下哪些框架可以满足需求?答案：

A. MindSpore

B. PyTorch

C. Caffe

D. TensorFlow

---

### 55.基于昇腾芯片的集合通信HCCL(Huawei Collective Communication Library)，支持的通信操作包括哪些?答案：

A. AllReduce

B. AllGather

C. broadcast

D. ReduceScatter

---

### 56.在性能调优过程中，通过分析采集profiling数据的timeline发现free time呈现少次大块的特征，在以下原因中可能导致该情况的是哪些项?答案：

A. 机器中其他程序抢占CPU资源

B. 橙型正在等待数据集加载

C. 集群多节点机器读写日志导致频繁抢占I0资源

D. 在与其他卡进行卡间通信

---

### 57.客户是一家手机厂商，需要实现智能相册系统，对相册中的图片按照人物、地点、场景等进行分类归档，并且支持使用自然语言搜索图片，如“公园放风筝”、“巴黎旅游”。请问以上任务可能会涉及哪些人工智能技术?答案：

A. 情感分析

B. 人脸识别

C. 图像描还生成

D. 多标签分类

E. 视频动作分类

---

### 58.模型训练时，在ModelArts管理控制台可以査看资源利用率，如果发现GPU/NPU的平均利用率较低，如下做法中哪些可以提升计算单元利用率?答案：

A. 适当增大算法的batch size超参数

B. 提升数据读取效率、数据增强性能

C. 控制模型保存的频率

D. 尽呈减少日志打印的频率

---

### 59.目前在AI社区里，很多厂商都发布了开源LM(large language model，大语言模型)，这些模型通常分为两种类别:base模型、chat模型，关于这两类模型的描述正确的有哪些?答案：

A. base模型一般只经历了预训练阶段，使用海呈无标签的文本数据进行了无监督学

B. base模型更适合文本补全等基础任务，具有更强的泛化能力

C. chat模型在base模型基础上，X经历了有监督微调等阶段，更适合多轮对话任务

D. 如果需要应用到特定领域的下游任务，且拥有大星的有标签数据，更建议在chat模型上做微调

---

### 60.如果迁移前发现昇腾机器上的固件驱动版本过老，需要重新安装，以下说法正确的是哪几项?答案：

A. 固件安装完后需要reboot重启机器才能生效

B. 安装驱动的命令为./Ascend-hdk-型号-npu-driver\_版本号\_linux-aarch64.run --full --install-for-all

C. 覆盖安装的场景下，安装顺序应该为先固件再驱动的顺序

D. 安装固件的命令为./Ascend-hdk-型号-npu-firmware 版本号.run --full

---

### 61.下列哪些手段可能消除AICPU算子?答案：

A. 尝试修改对应代码，通过矩阵计算的方式重写代码逻辑

B. 修改输入数据的dtype

C. 尝试升级cann包

D. 升级pytorch版本

---

### 62.昇腾大模型精度定位常用的手段有哪些?答案：

A. 减小模型层数

B. 减小集群节点

C. 关闭大kernel融合算子

D. 减小TP切分策略

---

### 63.在迁移到昇腾后以及在昇腾调测模型时的精度对齐中，通常需要与标杆实现进行精度结果比对，以下哪些是常用的标杆内容?答案：

A. CPU

B. GPU

C. 融合算子的小算子实现

D. 历史已有的正常的NPU结果

---

### 64.如下哪些工具可以将其他框架的模型转换为可在异腾设备上运行的模型? 答案：

A. Tailor

B. converter lite

C. ONNX-PTO

D. Transfer2NPU

---

### 65.迁移分析工具PyTorch Analyse支持哪几项内容的分析?答案：

A. 算子支持情况分析

B. 精度分析

C. 动态shape分析

D. 三方库API支持情况分析

---

### 66.pytorch框架动态图训练性能调优时，对于算子计算性能存在劣化的情况，开发者可以自行尝试哪些优化手段?答案：

A. AOE调优

B. 消除AICPU算子

C. 尝试升级CANN包

D. 增大batchsize

---

### 67.pytorch框架训练性能调优，基于Ascendlnsight可视化Profiling数据后发现CPU侧dataloader任务耗时占比很高，可能的优化手段有哪些?答案：

A. 排查数据所在磁盘是否存在I〇瓶颈

B. 设置pin\_memory=True参数

C. 调整num workers参数

D. 检查数据格式，避免使用zip， targz等数据格式，提前解压数据

---

### 68.如果使能精度对比工具后模型精度异常现象消失，说明该型的精度异常的原因可能是什么?答案：

A. 可能是模型训练时使用了drouout，且不等于零

B. 可能是算子下发的时序问题或者内存踩踏问题

C. 可能是模型训练的算子的确定性计算存在问题，导致精度异常

D. 可能是模型的算子存在累积偏差

---

### 69.在神经网络训练过程中，如果损失函数(loss function)出现NaN，那么可能的原因和解决方法有哪些?答案：

A. 可能是学习率(learning rate)设置过高，需要降低

B. 可能是计算过程中用0作为了除数，需要排查

C. 可能是因为梯度爆炸的原因，可以使用梯度裁剪(gradient cipping)来解决

D. 可能是batch size设置得过大，可以调小一些试试

E. 可能涉及指数运算并得到无穷(INF)值，如softmax中在计算exp(x)末做特殊处理

---

### 70.如下描述中，哪一项不属于CANN中AIPP(Al Pre-Processing)算子库的功能?答案：

A. 图像编解码

B. 图像尺寸变化

C. 图像色域转换

D. 图像数据归一化

---

### 71.调优工具AKG(Auto Kernel Generator)主要由如下哪几个优化模块组成？答案：

A. 规范化，主要包括自动运算符inline、自动循环融合和公共子表达式优化等。

B. 自动调度，主要包括自动向量化、自动切分、依赖分析和数据搬移等。

C. 前端优化，主要包括常量折叠、算子自动融合、循环重排序等。

D. 后端优化，主要包括Tensorcore使能、双缓冲区、内存展开和同步指令插入等

---

### 72.在将模型从其他三方平台迁移到昇腾时，涉及到一系列底层到上层的适配操作。模型迁移至昇腾需要适配的原因主要为哪些方面?答案：

A. 硬件实现差异

B. 计算架构差异

C. 模型来源差异

D. 深度学习框架差异，为了支持NPU硬件需要对PyTorch框架进行适配

---

### 73.关于ModelArts提供的昇腾迁移环境，以下说法正确的是哪几项?答案：

A. ModelArts提供了配套昇腾硬件环境的基础容器镜像

B. 在昇腾环境上启动容器镜像时，可以使用ASCEND\_VISIBLE DEVICES指定容器要使用的卡号

C. 容器内无法查看昇腾卡信息，宿主机上可以查看卡信息

D. ModelArts基础镜像内的PyTorch/MindSpore等AI框架包均安装在Conda环境内

---

### 74.昇腾NPU包含成千上万个计算核心，适合逻辑简单且计算密集型高并发任务，如下场景中哪些适合使用NPU? 答案：

A. 人脸识别模型训练

B. 普通办公应用

C. 数据库应用

D. 大语言模型推理

---

### 75.假设我们训练好的一个机器学习模型，它在训练集、验证集、测过集上的错误率分别为30%、30%、30%，产生这种现象的原因可能有哪些? 答案：

A. 训练数据太复杂

B. 训练数据量太大

C. 模型复杂度低，表达能力弱

D. 模型复杂度高，表达能力强

---

### 76.通常导致存在AICPU算子的原因是哪些?答案：

A. 昇腾计算芯片AICORE不支持该算子

B. 输入数据的dtype导致，如float32

C. 输入数据的shape导致

D. pytorch版本过低导致

---

### 77.模型推理业务昇腾迁移前的迁移评估，主要包含哪些工作?答案：

A. 算子支持度评估

B. 框架支持度评估

C. 三方依赖库支持度评估

D. 业务改造评估

E. 性能基线分析

---

### 78.精度对比工具ptdbg支持以下哪些API dump模式?答案：

A. dump全量的API及堆栈信息

B. dump指定列表中的API和堆栈信息

C. dump指定某一类的API和堆栈信息

D. 只dump堆栈信息，不dump API的数据

---

# 修订前原版对比（如下）

# 题目一（张海）

## 判断题

++1.性能优化的总体原则为:减少Device算子下发时间、减少Host算子执行时间。++**F****（确定）**

[三方应用: https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_2506.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2506.html)

![6f3a9f09fd2175cdb9edf5651dcb1ba0.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/be9ce9c7-cebe-4e5a-b760-94081bf125d6.png)

**由上图红线标识可知，优化原则和判断题的说法不一致。**

++2.模型迁移所用的Tailor工具，是一个算子自动调优工具。++**F****（确定）**

[三方应用: https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_0166.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_0166.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/6bb60823-f50f-467e-a9ac-9fa3b9c85f31.png)

[三方应用: https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_1165.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_1165.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/fb8b02a0-5d78-4272-b527-ff68fdc30eb1.png)

3.++昇腾HCCL数据并行策略支持DDP模式和DP模式。++T（确定）

[三方应用: https://www.hiascend.com/document/detail/zh/canncommercial/80RC2/developmentguide/hccl/hcclug/hcclug\_000001.html](https://www.hiascend.com/document/detail/zh/canncommercial/80RC2/developmentguide/hccl/hcclug/hcclug_000001.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/38eb8d66-78b2-46ff-9eb6-362ba937965b.png)

DP（Data Parallel）：在单机上使用多个GPU进行模型训练。（单机多卡）

DDP（Distributed Data Parallel）：在多台机器上使用多个GPU进行模型训练。（多机多卡）

4.Profiling数据采集可使用Ascend PyTorch Profiler，当采集数据量过大时，算子调用栈默认开启。（?）

[三方应用: https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug\_000068.html](https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000068.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/071d40d5-58ba-4646-8a0b-22d28823318b.png)

5.Ptdbg工具提供了模块级dump功能。T（确定）

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC1alpha001/devguide/moddevg/ptmigr/AImpug\_0034.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC1alpha001/devguide/moddevg/ptmigr/AImpug_0034.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/75534aec-322f-4edd-8bc5-a58706f36b66.png)

6.模型的超参大致可以分为学习率，batch-size，并行切分策略，学习率warm-up，模型参数，FA配置等，用户在行NPU精度和GPU精度比对前，需要保证两边的配置一致。T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b398064f-5037-4a55-bce1-4d0bf4b1bc43.png)

7.MA-Advisor是一款迁移辅助工具，提供了profiling分析并给出专家调优建议，包含调度性能分析、AICPU调优、亲和api替换建议等功能。（F）调度性能分析？

[三方应用: https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_2514.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2514.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/155e93fa-dfd0-4817-bfde-b1544aeb3c63.png)

8.分布式训练的本质是解决单设备内存不足或者单个设备计算能力不足问题。T（确定）

9.集合通信中AllReduce操作是将多个线程的数据聚合再分发到每一个节点，但每个节点数据不会相同。F（确定）

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclpython\_07\_0018.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclpython_07_0018.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c0855896-fa90-4fa3-95fd-03aba0c21c5f.png)

10.在fp16混合精度训练场景下，如果Loss scale在连续的50个step没有持续降低，这种情况可以判定为正常溢出。F（确定）

11.单层感知机只能处理线性数据，为了解决非线性分类问题，我们可以使用多层感知机，在输入层和输出层之间多加一些隐藏层。**多层感知机中添加的隐藏层数越多，整个网络的分类能力就越强**，可以提取的目标特征层次也越高  F（确定）

12.神经网络中如果不使用激活函数(activation function)，那么每一层节点的输入都是上层输出的线性函数，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，网络的表达能力就相当有限。因此，引入非线性激活函数主要就是为了添加非线性因素，增强深层神经网络的表达能力。T（确定）

13.Transformer架构非常适合处理文本数据，在自然语言处理领域得到了广泛应用，但无法应用在计算机视觉领域，卷积神经网络仍然是计算机视觉的必然选择。F（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0ccc0ea8-510d-490e-aa74-c9780341942a.png)

14.ModelArts不支持跨站点访问OBS桶，通过OBS下载文件到Notebook中时，请确保读取的OBS桶和Notebook处于同一站点区域。F（确定）

15.MindFormers支持ChatGLM、Llama、Baichuan、Qwen等热门的大模型系列，支持文本生成、问答、翻译、文本掩码等文本型的任务，当前还不支持如图像分割类的图像任务。T（？）

[三方应用: https://mindformers.readthedocs.io/zh-cn/r1.2.0/docs/model\_support\_list.html#translation](https://mindformers.readthedocs.io/zh-cn/r1.2.0/docs/model_support_list.html#translation)

## 单选题

1.对于动态分档场景，converter\_lite最多支持多少档?D（确定）

A．20

B．50

C．80

D．100

[MindSpore](https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/converter_tool_ascend.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/01a41b46-4dd9-43b2-98a0-f2a94443b210.png)

2.模型转换工县converter \_lite支持将ONNX模型转换为MindIR模型，转换时需要指定模型的inputShape信息，假设模型有2个输入，节点名称分别为node1/node2，shape分别为(2,1024)/(2,32,256)，则inputShape参数的值应该为如下哪一项      B

A． node1 2,1024/node2 2,32,256

B． node1:2,1024;node2:2,32,256

C． node1 (2,1024);node2 (2,32,256)

D． node1:(2,1024)/node2:(2,32,256)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/99f7801c-b6a9-4717-aa94-e5bda94fb497.png)

3.执行convert\_onnx\_to\_mindir.sh进行模型转换时，转换后，除了生成.mindir模型外，还生成了以下哪种模型?  D(?)

A．.pt模型

B．.pb模型

C．.pth模型

D．.om模型

实操3 - Stable Difffusion 昇腾模型推理运行中提到：转换成功后将会在./mindir文件夹下得到对应的.mindir模型，其中同名的.om模型是为了备份和调试使用，可以忽略。

4.使用benchmark工具对模型进行精度测试时，二进制输入数据通过哪个参数设置? B（确定）

A． inData

B． inDataFile

C． benchmarkData

D． benchmarkDataFile

[https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud\_infer/benchmark\_tool.html?highlight=%E6%B5%8B%E8%AF%95](https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/benchmark_tool.html?highlight=%E6%B5%8B%E8%AF%95)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5a270ba9-5eb6-4d66-9a87-9756389aa9c1.png)

5.以下哪项不是常见的集合通信库实现? D（确定）

A． OpenMPI & MPICH

B． NCCL

C． Gloo

D． cuDNN

cuDNN是深度学习加速库

6.以下关于数据并行说法错误的是哪项? B（确定）

A． 数据并行是指将一个进程或一张卡上无法处理的大量数据拆分为多组数据，在多个进程或多张卡上同时进行计算

B． 数据并行时各rank拥有不同的模型参数

C． 各卡上独立完成前向传播和反向传播得到梯度

D． 通过聚合再下发AllReduce操作将各卡的梯度进行平均并同步，各卡更新模型参数

7.使用Ascend PyTorch Profiler接口开启PyTorch训练时的性能数据采集，采集CANN软件栈及NPU数据的activities是什么? B（确定）

A． torch\_npu.profiler.ProfilerActivity.CPU

B． torch\_npu.profiler.ProfilerActivity.NPU

C． torch.profiler.ProfilerActivity.CPU

D． torch.profiler.ProfilerActivity.NPU

[https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/devaids/auxiliarydevtool/atlasprofiling\_16\_0037.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/devaids/auxiliarydevtool/atlasprofiling_16_0037.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d733c0f9-b025-42f8-adae-ffc488468bb3.png)

8.以下不属于PyTorch原生分布式训练框架的是哪一项? D

A．nn.DataParallel (DP)

B．nn.parallel.DistributedDataParallel (DDP)

C．Fully Sharded Data Parallel (FSDP)

D．Pipeline Parallel

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/74ffcf28-45b9-4a77-828a-c97f626486c8.png)

9.定位如千卡大集群场景的偶现性能问题时，为了减少需要分析的数据量，如下操作中应当首先尝试进行的是哪项

            A（？）

A． 在小集群或单节点上复现性能问题

B． 采集性能异常场景大集群全量性能数据进行分析

C． 将数据集、日志等文件转移到节点本地，日志等文件保存在本地，排除网络IO性能问题

D． 采集性能正常场景的大集群全量性能数据作为对比

10.在开启确定性计算后，NPU多次训练的Loss保持一致，但是在长稳的训练过程中，和GPU的Loss存在差异并且慢慢扩大，甚至出现Loss上扬等严重问题，以下哪项**不是**正确的排查思路和操作? D

A． 由于已经开启了确定性计算开关，数据存在差异不再是问题，而只有到数据存在较大差异时才被判定为问题。因此高灵敏的md5不再适用，需要记录原始数据进行后续的差异分析

B． 此时的监控对象从模型的权重，转变为了每次迭代步的权重梯度

C． 使用梯度监控工具监控GPU和NPU训练过程中的梯度方向差异

D． 使用ptdbg工具dump从训练开始到loss出现明显异常的数据

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e028e1e5-6479-45c6-a2cf-7ded5370cdf9.png)

11.以下关于精度预检工具的说法错误的是哪项?A

A． 支持随机生成输入和真实数据输入两种方式

B． 可以获取整网中每个API的输入数据的shape、dtype、数值分布等信息

C． 获取的数据会存在累积误差

D． 支持标杆比对法进行精度比对

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/3e8f3be8-c979-4353-a576-14ee8d373996.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d784732a-6be0-45b4-952c-aa92f96f3719.png)

12.以下关于集合通信原语说法错误的是哪项? B

A． broadcast是一对多操作

B． scatter是多对多操作

C． gather是多对一操作

D． ReduceScatter是多对多操作

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/eac607e2-f45c-4c3a-9dc6-028b3d933b1a.png)

13.在精度定位过程中，如果通过大量的实验后发现偏差是算法稳定性层面或者累积偏差导致的，算子的精度都是达标的，应该如何处理?    B（？）

A． 只要未达到客户合同要求的精度偏差指标，就继续投入分析

B． 分析偏差扩散的路径是否合理，并同时测试下游任务，通过下游任务得分和理论分析过程和客户解析原因

C． loss是反应模型精度最真实的指标，至少应该保证loss收敛后的值满足偏差指标才能认为精度达标

D． 以上都不对

14.假设我们已经有一个已经训练好的汽车分类模型，所用的大规模数据集来自专业网站上的汽车图片，包含上千种车型，均为静止状态下的高清图片。现在需要解决的场景也是汽车分类问题，但针对的是高速路上摄像头抓拍到的汽车图片，训练教据较少，但需要识别的车型类别少目均包含在之前模型的类别中，那么如下做法中比较合理的是哪一项?   D(?)

A． 使用新的训练数据集重新训练一个新的模型

B． 因为任务完全覆盖，可以直接使用已有模型

C． 在已有模型基础上使用新数据集继续训练

D． 使用新数据集对已有模型的最后几层进行微调

15.卷积神经网络(CNN)发展过程中，出现了很多各具特色的模型，其中AlexNet的问世可谓是石破天惊，在2012年lmageNet竞赛中以绝对优势一举夺冠，使得全球范围内掀起了一波深度学习热潮，如下关于这一经典模型的描述中错误的是那一项? A

A． AlexNet使用SE(Sequeeze-and-Excitation)模块学习不同通道之间的依赖关系，以提高模型的表现能力

B． AlexNet使用dropout技术在训练过程中随机失活一部分神经元，以避免模型过拟合

C． AlexNet使用ReLU代替传统的Sigmoid激活函数，训练速度更快

D． AlexNet使用局部响应归一化(Local Response Normalization，LRN)，以提高模型泛化能力

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b53b0659-9587-4fd0-b18b-53b7e3da5886.png)

16.循环神经网络(RNN)擅于处理序列数据，但是当序列长度过长时，普通的RNN模型会有长距离依赖(long-tenn dependencies)问题，即相关信息的间隔较大，RNN很难建模它们的关联性。针对这种长距离依赖问题，如下模型结构中不建议选择的是哪一项? D

A． LSTM (Long Short Term Memory)

B． GRU (Gate Recurrent Unit)

C． Transformer架构的模型

D． 含有残差(residual)结构的卷积神经网络 （只是可以解决梯度消失问题，不适合长距离依赖）

17.如下示例代码展示的是哪一种编程范式:class Network(nn.Module): def init(self): super().\_init\_\_()self.linear= nn.Linear(10,20)def forward (self, inputs): return self.linear(inputs)net = Network()outputs = net(torch.randn(2, 10)) A

A． 面向对象编程

B． 面向过程编程

C． 函数式编程

D． 声明式编程

18.MoXing是ModelArts自研的框架，提供了一套文件对象API，可以用来读写OBS文件，如果想要下载一个0BS文件夹sub\_dir 0到Notebook，如下哪个操作可以实现? B

A． mox.file.copy('obs://path\_of\_obs/sub\_dir\_0', 'path of notebook/sub\_ dir\_0)

B． mox.file.copy\_parallel('obs://path\_of\_obs/sub\_dir\_0', 'path\_of\_notebook/sub\_dir\_0')

C． mox.file.copy('path\_of\_notebook/sub\_dir\_0', 'obs://path\_of\_obs/sub\_dir\_0')

D． mox.file.copy\_parallel('path of notebook/sub\_dir 0', 'obs://path \_of obs/sub \_dir\_0')

19.如果用户想要快速的体验不同AI领域的大模型推理流程，可以使用MindFormers的哪一项功能接口? A

A． Pipeline

B． Trainer

C． AutoClass

D． inference

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/1df909b4-c645-4ec5-b388-bb2a83e9d926.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/7d2f1b74-738e-4711-a03c-d5594d0a9ebb.png)

20.昇腾云支持多种资源形态对外提供算力，如下场景描述的是哪种形态:面向云主机资源型用户，基于BMS(Bare Metal server，裸金属服务器)进行封装，并预装主流AI开发套件，兼容社区Open Stack原生接口     A

A． ModeArts Lite DevServer

B． ModelArts Lite k8s Cluster

C． ModelArts Standard

D． ModelArts Edge

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/3c1d5e69-51ea-491c-8643-cb2828de3f04.png)

## 多选题

1.msprof命令行工具采集到的timeline数据，包含如下哪几项内容?ABC

A． 应用层数据

B． CANN数据

C． 底层NPU数据

D． 算子可选优化项

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/3f3c230b-e139-459d-8571-6933952cfe80.png)

2.在模型推理性能优化分析中，性能瓶颈主要来自如下哪几项? AE  F ??

A． Host算子下发

B． Host算子执行

C． Host算子编译

D． Device算子下发

E． Device算子执行

F． Device算子编译

3.性能调优前，一般需要搜集哪些信息用于性能分析?

A． CANN版本信息

B． Docker版本信息

C． 训练代码框架及版本信息

D． 模型信息及数据集相关信息

4.常见的浮点数精度类型有哪些? ABCD

A． 单精度浮点数(float32)

B． 双精度浮点数(float64)

C． 半精度浮点数(float16)

D． 压缩浮点数(bfloat16)

5.在昇腾推理迁移中，以下哪些手段能够提高推理的QPS？ ABCD

A． 使用高性能推理框架，比如vLLM等

B． 使用权重量化手段

C． 使用mindspore\_lite将在线推理转换为离线整图推理

D． 在推理时延满足要求的前提下，增大batch size

6.关于Ascendspeed仓，下列说法正确的是哪几项?ABCD（？）

A．AscendSpeed是基于Megatron-LM仓库做的昇腾适配

B．Ascendspeed是针对华为昇腾设备的大模型加速库

C．使用时，需要在训练脚本前增加import ascendspeed.megatron\_adaptor

D．该仓库早期也包含模型代码、下游任务评测等解决方案内容，目前该部分内容已迁移至Modellink仓库

7.NPU环境下确定性计算打开的方式是什么?  C

A． torch.use deterministic algorithms(True)

B． export HCCL\_DETERMINISTIC=TRUE

C． expOrt NCCL\_DETERMINISTIC=TRUE

D． export INF\_NAN\_MODE\_ENABLE=1

8.pytorch框架动态图训练，llm类模型可能涉及的并行模式有哪些? ABC ??

A． 张量并行

B． 流水线并行

C． 数据并行

D． 专家并行

[三方应用: https://blog.csdn.net/weixin\_44986037/article/details/139017206](https://blog.csdn.net/weixin_44986037/article/details/139017206)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/9f1847c9-ec03-47f9-9afa-2efbe8743962.png)

9.关于精度问题，以下说法正确的有哪些?ABCD（？）

A． 迁移之后的精度校验工作可以采用CPU/GPU作为标杆，前提是在迁移前模型已经在CPU/GPU环境达到预期训练效果

B． 可以通过下游任务评估来检测精度，下游任务验证符合业务需求即可认为精度正常

C． 训练过程loss和标杆loss无法做到完全对齐，只要模型正常收敛就可以认为符合预期

D． 确定性计算是用来辅助精度问题定位的，本身并不属于精度问题

10.精度问题定位过程中，梯度监控工具的用途主要有下列哪几项? AC

A． 检测确定性问题:监控NPU训练过程中的确定性问题

B． dump数据:提取单API的统计量数据

C． 监控梯度差异:监控GPU和NPU训练过程中的梯度差异

D． 精度数据比对:将NPU/CPU/GPU的数据做三方比对

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/af196812-9a73-4c0b-b5ac-4f665d230f09.png)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e182314b-d60b-4ab2-812d-9803f4260a78.png)

11.图像分类是计算机视觉领域的基础问题，如下指标中可以用来评测图像分类模型的有哪些? ABCE

A．准确率 accuracy 

B．精确率 precision

C．召回率 recall

D．BLEU 评估机器翻译质量的指标

E．F1-score

12.LSTM(Long short Term Memory，长短期记忆网络)是一种特殊的循环神经网络(RNN)，通过“门”(gate)结构的设计，更好的控制信息记录。如下关于LSTM结构描述正确的有哪些? BCD

A． 隐藏门(hidden gate)，决定什么信息需要被忽略 （没有隐藏门这个说法）

B． 输入门(input gate)，决定何时将数据读入单元 

C． 输出门(output gate)，决定从单元中输出的条目

D． 遗忘门(forget gate)，决定什么时候记忆或忽略输入信息

13.作为ModelArts系列中负责边缘部署和管理的服务，如下功能描述中，属于ModelArts Edge能力范畴的有哪几顶   ABD

A． 支持纳管多种异构算力的边缘设备，方便业务集成与运维

B． 支持进程、容器等多种格式的AI应用部署，方便应用的快速上线

C． 提供端到端的模型生产工具链，AI开发、训练、推理一站式服务

D． 提供多种调度方式，支持边云协同推理，高效利用边缘资源

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/947c747b-3481-4241-af83-ec661ce6786b.png)

14.大模型的训练是一个复杂的工程，因此多家厂商针对PyTorch推出了优化库，加速大模型的分布式训练，这些优化库大部分也有了昇腾适配，可以在昇腾云平台上使用。如下优化库中属于大模型训练分布式加速库的有哪些? AD

A． DeepSpeed

B． MMDetection （基于PyTorch 的目标检测开源工具箱）

C． FastText （Facebook研究团队创建的一个库，用于高效计算word representation和执行文本分类，可以在几秒内完成其他算法几天才可以完成的任务）

D． Megatron （基于PyTorch 的分布式训练框架，用来训练基于Transformer 的大型语言模型）

E． Fairseq （开源的深度学习工具库，主要用于自然语言处理任务，包括机器翻译、文本生成、问答等）

15.ModelArts支持用户将自己在其他环境开发好的模型迁移到平台上进行部署，在创建AI应用时，如下哪些文件必选包含在模型包中?ABD

A． 模型文件，如PyTorch框架的pt文件

B． 模型配置文件，固定为config.json

C． 三方依赖包安装文件，如requirements.txt

D． 模型推理代码文件，固定为customize\_servyice.py

# 题目二（马善）

## 判断题

1.converter lite是Mindspore Lite提供离线转换模型工具，目前支持的输入模型类型有:Mindspore、TensorFlow Lite、Caffe、TensolFlow、PaddlePaddle、ONNX和PyTorch. F

2.使用benchmark工具进行模型性能测试时，不需要设定输入数据，也不需要设置基准数据 F

3.Deepspeed分布式训练加速工具，实现了内存优化算法，最新版本DeepSpeed可以直接在Atlas 800T A2 昇腾设备上使用，无需deepspeed\_npu插件。 T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/6bff5e6d-db3a-4922-963d-0ad69c8605de.png)

4.Ascend Insight提供适配昇腾平台的框架Profiing可视化呈现，可根据Memory折线图找峰值拐点附近区域的算子明细分析算子内存占用。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/45521d7f-206d-48e2-bd67-2baf1880d2cd.png)

5.PyTorch Adapter支持通过pip方式安装下载后的whl包. T

7.性能问题通常出现在算子下发和执行的异步过程中，因此性能优化的总体原则为:减少Host算子下发时间和减少Device算子执行时间。T

8.在确定性计算中，任何微小的差异都是不符合预期的，都应该被视作问题，F

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/ffde8913-07bd-4c0f-aeaf-3960c8c27959.png)

确定性计算，微小的差异不符合预期，但是只有较大的差异才应该被视作问题。

9.MA-Advisor是一款迁移辅助工具，提供了profiling分析并给出专家调优建议，包含调度性能分析、AICPU调优、亲和api替换建议等功能。（F）调度性能分析？

[三方应用: https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_2514.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2514.html)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/070df939-ebc2-4b16-b7ac-ed65822e41d5.png)

10.使用api\_precision\_compare比对的结果中，某API最大绝对误差<0.001,余弦相似度=0.95，该API精度不达标

F（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/017436d8-df5c-45e1-9105-10e7c4a72228.png)

11.在机器学习中，过拟合与欠拟合都是需要避免的现象，其中过拟合指的是在训练集和测试集上的性能都较差，而欠拟合往往能较好地学习训练集数据的性质，但在测试集上的性能较差。F

12.Transformer架构非常适合处理文本数据，在自然语言处理领域得到了广泛应用，但无法应用在计算机视觉领域，卷积神经网络仍然是计算机视觉的必然选择。F（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e53eb8d6-7865-4034-b5eb-fa99f63186b6.png)

13.单层感知机只能处理线性数据，为了解决非线性分类问题，我们可以使用多层感知机，在输入层和输出层之间多加一些隐藏层。多层感知机中添加的隐藏层数越多，整个网络的分类能力就越强，可以提取的目标特征层次也越高。F（确定）

14.ModelArts不支持跨站点访问OBS桶，通过0BS下载文件到Notebook中时，请确保读取的OBS桶和Notebook处于同一站点区域。T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/e5c6a4a3-267b-43ab-a4de-ca74557947ca.png)

15.Mindformers支持ChatGLM、Llama、Baichuan、Qwen等热门的大模型系列，支持文本生成、问答、翻译、文本掩码等文本型的任务，当前还不支持如图像分割类的图像任务。T（？）

[三方应用: https://mindformers.readthedocs.io/zh-cn/r1.2.0/docs/model\_support\_list.html#translation](https://mindformers.readthedocs.io/zh-cn/r1.2.0/docs/model_support_list.html#translation)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/7a3d0f9b-674d-49a4-82e8-0e83c55a619d.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/504ea873-e357-4c21-b97a-9669b891d585.png)

## 单选题

1.给定网络模型，构建包含自动调优策略生成、编译、运行环境验证的闭环反馈机制，利用AI算法在机器上不断迭代，最终得到最优的策略结果井将其写入知识库，从而达到在有限硬件资源上不断提升网络性能的效果。以上功能描述的是哪一款模型调优工具? B

1.  MA Advisor
    
2.  AOE(Ascend Optimization Engine)
    
3.  AKG (Auto Kernel Generator)
    
4.  Tailor
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d0b8b357-0baa-4082-a919-0937363e5cd5.png)

[https://www.hiascend.com/document/detail/zh/canncommercial/63RC2/devtools/auxiliarydevtool/aoe\_16\_001.html](https://www.hiascend.com/document/detail/zh/canncommercial/63RC2/devtools/auxiliarydevtool/aoe_16_001.html)

2.AOE(Ascend Optimization Engine)模型调优过程中，根据数据切分等价原理自动搜索生成计算图的切分策略，通过切分算子来减少数据量，提升模型计算的性能，这属于哪一种性能优化方法? A

1.  子图调优
    
2.  模型裁剪
    
3.  算子调优
    
4.  算子切分
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/9c01a294-e323-42b3-bdf8-225f285bf060.png)

3.使用Mindspore Lite的predict接口进行模型推理，如果output的内容在显存中，可以通过如下哪个方法将数据读取到内存中使用?A（确定）

1.  output.get data to numpy()
    
2.  output.to('cpu')
    
3.  output.move to cpu()
    
4.  output.set('cpu')
    

原因：MindSpore Lite的predict接口中，output.get\_data\_to\_numpy()方法可以将显存中的数据读取到内存中。

[三方应用: https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_1159.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_1159.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/85e5ccf0-a3d6-4047-ad57-f220605c8c73.png)

4.使用Mindspore Lite转换工具进行模型转换时，如果出现如下报错，可能的原因是哪一项?C（）\[ERROR\]ME(103674,7fbdc90a8ec0,python):2021-12-13-16:20:49.506.131 \[mindspore/lite/src/extendrt/session/single op session.cc:242\] CompileGraph\] Only support CustomAscend, but got Reshape, node ReshaDe 9IERRORI ME(103674,7fbdc90a8ec0,pvthon):2021-12-13-16:20:49.506.245 \[mindspore/lite/src/extendrt/cxx api/model/model impl.cc:280\] BuildByBufferlmpl\] compile graph failed.

1.  转换工具不支持模型中的Reshape算子
    
2.  转换工具不支持Reshape算子中的某些参数
    
3.  模型转换时未指定Ascend后端
    
4.  模型文件损坏
    

5.定位精度问题时，首先要保证NPU和标杆设备上的模型初始状态保持一致，最方便且有效的做法是什么?C

1.  固定随机种子进行随机初始化
    
2.  打开确定性计算开关后进行随机初始化
    
3.  固定随机性目打开确定性计算开关后进行随机初始化
    
4.  加载相同的初始权重进行初始化
    

6.以下不属于模型迁移开发全流程的是哪一项?C

1.  迁移评估
    
2.  模型代码迁移
    
3.  模型可视化
    
4.  精度性能调优
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/7b9b6db3-dea7-45d5-bff3-82288cbf1edb.png)

7.以下哪项是昇腾异构计算中的集合通信库?C

1.  CuDNN
    
2.  NCCL
    
3.  HCCL
    
4.  Gloo
    

[https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclapi\_07\_0001.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclapi_07_0001.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/85b393ca-0b44-4b1e-8132-008aa9b79376.png)

8.请问以下哪个仓库是昇腾提供的大模型解决方案仓库?B

1.  DeepSpeed
    
2.  ModelLink
    
3.  AscendSpeed
    
4.  Megatron-LM
    

[https://gitee.com/ascend/ModelLink](https://gitee.com/ascend/ModelLink)

9.下面哪一项负责AI Core内部数据在不同Buffer之间的读写管理及一些格式转换的操作，比如填充(padding)、转置(transpose)3D图像转2D矩阵(Img2Col)等? A

1.  存储转换引擎MTE
    
2.  总线接口单元BIU
    
3.  通用寄存器GPR
    
4.  专用寄存器SPR
    

[https://www.hiascend.com/doc\_center/source/zh/CANNCommunityEdition/80RC2alpha001/devguide/opdevg/tbeaicpudevg/atlasopdev\_10\_0008.html](https://www.hiascend.com/doc_center/source/zh/CANNCommunityEdition/80RC2alpha001/devguide/opdevg/tbeaicpudevg/atlasopdev_10_0008.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b5cb9164-3c52-47c3-9fb3-0ec5b0aaf2b5.png)

10.通常来讲，算子下发瓶颈识别可以通过搜索观察哪个接口间隙来判断，间隙越多说明存在算子下发瓶颈，间隙越少说明算子下发状态良好。B

1.  Enqueue
    
2.  Dequeue
    
3.  Enstack
    
4.  Destack
    

[https://www.hiascend.com/doc\_center/source/zh/CANNCommunityEdition/80RC1alpha001/devaids/auxiliarydevtool/atlasprofiling\_16\_0006.html](https://www.hiascend.com/doc_center/source/zh/CANNCommunityEdition/80RC1alpha001/devaids/auxiliarydevtool/atlasprofiling_16_0006.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e6120b38-5b19-43fe-bcc6-6e90ddef5da0.png)

11.完成精度调试的标志是什么?B（？）

1.  Loss与标杆完全对齐
    
2.  采用常规数据集评估模型分数符合社区实践评分预期
    
3.  模型在验证集上的准确率达到一定水平
    
4.  以上都不是
    

12.以下关于集合通信原语说法错误的是哪项?B

1.  broadcast是一对多操作
    
2.  scatter是多对多操作
    
3.  gather是多对一操作
    
4.  ReduceScatter是多对多操作
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/255173cb-69a6-4f72-b307-e2f0650ea3ce.png)

13.卷积神经网络(CNN)在计算机视觉领域取得了极大成功，这是因为卷积运算的两大核心思想--局部感知与参数共享--非常适合图像处理，那么如下关于这两个思想的描述中错误的是哪一项?D

1.  局部感知指的是每个神经元仅与输入层的一小块区域连接，这块局部区域称作感受野(receptive field)
    
2.  局部感知是通过小尺寸卷积核实现的，即卷积核尺寸远小于输入图像尺寸，只探索局部信息
    
3.  参数共享指的是卷积过程中卷积核的权重不会改变，通过相同的卷积核提取了不同位置的特征
    
4.  参数共亨的优点是可以减少计算量，降低内存/显存需求，而局部感知没有这个效果
    

14.某客户在公有云上部署了AI业务，某天的15点5分业务量暴增，15点20分用户下扩容订单，昇腾云服务在20分钟后即完成千卡资源扩容上线，保障了用户业务的平稳运行。以上案例体现的是异腾云服务的哪一项关键能力? A

1.  立等可取，即开即用
    
2.  集群优化，释放性能
    
3.  全栈优势，高效诊断
    
4.  安全可靠，上云无忧
    
5.  百模千态，一键部署
    

15.SPMD(Single Program Multiple Data，单程序多数据)是并行计算中的常用方法，如下关于SPMD流程描述错误的是哪一项? C

1.  启动一组进程，他们运行相同的程序
    
2.  切分待处理的数据，把数据分片分发给不同进程
    
3.  每个进程都处理所有的数据切片         （每个进程只处理分配给它的数据分片）
    
4.  每个进程对自己的数据分片进行所有任多的处理
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d8d05c13-a8b0-403e-8ca8-2a97c304f7be.png)

16.假设我们训练好的一个机器学习模型，它在训练集、验证集、测试集上的错误率分别为0.5%、15%、15%，那么如下优化措施，我们不建议使用哪一项?  D

1.  使用新的模型架构
    
2.  增加训练数据并做更多的数据增强
    
3.  尝试提前终止训练(early stopping)
    
4.  减少正则化
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/57f8dc9a-15de-4582-ad87-3db68531d046.png)

17.假设我们在神经网络中使用了某个激活函数(activation function)，对于某个输入得到的输出值是-0.01，那么这个激活函数可能是以下哪一个? A

1.  Leaky ReLU
    
2.  ReLU
    
3.  Sigmoid
    
4.  Softmax
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/61a7f016-1338-4502-8b7d-e6eb93363606.png)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/763dc8af-74a2-4de3-9303-34634ae1a427.png)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/3ded3ebf-e3c5-47bd-a3ba-f44d57082bd5.png)

18.在精度调试问题中，以下哪些操作不是确定性问题排查的手段? C

1.  使用ptdbq工具的md5 dump功能找到不确定问题首次发生的step
    
2.  使用梯度监控工具监控NPU训练过程中的确定性问题
    
3.  设置export HCCL DETERMINISTIC=TRUE
    
4.  使用ptdbq工具的dump功能导出API的tensor统计数据
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/2609ff3a-4426-44ca-994b-158d126a0dc2.png)

19.在使用MindFormers进行大语言模型的文本生成时，可以配置不同的采样策略，如下描述的是哪一种策略:每个时间步，按照token出现的概率由高到底排序，当概率之和大于某个阈值时，就不取后面的样本了;然后对取到的这些token的概率重新归一化后，进行采样 B

1.  贪心采样
    
2.  Top-p 采样
    
3.  Top-k 采样
    
4.  Beam Search 采样
    

贪心采样总是选择概率最高的 token。

Top-k 采样是只在概率最高的前 k 个 token 中进行采样。

Beam Search 采样则是通过维护多个候选序列来搜索最优输出。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d172d128-4e88-4f6d-a938-03ddf97d534e.png)

20.昇腾云支持多种资源形态对外提供算力，如下场景描述的是哪种形态:面向云主机资源型用户，基于BMS(Bare MetalServer，裸金属服务器)进行封装，并预装主流AI开发套件，兼容社区Open stack原生接口，A

1.  ModeArts Lite DevServer
    
2.  ModelArts Lite k8s Cluster
    
3.  ModelArts Standard
    
4.  ModelArts Edge
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/7bcb9317-5ded-4059-b7be-baff1e30b32c.png)

## 多选题

1.作为ModelArts系列中负责边缘部署和管理的服务，如下功能描述中，属于ModelArts Edge能力范畴的有哪几项?  ABD

1.  支持纳管多种异构算力的边缘设备，方便业务集成与运组
    
2.  支持进程、容器等多种格式的AI应用部署，方便应用的快速上线
    
3.  提供端到端的模型生产工具链，AI开发、训练、推理一站式服务
    
4.  提供多种调度方式，支持边云协同推理，高效利用边缘资源
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/a56634df-0ef8-434e-8b82-afa01b040283.png)

2.神经网络模型分为训练和推理两套流程，如下关于组件和流程的描述中，属于模型推理流程的有哪些? ABE

1.  dataset:用于获取数据，包含网络的输入，标签等
    
2.  network:网络模型实现，MindSpore中一般使用Cell包装
    
3.  loss:损失函数，用于衡量预测值与真实值差异的程度
    
4.  optimmizer:优化器，用于计算和更新网络参数
    
5.  metrics:评价指标，用于评估模型的好坏
    

3.LLM(large language model，大语言模型)兴起后，在各个领域的应用越来越多，受到越来越大的关注，但是LLM的训练是一个复杂的过程，如下关于LLM训练过程的描述正确的有哪些? ABCD

1.  预训练(Pretraining)阶段，模型通过学习大量无标签文本数据来学习语言的基础知识
    
2.  有监督微调(Supervised Finetuning)阶段，模型使用特定任务的标签数据进行训练，以更好地适应真实场景
    
3.  奖励建模(Reward Modeling)阶段，通过人工标注数据学习什么样的生成文本是“好”的文本
    
4.  强化学习(Reinforcement Learming)阶段，利用奖励模型让LLM的行为与人类“对齐“
    

4.在Transformer架构提出之前，自然语言外理领域使用最多的是各种类型的循环神经网络(RNN)，如下关于RNN与Transformer的描述正确的有哪些? ABCD

1.  虽然有LSTM/GRU等改进形态，但RNN处理长距离依赖的能力仍然不够好
    
2.  Transformer架构可以直接计算序列中任意两个位置之间的关系，使得模型能够有效地捕获长距离依赖信息
    
3.  RNN是时序结构，当前时刻的输入依赖前一时刻的输出，不太适合做并行化
    
4.  Transformer架构可以高效地并行处理整个序列，推理时也可以并行化输出完整的句子
    

5.在模型迁移前GPU上loss正常收敛，迁移到NPU后loss跑飞，可能的原因有哪些? ABCD

1.  NPU算子实现有bug
    
2.  代码迁移时未正确使用NPU相关API
    
3.  存在计算溢出问题
    
4.  代码迁移时未和GPU版本采用等价的超参设置
    

6.NPU环境下确定性计算打开的方式是什么? BD

1.  torch.use deterministic algorithms(True)
    
2.  expOrt HCCL DETERMINISTIC=TRUE
    
3.  export NCCL DETERMINISTIC=TRUE
    
4.  expOrt INF NAN MODE ENABLE=1
    

7.当使用精度工具定位到某个API计算存在较大偏差时，以下哪些方法是合理的? C

1.  删除该API执行逻辑，再次观察是否还有精度问题
    
2.  将该API使用.cpu()转换到cpu上计算，再次观察是否还有精度问题
    
3.  构造单API用例，并在NPU、CPU或GPU上运行的结果进行对比
    
4.  直接将该API的名称反馈给华为侧定位
    

8.pytorch框架动态图训练，CV类型小模型例如resnet,mibilenet等存在通信的场景有哪些? AD

1.  反向传播过程中对多卡梯度聚合
    
2.  Relu激活函数导致多卡通信   
    
3.  dataloader加载数据时数据分发    ？
    
4.  前向传播过程中syncBatchNorm导致多卡通信
    

Relu激活函数本身不会导致多卡通信，因为它是一个逐元素的操作，不需要跨GPU交换数据 

9.pytorch框架训练性能调优，获取到训练的profiling数据后，应该从以下哪些维度展开分析? ABCD

1.  cpu侧任务下发
    
2.  通信
    
3.  计算
    
4.  数据加载
    

原因：

**CPU侧任务下发**：查看 CPU 任务调度的效率，是否存在过多的等待时间或不必要的任务切换。

**通信**：检查数据交换的时间消耗，尤其是分布式训练时的通信延迟，以及是否有效地利用了可用带宽。

**计算**：分析 GPU 或其他计算设备的利用率，检查是否存在计算资源的空闲时间，以及计算任务的执行效率。

**数据加载**：检查数据加载和预处理的效率，包括数据读取时间、数据预处理时间以及是否有效地利用了多线程或多进程技术。

10.使用benchmark工具对Mindspore lite推理模型进行性能基准测试时，会将推理得到的输出与标杆数据进行相似度度量，工具将会输出如下哪几顶度量教据?AC

1.  平均相对误差
    
2.  最大相对误差
    
3.  余弦相似度
    
4.  相对熵
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2c2b5b1a-321d-403f-8fcc-b6311d829c3d.png)

11.在进行模型精度校验时，如下哪些因素会影响模型在不同平台的实际效果?ABD（？）

1.  算子实现差异
    
2.  设备性能差异
    
3.  设备通信时长
    
4.  数据类型差异
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/62f3a26e-69c6-4ef1-b809-b25cc7dcd478.png)

12.ModelArts支持训练模型过程中安装第三方依赖包，其中依赖包安装文件的命名支持以下哪几种格式?  ABCD

1.  pip-requirement.txt
    
2.  pip-requirements.txt
    
3.  reguirement.txt
    
4.  reguirements.txt
    

[https://support.huaweicloud.com/modelarts\_faq/modelarts\_05\_0063.html](https://support.huaweicloud.com/modelarts_faq/modelarts_05_0063.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/cab63710-0639-47d8-8565-260b700548a3.png)

13.在无标杆性能数据的情况下，可考虑什么方式进行性能调优?

1.  使用权威网站的性能数据作为目标
    
2.  替换NPU亲和api算子
    
3.  尝试使用apex优化库
    
4.  定位ai cpu算子并尝试使能ai core
    

14.模型迁移完成后进行性能调优时，以下哪些是常用的调优方法?ABCD（？）

1.  使能NPU亲和融合API算子与优化器
    
2.  使能二进制编译调优
    
3.  打开确定性计算开关
    
4.  增大模型参数batch size
    

15.对于迁移前的训练是基于PyTorch+FSDP的场景，推荐采用哪种方式进行迁移?BC

1.  自行编写训练脚本
    
2.  切换到PyTorch2.1及以上版本
    
3.  使用白动迁移工具进行迁移
    
4.  切换成其他框架
    

# 题目三(张瑜)

## 判断题

1.精度校验是通过固定输入，对比模型推理结果和基准数据的相似度来完成的。T（？）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b7b4044c-a2ce-474f-b57b-310ba04bf4c5.png)

2.compare一键式全流程精度比对工具适用于TensorFlow、PyTorch和ONNX模型。T（？）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b3a29f27-ae2b-4ad2-a37c-c30cc48291c8.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d380eedd-0a8c-4568-8a83-e5af590f8e0e.png)

3.优化器并行-ZeRO 主要思想是在训练过程中去除冗余数据。ZeRO 有三个不同优化级别，对模型状态进行不同程度的分片。T

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/9c203595-c579-4160-b593-63a61b71779d.png)

4.PyTorch Adapter 支持通过 pip 方式安装下载的 whl 包。T（？）

5.DeepSpeed分布式训练加速工具，实现了内存优化算法，最新版本的DeepSpeed可以直接在Atilis 800T A2昇腾设备上使用，无需deepspeed\_npu插件。T （确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5a3743c9-3a78-4aa5-a2d8-37c049155263.png)

6.部分算子因为数据输入类型问题或者算子实现问题，导致会在昇腾芯片的AI CPU上执行，没有充分利用AI CORE的资源。使用ma-advisor query all可获取亲和API替换调优、AI CPU调优、算子调优建议。T（？）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b47192e5-f987-48f5-894a-b291688e657d.png)

7.使用api\_precision\_compare比对的结果中，某个API最大绝对误差<0.001，余弦相似度=0.95，该API精度不达标。F（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b0abb5c7-a5ee-445f-8c0f-9f2a7f48886a.png)

8.性能问题通常出现在算子下发和执行的异步过程中，因此性能优化的总体原则为：减少Host算子下方时间和减少Device算子执行时间。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e2b9a51e-3f0e-4c0b-80e5-617714143953.png)

9.在fp16混合精度训练场景下，如果Loss scale在连续的50个step没有持续降低，这种情况可以判定为正常溢出。F

10.Ptdbg工具提供了模块级dump功能。T（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/bad67e90-fd9c-4f7f-9044-5c52e81517fa.png)

11.神经网络中如果不使用激活函数（activation function），那么每一层节点的输入都是上层输出的线性函数，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，网络的表达能力就相当有限。因此，引入非线性激活函数主要就是为了添加非线性因素，增强深层神经网络的表达能力。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0016c483-0bcd-4619-b5de-7a4101d54c89.png)

12.GoogleLeNet是一种经典的卷积神经网络，其中引入了Inception结构，代替单纯的卷积-池化-激活的传统操作，通过使用不同大小的卷积核来抓取不同大小的感受野，拓宽了网络的宽度。T(?)

13.单层感知机只能处理线性数据，为了解决非线性分类问题，我们可以使用多层感知机，在输入层和输出层之间多加一些隐藏层。多层感知机中添加的隐藏层数越多，整个网络的分类能力就越强，可以提取的目标特征层次也越高。F（确定）

14.ModelArts训练作业的运行过程中，如果需要安装第三方依赖包，可以在训练代码目录下放置安装软件，文件内容格式为“包名==版本号”，如“click==6.6”，训练后台会自动下载安装依赖包；目前不支持安装用户自己编译的whl包。T（？）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/87dbd83a-c367-4349-8292-d04fbe2d0b80.png)

15.ModelArts的开发环境允许用户在同一个Notebook实例中切换节点的运行规格，如从CPU环境切换到NPU环境，但切换时Notebook实例必须处于“停止”状态。F（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b41f8394-21bc-44c1-9b33-8521bcc6f754.png)

## 单选题

1.使用benchmark工具对模型进行精度测试时，二进制输入数据通过哪个参数设置？B（确定）

A.inData

B.inDataFile

C.benchmarkData

D.benchmarkDataFile

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/51421b91-a7e8-4131-9a70-369f9f7dbcef.png)

2.以下关于离线模型转换评估工具Tailor相关描述错误的是哪一项？B（）

A.Tailor是用于模型转换（ONNX到MindIR)和性能分析的辅助工具

B.Tailor的主要功能是：模型转换、性能测试&精度测试、Profiling性能分析，ONNX网络修改

C.Tailor在分析过程可以开启AOE优化

D.Tailor可以查询ONNX模型的输入输出信息

[AIGC工具tailor使用指导\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_0166.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/1dfb84b1-ba66-4f23-8c1b-91196d227dc4.png)

3.AOE（Ascend Optimization Engine）模型调优过程中，根据数据切分等价原理自动搜索生成计算图的切分策略，通过切分算子来减少数据量，提升模型计算的性能，这属于哪一种性能优化方法？A(?)

A.子图调优

B.模型裁剪

C.算子调优

D.算子切分

4.模型训练时，出现OOM (Out Of Memory) 错误，则如下哪个改动有助于解决问题？D （确定）

A. 数据精度由 fp16 -> bf16

B. 数据精度由 fp16 -> fp32

C. 数据精度由 bf16 -> fp32

D. 数据精度由 fp32 -> fp16

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4580315a-80d1-4c25-8764-fdff08cb8557.png)

5.在开启确定性计算后，NPU多次训练的Loss保持一致。但是在长时间的训练过程中，和GPU的Loss存在差异并且慢慢扩大，甚至出现Loss上扬等严重问题，一下哪项不是正确的排查思路和操作？D(?)

A.由于已经开启了确定性计算开关，数据存在差异不再是问题，而只有到数据存在较大差异时才被判定为问题。因此高灵敏的md5不再适用，需要记录原始数据进行后续的差异分析

B.此时的监控对象从模型的权重，转变为了每次迭代步的权重梯度

C.使用梯度监控工具监控GPU和NPU训练过程中的梯度方向差异

D.使用ptdbg工具dump从训练开始到loss出现明显异常的数据

6.模型脚本自动迁移时使用的是如下哪行代码？A（确定）

A.import torch\_npu; from torch\_npu.contrib import transfer\_to\_npu

B. from mist\_llm import DumpConfig, register\_hook

C.import deepspeed

D. deepspeed.init\_distributed('hccl')

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/18b7cd53-d832-4a25-87bc-695bb7661163.png)

7.模型训练过程中算子的高精度主要指什么？B（确定）

A.整数运算高精度

B. 浮点数运算高精度

C.FP16

D. 混合精度

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/8a29c49f-effe-4e6b-8db6-ab414a48a218.png)

8.使用Ascend PyTorch Profiler接口开启PyTorch训练时的性能数据采集，采集CANN软件栈及NPU数据的activities是什么？B（确定）

A.torch\_npu.profiler.ProfilerActivity.CPU

B. torch\_npu.profiler.ProfilerActivity.NPU

C.torch.profiler.ProfilerActivity.CPU

D. torch.profiler.ProfilerActivity.NPU

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/a1307b06-6c28-4487-8149-6ef9ad0db934.png)

9.以下关于分布式并行DDP的说法正确的是哪项？C（？）

A.DDP采用单机多卡，一台机器上运行一个进程

B. DDP运行时，server要和每一个worker进行梯度传递，当server和worker不在同一台机器时，server带宽会成为瓶颈

C.DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长

D.DDP通过手机梯度到device\[0\]，在device\[0\]更新参数，然后其他设备复制到device\[0\]的参数实现各个模型同步

10.定位如千卡大集群场景的偶现性能问题时，为了减少需要分析的数据量，如下操作中应当首先尝试进行的是哪项？A（？）

A.在小集群或单节点上复现性能问题

B.采集性能异常场景大集群全量性能数据进行分析

C.将数据集、日志等文件转移到节点本地，日志等文件保存在本地，排除网络I0性能问题

D.采集性能正常场景的大集群全量性能数据作为对比

11.在精度定位过程中，如果通过大量的实验后发现偏差是算法稳定性层面或者累积偏差导致的，算子的精度都是达标的，应该如何处理？B（？）

A.只要未达到客户合同要求的精度偏差指标，就继续投入分析

B.分析偏差扩散的路径是否合理，并同时测试下游任务，通过下游任务得分和理论分析过程和客户解析原因

C.loss是反应模型精度最真实的指标，至少应该保证loss收敛后的值满足偏差指标才能认为精度达标

D.以上都不对 

12.以下哪项不属于集合通信的最基础的操作？D（确定）

A.send

B.receive

C.copy 

D.all2all 

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0239cc7b-1752-4c82-ae1b-018559031175.png)

13.以下关于数据并行说法错误的是哪项？ B（确定）

A.数据并行是指将一个进程或一张卡上无法处理的大量数据拆分为多组数据，在多个进程或多张卡上同时进行计算

B.数据并行时各rank拥有不同的模型参数

C.各卡上独立完成前向传播和反向传播得到梯度

D.通过聚合再下发AllReduce操作将各卡的梯度进行平均并同步，各卡更新模型参数

14.过拟合是机器学习中需要避免的现象，在其它条件不变的前提下，以下哪种做法容易引起过拟合问题？C（确定）

A.增加训练数据集的样本量

B.减少神经网络中隐藏层的节点数

C.减少或不做数据增强

D.使用dropout等正则化方法

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5140c04e-b18e-48c7-a931-73ed860f506f.png)

 15.提高网络模型的抗噪能力，方法之一就是在训练过程中加入随机噪声，我们可以在网络的不同位置加入噪声，如下关于噪声注入的描述错误的是哪一项？B（确定）

A. 在输入层加入噪声，可以看做是数据增强，使网络对于输入更加鲁棒

B.我们通常无法保证数据集100%标记正确，因此可以在隐藏层增加噪声，即标签平滑

C.标签平滑主要用于分类任务中，能够防止模型过于求确切的概率而不能学习正确分类

D.dropout也是一种噪声注入方法，通常加在隐藏层中

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4b8e729a-60f1-4149-8a07-f3b9488d06c3.png)

16.量大小（batchsize）的设置对神经网络的训练效果有较大的影响，在训练中，我们通常将batchsize设置为2的指数倍，如32/64/128等，这么做的原因是什么？A（？）

A.内存/显存一般也是2的指数倍，方便并行化

B.梯度优化算法在2的指数倍场景下效果更好

C.损失函数（lossfunction）更容易计算，收敛更快

D.对学习率的设置更友好，更鲁棒

17.ModelArtsLite提供了多种场景下的存储解决方案，如下场景描述的是哪种存储配置方案：提供高可靠、高性能、规格丰富并且可弹性扩展的块存储服务，其中存放的是二进制数据，无法直接存放文件，且只能在ECS（ElasticCloudServer，弹性云服务器）、BMS（BareMetalServer，裸金属服务器）中挂载使用，不能被操作系统应用直接访问。C（？）

A.SFS（ScalableFileService），弹性文件服务

B.SFS Turbo

C.EVS（ElasticVolumeService），云硬盘

D.OBS（ObjectStorageService），对象存储服务

18.Moxing是ModelArts自研的框架，提供了一套文件对象API，可以用来读写OBS文件，如果想要下载一个OBS文件夹sub\_dir\_0到Notebook，如下哪个操作可以实现？B（确定）

A.mox.file.copy('obs://path\_of\_obs/sub\_dir\_0','path\_ofnotebook/sub\_dir\_0'）

B.mox.file.copy\_parallel（'obs://path\_of\_obs/sub\_dir\_0','path\_of\_notebook/sub\_dir\_0'）

C.mox.file.copy（'path\_of\_notebook/sub\_dir\_0','obs://path\_of\_obs/sub\_dir\_0'）

D.mox.file.copy\_parallel ('path\_of notebook/sub\_dir\_0','obs://path\_ofobs/sub\_dir\_0'）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/01665c62-190f-49b8-b849-24895935d4ed.png)

19.MindSpore的Cell类是构建所有网络的基类，当用户需要自定义网络时，需要继承Cell类，其中网络的执行需要重写Cell类的哪个方法？A（确定）

A.construct

B.inference

C.forward

D.call

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/76df471b-d752-49cd-bb52-898e44c65a39.png)

20.ModelArts支持开发者使用本地IDE连接到Notebook开发环境进行远程开发，此时需要使用以下哪一项进行鉴权认证？A（确定）

A.秘钥对

B.AK/SK

C.华为账号密码

D.项目ID

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/fba4f909-0af4-4c0b-b44c-be3e683cf00b.png)

## 多选题

1.使用MindSporeLite转换工具进行模型转换时，如果出现如下报错，可能的原因有哪些？CD（？）

WARNING LITE（11979,7fbdc90a8ecOconverter\_lite）:2021-12-13-16:20:49.506.071 \[mindspore/lite/tools/commonyprotobuf\_utilS.CC:94\] ReadProtoFromBinaryFilel Parse \*\*\*.onnx failed

\[ERROR LITE（11979,7fbdc90a8ecOconverter\_lite）:2021-12-13-16:20:49.506.122 \[mindspore/lite/build/tools/converter/parser/onnx/onnx\_op\_parser.cc:3079 InitOriginModel Read onnx model file failed model path: /mLaudio\_kit vocals resunet.onnx

\[ERROR\] LITE(119797fbdc90a8ecOconverter\_lite）:2021-12-13-16:20:49.506.131 \[mindspore/lite/build/tools/converter/parser/onnx/onnx\_op\_parser.cc:3026\] Parse\] init origin model failed.

A.存在转换工具不支持的算子

B.转换工具不支持该算子的某种特殊属性或参数

C.模型路径错误

D.模型文件损坏

2.在进行模型精度校验时，如下哪些因素会影响模型在不同平台的实际效果？ABD（？）

A.算子实现差异

B.设备性能差异

C.设备通信时长

D.数据类型差异

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/55ae08db-a4e0-4ea4-aab6-c0859b065c32.png)

3.GPU环境下确定性计算打开的方式是什么? AD（？）

A.torch.use\_deterministicalgorithmsTrue）

B.export HCCL DETERMINISTIC=TRUE

C.export NCCL\_DETERMINISTIC=TRUE

D.export INF\_NAN\_MODE\_ENABLE=1

4.关于精度问题，以下说法正确的有哪些?ABCD（？）

A.迁移之后的精度校验工作可以采用CPU/GPU作为标杆，前提是在迁移前模型已经在CPU/GPU环境达到预期训练效果

B.可以通过下游任务评估来检测精度，下游任务验证符合业务需求即可认为精度正常

C.训练过程loss和标杆loss无法做到完全对齐，只要模型正常收敛就可以认为符合预期

D.确定性计算是用来辅助精度问题定位的，本身并不属于精度问题

5.模型迁移完成后进行性能调优时，以下哪些是常用的调优方法？ABCD（？）

A.使能NPU亲和融合API算子与优化器

B.使能二进制编译调优

C.打开确定性计算开关

D.增大模型参数batch size

6.关于PyTorch确定性计算，以下说法正确的是   ABCD（？）

A.当前阶段，并不是所有的NPU和CUDA算子都支持确定性计算

B.开启确定性计算后性能会受到影响，建议只有在定位精度相关问题时再开启确定性计算

C.确定性计算是定位精度问题时首先要考虑并解决的问题

D.在精度问题位程中，确定性计算不是目的，而是手段，部分场景要在确定性计算使能的情况下，进行下一步的精度问题分定位（常稳问题）

7.关于ModelArts提供的昇腾迁移环境，以下说法正确的是哪几项?ABD（确定）

ModelArts提供了配套昇腾硬件环境的基础容器镜像

在昇腾环境上启动容器镜像时，可以使用ASCENDVISIBLE DEVICES指定容器要使用的卡号

容器内无法查看昇腾卡信息，宿主机上可以查看卡信息

ModelArts基础镜像内的PyTorch/MindSpore等AI框架包均安装在Conda环境内

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/fb94ae8f-a33c-4c74-b8a9-43ad215c279e.png)

8.pytorch框架动态图训练性能调优，对于CPU侧下发性能瓶颈，有哪些优化手段？ABCD（？）

A.使能融合算子API，减少小算子下发

B.可视化profiling，如果发现大量aclopcompile类算子，则使能二进制调优torch.npu.set\_compile\_modejit\_compile=False）

C.排查是否有频繁的张量同步到CPU的操作，如loss.item（），tensor.cpu（）等

D.增大BatchSize

9.在迁移可行性分析中如果存在平台未支持的算子，可通过下面哪些方式解决?  ACD（？）

A.修改模型脚本，使用等价支持的算子替换

B.将CANN版本降低

C.联系华为工程师提出开发适配诉求

D.参考文档进行算子适配

10.关于Ascendspeed仓，下列说法正确的是哪几项？ABCD（？）

A.Ascendspeed是基于Megatron-LM仓库做的异腾适配

B.Ascendspeed是针对华为异腾设备的大模型加速库

C.使用时，需要在训练脚本前增加importascendspeed.megatron\_adaptor

D.该仓库早期也包含模型代码、下游任务评测等解决方案内容，目前该部分内容已迁移至ModelLink仓库

11.学习率（learningrate）是机器学习模型训练中的重要超参数，学习率的选取会影响到训练性能和模型效果，如下关于学习率的描述正确的是有哪些？ AB

A.如果学习率设置得很小，那么训练将花费更多时间，因为每次移动的步长很小

B.如果学习率设置得很大，那么训练可能不收敛，或在极值附近震荡

C.不建议使用学习率自适应优化算法（如Adam，Adadelta等），模型不容易收敛

D.建议在一个取值范围内周期性地改变学习率，而不是将其设定为固定

12.在Transformer架构提出之前，自然语言处理领域使用最多的是各种类型的循环神经网络（RNN），如下关于RNN与Transformer的描述正确的有哪些？ ABCD（？）

A.虽然有LSTM/GRU等改进形态，但RNN处理长距离依赖的能力仍然不够好

B.Transformer架构可以直接计算序列中任意两个位置之间的关系，使得模型能够有效地捕获长距离依赖信息

C.RNN是时序结构，当前时刻的输入依赖前一时刻的输出，不太适合做并行化

D.Transformer架构可以高效地并行处理整个序列，推理时也可以并行化输出完整的句子

13.作为ModelArts系列中负责边缘部署和管理的服务，如下功能描述中，属于ModelArtsEdge能力范的有哪几项？ABD

A.支持纳管多种异构算力的边缘设备，方便业务集成与运维

B.支持进程、容器等多种格式的AI应用部署，方便应用的快速上线

C.提供端到端的模型生产工具链，AI开发、训练、推理一站式服务

D.提供多种调度方式，支持边云协同推理，高效利用边缘资源

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/7bd80953-8603-41e8-9cc2-c1883d6f1c15.png)

14.MindFormers提供了textgenerator（文本生成）方法，在让用户能够便捷地使用生成类语言模型进行文本生成任务，该方法支持的推理能力有哪些？ABCD（？）

A.增量推理

B.Batch推理

C.流式推理

D.分布式推理

15.PyTorchAdapter使用插件化方式在线对接适配昇腾AI处理器，这样做的优势有哪些? ABD

A.最大限度的继承GPU在PyTorch上的使用方式，移植的时候，在开发方式和代码复用方便做到最小的改动

B.最大限度的继承PyTorch原生的体系结构，保留框架本身出色的特性

C.使用方便，插件内置在PyTorch安装包中，只需要一次pip安装即可完成

D.扩展性好，对于新增的网络类型或结构，只需相关计算类算子的开发和实现

[三方应用: https://www.hiascend.com/document/detail/zh/canncommercial/70RC1/modeldevpt/ptmigr/AImpug\_0004.html](https://www.hiascend.com/document/detail/zh/canncommercial/70RC1/modeldevpt/ptmigr/AImpug_0004.html)

# 题目四（叶时意）

## 判断题

1.性能优化的总体原则为: 减少Device算子下发时间、减少Host算子执行时间。 F（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c425bf8f-ba18-44e0-83fa-7ebcb9fc0c5c.png)

2.使用benchmark工具进行模型性晓测试时，不需要设定输入数据，也不需要设置基准数据。F（确定）

3.算子的数值精度是计算过程的基础，通常认为算子精度问题是大模型精度问题的来源之一。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/84fb01ba-f8d4-4576-a8db-90383f824f08.png)

4.分布式训练的本质是解决单设备内存不足或者单个设备计算能力不足问题。T（确定）

5.DeepSpeed分布式训练加速工具，实现了内存优化算法，最新版本DeepSpeed可以直接在Atlas 800T A2 异网设备上使用，无需deeps peed\_npu插件.T（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0ffc0c0a-e434-49d1-89c4-cb7b86f74922.png)

6.优化器并行-ZeRO主要思想是在训练过程中去除冗余数据，ZeR0有三个不同优化级别，对模型状志进行不同程度的分片.T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d47a7749-d764-4c5a-a9f9-f29b620c6228.png)

7.部分NPU硬件对FP32的限制，导致混合精度问题，造成精度损失，在训练过程中避免开启混合精度方式.F(?)

8.算子精度问题分析思路通过比对标杆和NPU训练过程中API的输入输出张量粒度的对比，定位出异常api。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/58bac107-f89f-450f-8505-60c5ced61b8f.png)

9.模型的超参大数可以分为学习率，batch-size，并行切分策路，学习南warm-up，模型数，FA配置等，用户在进行NPU精度和GPU精度比对的，需要保证两边的配置一致。T(?)

 10.NPU和GPU芯片对浮点计算指令npu.exp(x)= gpu\_exp(x).F（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b1c8e038-bdd3-49dd-8d00-e13c70374eb7.png)

11.神经网络的训练过程，就是通过对训练数据集的学习，调盈神经网络中每个神经元的参数，使得损失函数的值取得最高或者相对较高的值。因此，训练的目标就是要让损失函数的值尽可能的大。 F

12.模型容易产生过拟合的原因之一是没有太好的抗噪能力，也就是说如果输入数据经过微小的变动，就可能得到完全不一样的的结果。因此，防止模型过拟合的方法之一，就是在训练过程中加入随机噪声帮助训练。T（确定）

13.在机器学习中，过拟合与欠拟合都是需要避免的现象，其中过拟合描的是在训练集和测试集上的性能都较差，而欠拟合往往能较好地学习训练集数据的性质，但在测试,失上的性能较差。F（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/16be7290-7cf4-4d07-b5e1-78efcce3e242.png)

14.CPU的架构中需要大量的空间去放晋缓存单元(cache) 和控制单元(control)，相比之下计算单元(即算术逻单元 Arithmetic Logic Unit,ALU)只占据了很小的一部分，所以CPU在进行大规模并行计算方面受到限制，相对而言更长于复杂逻掘运算。T（确定）

15.ModelArts训练作业的运行过程中，如果需要安波第三方依顺包，可以在训练代码目录下放置安装文件，文件内容格式为”包名==板本号”，如”click==6.6”，训练后台会自动下我安液依赖包;目前不支持安装用户自己编译的whl包。T(?)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0145e74c-2175-42b3-8922-85947f24ad73.png)

## 单选题

1.一个7 B参数量的模型，使用fp16格式的数据精度进行推理，其显存占用最接近如下哪一项?  C

1.  3.5 G8
    
2.  7 GB
    
3.  14 GB
    
4.  28 GB
    

2.如下信息是使用哪一条命令执行得到的?+---------pu-smi23.0.rc2.2 Version:23.0.rc22|+--------U Name | Health | Power(W) Temp(C) Hugepages-Usage(page)llChipBus-ld AlCore(96) Memory-Usage(MB) HBM-Usage(M8)|+=====-===:=====H4 910B4|OK|84.239 0/01010000:81:00.0100/03170/32768|+=======p|Process id |Process name | Process memory(MB)|+=============二二二三二ニ二ニニニ二二二二二========================+ No running processes found in NPÚ 4 +=================+====================+===================+

A（？）

1.  npu-smi info
    
2.  npu-smi info watch
    
3.  npu-smi info -l
    
4.  npu-smi info -m
    

3.使用AOE(Ascend Optimization Engine) 进行单模型性能调优时，建议的整体操作步骤是如下哪一个? 1.制除编译续存2.删除已有的AOE知识斥3.配置文件中启用AOE自动喝优4.配置文件中关团AOE自动调优5.执行模型转换 。  C（？）

1.  1,3,5
    
2.  1,2,3,5
    
3.  1,2,3,5,1,4,5
    
4.  1,2,4,5,1,3,5
    

4.对于动志分档场景，converter\_lite最多支持多少档?   D（确定）

1.  20
    
2.  50
    
3.  80
    
4.  100
    

5.下面哪一个命今可以获取NPU设备内存总的便用情况?  D（确定）

1.  midia-smi
    
2.  midia-smi info
    
3.  npu-smi
    
4.  npu-smi info
    

6.下面哪一项负责AI Core内部数据在不同Buffer之间的读写管理及一些格式转换的操作，比如填充(padding)、转置(transpose)3D图像转2D矩阵(Img2Col)等? A

1.  存储转换引|警MTE
    
2.  总线接口单元BIU
    
3.  通用言存器GPR
    
4.  专用吉存器SPR
    

7.NPU上Flash attention中 (npu\_fusion attention) 常提到的layout排布(B、S、N、D、H)中，以下说法错识的是 ？C

1.  B表示batch size维度
    
2.  S表示序列长度
    
3.  N表示Query、Key、Value的numm\_heads数，且三者长虚必须一致
    
4.  HND
    

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/700alpha002/ptmoddevg/ptmigr/ptaoplist\_246.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/700alpha002/ptmoddevg/ptmigr/ptaoplist_246.html)

8.流行的深度学习框架中有不同的数据格式，典型的有NCHW、NHWC等格式。其中，N、C、H、W分别指的是什么?  C（确定）

1.  N (NUM) 、c (Count) 、H (Height) 、w (Width)
    
2.  N (Head-Num) c (Channel) ，H (HEAD) 、W (Width)
    
3.  N (Batch) .C (Channel) 、H (Height) .w (Width)
    
4.  N (Batch) .C (Count) 、H (Height) .w (Width)
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/7c744435-d3a3-46c3-abe9-9f96df08c722.png)

9.以下哪项不属于算子精度问题分析流程?   D（？）

1.  溢出检测
    
2.  dump数据
    
3.  hccl检测
    
4.  通过预检工具比对数据
    

10.关于昇腾精度定位问题分析，以下说法正确的是。C（？）

1.  只要loss和标杆对齐(满足一定的偏差阈值)就说明精度已经没有问题了
    
2.  只要昇腾和GPU在相同输出时，API的输出结果不一致就可以认为是昇腾算子有问题
    
3.  算子的性能和精度存在此消彼长的关系，需要根据实际情况进行权衡
    
4.  GPU上同等精度输出可以作为真值参考，所以要保证所有NPU的输出需要尽可能地和GPU对齐
    

11.在大模型训练中，若想指定运行的NPU卡为第6和第7张卡，正确的指定方式是什么?  A（？）

1.  export ASCEND\_RT\_VISIBLE\_DEVICES=6,7
    
2.  export ASCEND\_RT\_VISIBLE DEVICES=6~7
    
3.  export ASCEND\_RT\_VISIBLE\_DEVICES=\[6,7\]
    
4.  export VISIBLE\_DEVICES=\[6,7\]
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/8093bb26-bd62-4ef7-af2a-f142f1b896c2.png)

12.以下不属于模型迁移开发全流程的是哪一项?  C（确定）

1.  迁移评估
    
2.  模型代码迁移
    
3.  模型可视化
    
4.  精度性能调优
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/53c53575-dd8e-4ff7-8b4f-60929c72a969.png)

13.以下哪种现象可以说明PyTorch确定性计算开关开启成功目生效:  A（？）

1.  多次运行训练脚本，loss曲线趋势保持一致(在同一时刻下降和上升，且偏差幅度始终保持一致)
    
2.  多次运行训练脚本，loss曲线的值必须保持完全一致，任何差异都是不可以接受的
    
3.  开启确定性开关前后的loss曲线趋势保持-致(在同一时刻下降和上升，且偏差幅度始终保持一致)
    
4.  由于集合通信的累加顺序不一致，因此即使打开确定性计算，也无法保证最终的输出是完全一致的
    

14.在卷积神经网络CNN中，卷积是最核心的操作，其输入输出都是多维向量，或是图像，或是特征图。假设某一个卷积操作中，输入图像大小为5\*5\*3(HWC，高"宽"通道数，不考虑批量大小batch size，下同)，卷积核尺寸为3“3，通道数为5，卷积步长为1，边缘不做填充，则输出的特征图大小是多少 (用HWC格式表示)?  B（？）

1.  3\*3\*3
    
2.  3\*3\*5
    
3.  5\*5\*3
    
4.  5\*5\*5
    

15.梯度下降算法的正确步骤是什么?1.计算预测值和真实值之间的误差2.重复迭代，直至得到网络权重的最佳值3.把输入传入网络，得到输出值4.用随机值初始化权重和偏差5.调整权重以减小误差     D（？）

1.  3,1,5,4,2
    
2.  4,1,3,5,2
    
3.  3,4,1,5,2
    
4.  4,3,1,5,2
    

16.数据增强是深度学习中的必要操作，相当于增加了训练数据样本，可以降低过拟合的概率，但是在不同的任务中也要注意数据增强方法的选择，不能干扰到模型对数据特征的学习。例如在0~9的手写数字识别中，哪一项数据增强方法不建议使用?  C（确定）  D

1.  图像缩放
    
2.  随机亮度变化
    
3.  随机添加噪声
    
4.  图像翻转
    
5.  图像颜色变换
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/34db0792-1b05-4688-9031-69a591d9e670.png)

17.昇腾云支持多种资源形态对外提供算力，如下场景描述的是哪种形态:面向云主机资源型用户，基于BMSBare Metal Server，裸金属服务器)进行封装，并预装主流AI开发套件，兼容社区Open Stack原生接口 ？ A

1.  ModeArts Lite DevServer
    
2.  ModelArts Lite k8s Cluster
    
3.  ModelArts Standard
    
4.  ModelArts Edge
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/bb044089-932e-4445-9961-0015a1b45de0.png)

18.在ModelArts控制台创建A应用时，如果需要使用pip方式安装某些依赖包，那么这些信息需要填写在配置文件config.json的哪个字段下?    D（？）  A

1.  dependencies
    
2.  pip-dependencies
    
3.  requirements
    
4.  pip-requirements
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/9c475fdb-cb2e-4f73-a134-2dd09d9b08f6.png)

19.MindSpore支持动态图和静态图两种模式，可以通过st.context接口来设置运行环境，如果需要设置为动态图运行模式，该接口的mode参数应该如何设置?   A（确定）

1.  PYNATIVE\_MODE
    
2.  GRAPH MODE
    
3.  DYNAMIC MODE
    
4.  ASCEND MODE
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b512d5bc-a33f-4300-94d3-402d7561962a.png)

20.Moxing是ModelArts自研的框架，提供了一套文件对象AP1，可以用来读写OBS文件，如果想要下载一个0BS文件夹sub.dir\_0到Notebook，如下哪个操作可以实现?   B（确定）

1.  mox. file.copy('obs://path\_of\_obs/ p-dir\_0', 'path\_of\_notebook/sub\_dir\_0")
    
2.  mox.file.copy\_parallel(obs://path\_of\_obs/sub\_dir\_0' path\_of\_notebook/sub\_dir\_0)
    
3.  mox.file.copy('path\_of\_notebook/sub dir\_0', obs://path of obs/sub dir 0)
    
4.  mox.file.copy\_parallel(path\_of\_notebook/sub \_dir\_0', obs://path\_of\_obs/sub\_dir\_0')
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/58c2b433-1b92-4ce4-b81b-b92f3a8ee398.png)

## 多选题

1.使用AOE (Ascend Optimization Engine) 进行单模型性能调优后，其输出的json文件主要包含如下哪些信息?   ABCD（？）

1.  model\_baseline\_performance，表示调优前模型执行时间，单位为ms
    
2.  model performanceimprovemet
    
3.  表示调优后模型执行时间减少的百分比
    
4.  model\_result\_performance，表示调优后模型执行时间
    
5.  repo\_summary，包含调优过程中使用到的知识库算子个数或者追加到知识库的算子个数
    

2.msprof命令行工具采集到的timeline数据，包含如下哪几项内容?   ABC（确定）

1.  应用层数据
    
2.  CANN数据
    
3.  底层NPU数据
    
4.  算子可选优化项
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5dff7af3-3aac-4a95-965a-b59e982a47cc.png)

3.在迁移可行性分析中如果存在平台未支持的算子，可通过下面哪些方式解决?  ACD（？）

1.  修改模型脚本，使用等价支持的算子替换
    
2.  将CANN版本降低
    
3.  联系华为工程师提出开发适配诉求
    
4.  参考文档进行算子适配
    

4.pytorch框架动态图训练，CV类型小模型例如resnet, mibilenet等存在通信的场景有哪些?   AD（？）

1.  反向传播过程中对多卡梯度聚合
    
2.  Relu激活函数导致多卡通信
    
3.  dataloader加载数据时数据分发
    
4.  前向传播过程中syncBatchNorm导致多卡通信
    

Relu激活函数本身不会导致多卡通信，因为它是一个逐元素的操作，不需要跨GPU交换数据 

5.GPU环境下确定性计算打开的方式是什么?   AC（？）

1.  torch.use\_deterministic algorithms(True)
    
2.  export HCCL\_DETERMINISTIC=TR
    
3.  export NCCL\_DETERMINISTIC=TRUE
    
4.  export INF\_NAN\_MODE\_ENABLE=1
    

6.关于PyTorch确定性计算，以下说法正确的是:   ABCD（？）

1.  当前阶段，并不是所有的NPU和CUDA算子都支持确定性计算
    
2.  开启确定性计算后性能会受到影响入建议只有在定位精度相关问题时再开启确定性计算
    
3.  确定性计算是定位精度问题时首先要考虑并解决的问题
    
4.  在精度问题定位过程中，确定性计算不是目的，而是手段，部分场景要在确定性计算使能的情况下，进行下一步的精度问题分析定位(常稳问题)
    

7.精度对比工具ptdbg的seed\_all接口能够固定哪些随机性?  ABCD（？）

1.  固定random模块的随机生成器种子
    
2.  固定numpy中随机生成器种子
    
3.  固定torch随机种子
    
4.  固定数据集dataloader加载顺序
    

8.在模型迁移前GPU上loss正常收敛，迁移到NPU后loss跑飞，可能的原因有哪些?  ABCD（？）

1.  NPU算子实现有bug
    
2.  代码迁移时未正确使用NPU相关API 
    
3.  存在计算溢出问题
    
4.  代码迁移时未和GPU版本采用等价的超参设置
    

9.大模型精度对齐场景，往往面临网络规模参数量巨大的限制，以下哪些方法可以缓解上述现象，且能够尽可能不影响原问题的定位? ABC（？）

1.  只dumpAPI的统计量信息进行对比
    
2.  减小模型层数
    
3.  减小输入token的序列长度
    
4.  减小模型的学习率
    

10.进行模型迁移之前，需要做以下哪些工作?   ABCD（？）

1.  选取合适的模型，在三方平台运行成功
    
2.  在昇腾设备上搭建环境
    
3.  使用迁移分析工具分析模型在昇腾设备上的支持度
    
4.  在昇腾设备上运行下游任务评测
    

11.Transformer架构提出以来，在自然语言处理(NLP)、计算机视觉(CV)等领域都得到了广泛应用，如下模型中有哪些使用了Transtormer架构?   ABCE（？）

1.  BERT
    
2.  ViT
    
3.  DETR
    
4.  SENet
    
5.  GPT
    

12.LSTM(Long Short Term Memory,长短期记忆网络)是一种特殊的环神经网络(RNN)，通过"门”(gate) 结构的设计，更好的控制信息记录。如下关于LSTM结构描述正确的有哪些?  BCD

1.  隐藏门 (hidden gate)，决定什么信息需要被忽略
    
2.  输入门 (input gate)，决定何时将数据读入单元
    
3.  输出门 (output gate)，决定从单元中输出的条目
    
4.  遗忘门 (forget gate)，决定什么时候记忆或忽略输入信息
    

13.MindFormers提供了text generator(文本生成)方法，旨在让用户能够便捷地使用生成类语言模型进行文本生成任务，该方法支持的推理能力有哪些?  ABCD（？）

1.  增量推理
    
2.  Batch推理
    
3.  流式推理
    
4.  分布式推理
    

14.使用ModelArts的开发环境，创建Notebook实例时需要选择一种A!引擎的镜像，可以选择的镜像类型包括如下哪几项?ABC（？）

1.  预置在ModelArts内部的公共镜像
    
2.  AI Gallery社区发布的镜像
    
3.  基于公共镜像创建的实例保存下来的自定义镜像
    
4.  在ECS(Elastic cloud Server)上构建的自定义镜像
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b3da7961-c82a-4aa4-bf92-802f9d2f006d.png)

15.使用ModelArts的开发环境进行模型训练时，如果需要将本地12 GB左右的数据集上传到Notebook，如下哪些操作可以实现该功能?  CD（？）

1.  直接将文件拖拽到Notebook窗口左边的空白处
    
2.  单击导航栏的Upload Files按钮，打开文件上传界面进行上传
    
3.  将本地文件上传至OBS桶中，然后使用ModelArts SDK从OBS下载文件至Notebook本地
    
4.  将本地文件上传至OBS桶中，然后使用Moxing接口从OBS下载文件至Notebook本地
    

# 题目五（许腾飞）

## 判断题

1.使用benchmark工具进行模型性能测试时，不需要设定输入数据，也不需要设置基准数据。F（确定）

原因：通常情况下，进行性能测试需要有明确的输入数据和基准数据作为参考。

2.AOE(Ascend Optimization Engine) 优化成功的.mindir模型，在使用时不可以删除AOE知识库，否则会影响该模型的性能。F（确定）

原因：AOE优化引擎生成的.mindir模型在使用时并不依赖于AOE知识库的存在。 

[关键字：AOE优化引擎、.mindir模型](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2012.html)

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/5262040e-3c1b-443c-9d93-cb770e0bada5.png)

3.torch\_npu作为一个PyTorch"插件"，在已安装PyTorch的基础上安装后，支持在不改变PyTorch表达层的基础上，动态添加昇腾后端适配，包含增加了NPU设备、hccl等一系列能力的支持。安装后可以直接使用PyTorch的表达层来运行在NPU设备上。T（确定）

原因：torch\_npu插件可以在已有的PyTorch基础上动态添加昇腾后端适配能力。 关键字：torch\_npu插件、PyTorch、昇腾后端适配

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a1a1f675-b34d-4aad-8300-89636201f4e9.png)

4.性能问题通常出现在算子下发和执行的异步过程中，因此性能优化的总体原则为：减少Host算子下发时间和减少Device算子执行时间。T（确定）

原因：性能优化的原则之一就是减少主机算子下发时间和设备算子执行时间。

5.使用api\_precision\_compare比对的结果中，某API最大绝对误差<0.001，余弦相似度=0.95，该API精度不达标。F（确定）          

原因：精度比对结果中，余弦相似度为0.95通常被认为是较为接近的，但还需要结合具体场景和标准来判断是否达标。 

关键字：精度比对、余弦相似度、最大绝对误差

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/f2cbfb05-f9fa-4855-9ac0-e05221b7f96f.png)

6.当神经网络非常巨大，甚至网络可能巨大到无法存放到单一计算设备中，这时候，可以采用模型并行策略省去多个设备之间的梯度AllReduce操作，从而优化梯度同步和数据通信开销。F（确定）

原因：模型并行策略可以用于处理非常大的模型，但是它通常会涉及到梯度AllReduce操作来同步梯度。 

7.在fp16混合精度训练场景下，如果Loss scale在连续的50个step没有持续降低，这种情况可以判定为正常溢出。F（确定）

原因：在FP16混合精度训练中，如果Loss scale在连续的多个步骤中没有降低，这可能是Loss scale设置不当的表现，而不是正常溢出。 

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/6aa2f0eb-d687-4b88-9e4b-8453e4266e24.png)

8.假设您对mindspore框架训练的大模型结构比较熟悉，知道哪些"关键算子"容易成为计算瓶颈，为"关键算子"配置合适的切分策略以获得更好的性能，您可以在初始化网络之前调用 mindspore.set\_auto\_parallel\_context(parallel\_mode=ParallelMode.SEMI\_AUTO\_PARALLEL)：设置半自动并行模式。T（确定）

原因：通过设置mindspore的auto\_parallel\_context，可以指定半自动并行模式，这有助于优化关键算子的性能。

9.算子的数值精度是计算过程的基础，通常认为算子精度问题是大模型精度问题的来源之一。T（确定）

原因：算子的数值精度对于整个模型的计算准确性至关重要，算子精度问题确实是影响大模型精度的一个因素。 

10.模型的超参大致可以分为学习率， batch-size，并行切分策略，学习率warm-up，模型参数，FA配置等，用户在进行NPU精度和GPU精度比对前，需要保证两边的配置一致。T（确定）

原因：为了确保精度比对的准确性，需要确保在不同平台上（如NPU和GPU）使用的超参数配置是一致的。

11.神经网络中如果不使用激活函数 (activation function)，那么每一层节点的输入都是上层输出的线性函数，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，网络的表达能力就相当有限。因此，引入非线性激活函数主要就是为了添加非线性因素，增强深层神经网络的表达能力。T（确定）

原因：人工神经元单元由线性函数和激活函数构成，如果没有激活函数，则每一层的输出将是输入的线性组合。

12.模型容易产生过拟合的原因之一是没有太好的抗噪能力，也就是说如果输入数据经过微小的变动，就可能得到完全不一样的结果。因此，防止模型过拟合的方法之一，就是在训练过程中加入随机噪声帮助训练。T（确定）

原因：加入随机噪声可以帮助模型学习更加鲁棒，减少过拟合的风险。

13.提前终止(early stop)是一种防止欠拟合的方法，即在模型对训练数据集完全收敛之前停止迭代来防止欠拟合。可能的做法是，在每一个Epoch结束时计算验证集的loss或准确率，发现loss上升或者准确率不再提高时，提前停止训练。F（确定）

原因：提前终止是为了防止过拟合，而不是欠拟合。

14.在使用开发环境或者训练作业时，ModelArts会挂载硬盘至"/cache"目录，用户可以使用此目录来储存文件，此目录无法扩容，不同资源规格有不同的容量，且环境重启后数据将被清空无法恢复。F（？）

原因：ModelArts挂载的硬盘目录"/cache"是可以扩容的，并且某些资源规格的数据可以持久化。

 [开发环境中不同Notebook规格资源“/cache”目录的大小\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/modelarts_faq/modelarts_05_3151.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/29bc81d8-f604-4743-ac89-4fccd4a09e98.png)

15.CPU的架构中需要大量的空间去放置缓存单元(cache)和控制单元(control)，相比之下计算单元(即算术逻辑单元 Arithmetic Logic Unit， ALU) 只占据了很小的一部分，所以CPU在进行大规模并行计算方面受到限制，相对而言更擅长于复杂逻辑运算。T（确定）

原因：CPU架构中缓存单元和控制单元占据较大空间，ALU占比较小，因此CPU更适合复杂逻辑运算而非大规模并行计算

## 单选题

1.对于动态分档场景，converter\_lite最多支持多少档?D（确定）

1.  20
    
2.  50
    
3.  80
    
4.  100
    

原因：converter\_lite工具支持的最大动态分档数量为100档

[模型适配\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2004.html)

2.AIT (Ascend Inference Tool) 是昇腾推理一体化开发工具，可执行多项任务，如果需要分析昇腾推理设备对输入模型的支持度情况，包括算子支持情况、算子定义、算子输入等，应该使用如下哪一项task类型?C（确定）

1.  benchmark
    
2.  transplt
    
3.  analyze
    
4.  profile
    

原因：使用analyze task可以获取昇腾推理设备对输入模型的支持度情况。

benchmark 和 profile 测试  transplt 迁移  analyze 分析

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/0069edb7-3362-4876-a936-f7b69141b9e7.png)

3.采用converter\_lite工具进行模型转换时，可在配置文件中通precision\_mode参数指定精度模式，该参数的默认设置为如下哪一项? A（确定）

1.  enforce\_fp16
    
2.  enforce\_fp32
    
3.  preferred\_fp32
    
4.  enforce\_origin
    
5.  preferred\_optimal
    

 [MindSpore](https://www.mindspore.cn/lite/docs/zh-CN/r2.3.1/use/cloud_infer/converter_tool_ascend.html)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/50e62ae6-52d7-4833-9149-3a3104d472c8.png)

4.使用MindSpore Lite的predict接口进行模型推理，如果output的内容在显存中，可以通过如下哪个方法将数据读取到内存中使用?A（确定）

1.  output.get\_data\_to\_numpy()
    
2.  output.to('cpu')
    
3.  output.move\_to\_cpu()
    
4.  output.set('cpu')
    

原因：MindSpore Lite的predict接口中，output.get\_data\_to\_numpy()方法可以将显存中的数据读取到内存中。

[基于MindSpore Lite的模型转换\_AI开发平台ModelArts (huaweicloud.com)](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_1159.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/85e5ccf0-a3d6-4047-ad57-f220605c8c73.png)

5.以下不属于DeepSpeed分布式并行技术的是哪一项?D（确定）

1.  ZeRO1-3
    
2.  3D并行
    
3.  CPU offloading
    
4.  Page Attension
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f71e9376-0570-476a-a1d6-d4df1c88a8e6.png)

6.以下关于梯度监控工具的level参数说法错误的是哪项?B

1.  LO：梯度特征数据，包含如下特征：("param\_name"， “MD5"，"max"，“min"， "norm"， “shape")、无梯度方向数据
    
2.  L1：梯度特征数据，包含如下特征：("param\_name"， "MD5"， interval\_O..interval\_n， "=0"， "max"，"“min"，"norm"， "shape")、有梯度方向数据
    
3.  L2：梯度特征数据，包含如下特征：("param\_name"，“MD5"， “max"，“min"， "norm"， "shape")、有梯度方向数据
    
4.  L3：梯度特征数据，包含如下特征：("param\_name"， "MD5"， interval\_O..interval\_n， "=0"， "max"， "“min"，"norm"， "shape")、有梯度方向数据
    

原因：L1：无梯度方向数据。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/ed192ade-4a1e-4481-b48b-017324800aac.png)

7.pytorch框架训练性能调优时，采集profiling时需要采集堆栈信息，需要配置的参数是哪项?A（确定）

1.  with stack=True
    
2.  data\_simplification=False
    
3.  aic\_metrics=torch\_npu.profiler.AiCMetrics.PipeUtilization
    
4.  record\_shapes=True
    

原因：采集profiling时需要配置with\_stack=True来采集堆栈信息。

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d0832166-6105-4a6d-9c23-964d4eba4e8e.png)

8.以下哪项是昇腾异构计算中的集合通信库?C（确定）

1.  (cuDNN
    
2.  NCCL
    
3.  HCCL
    
4.  Gloo
    

原因：HCCL是昇腾异构计算中的集合通信库。

9.以下关于分布式数据并行DDP的说法正确的是哪项?C（确定）

1.  DDP采用单进程，一台机器上运行一个进程
    
2.  DDP通信开销大，server要和每一个worker进行梯度传输，当server和worker不在同一台机器时，server带宽会成为瓶颈
    
3.  DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长
    
4.  DDP通过收集梯度到device\[0\]，在device\[0\]更新参数，然后其他设备复制 device\[0\] 的参数实现各个模型同步
    

原因：

DDP采用单进程，一台机器上运行一个进程：这是错误的描述。DDP 实际上采用多进程的方式，在每台机器上运行多个进程，每个进程负责一部分数据并行处理。

DDP通信开销大，server要和每一个worker进行梯度传输，当server和worker不在同一台机器时，server带宽会成为瓶颈：这是错误的描述。DDP 不是基于 server-worker 模型的，而是基于 peer-to-peer 的模型，每个 worker 都与其他 worker 直接通信，无需通过中央 server。

DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长：这是正确的描述。DDP 使用 Ring AllReduce 算法来最小化通信开销。在这种算法中，每个进程只与相邻的两个进程通信，这样可以有效地减少通信的成本，并且随着节点数的增加，通信成本的增长不是线性的。

DDP通过收集梯度到device\[0\]，在device\[0\]更新参数，然后其他设备复制 device\[0\] 的参数实现各个模型同步：这是错误的描述。DDP 并不是将梯度集中到一个设备上更新参数，而是每个设备都参与参数更新的过程，并通过 AllReduce 算法同步梯度。

10.跨框架的大模型迁移(比如从GPU的书生迁移到NPU的modellink，网络定义不一致，但是整体结构一致)发现精度偏差较大，此时在进行精度对齐时最适合的定位手段是什么?A（？）

1.  使用精度对比工具dump所有API真值数据进行对比
    
2.  使用精度对比工具采集所有API统计信息数据进行对比
    
3.  使用精度对比工具分析网络是否有溢出
    
4.  使用精度对比工具dump两个框架网络的模块信息进行对比
    

原因：在进行精度对齐时，最适合的定位手段是使用精度对比工具dump所有API真值数据进行对比。

11.模型训练过程中算子的高精度主要指什么?B（确定）

1.  整数运算高精度
    
2.  浮点数运算高精度
    
3.  FP16
    
4.  混合精度
    

原因：算子的高精度通常指的是浮点数运算的精度。

12.在开启确定性计算后，NPU多次训练的Loss保持一致。但是在长稳的训练过程中，和GPU的Loss存在差异并且慢慢扩大，甚至出现Loss上扬等严重问题，以下哪项不是正确的排查思路和操作?D（确定）

1.  由于已经开启了确定性计算开关，数据存在差异不再是问题，而只有到数据存在较大差异时才被判定为问题。因此高灵敏的md5不再适用，需要记录原始数据进行后续的差异分析
    
2.  此时的监控对象从模型的权重，转变为了每次迭代步的权重梯度
    
3.  使用梯度监控工具监控GPU和NPU训练过程中的梯度方向差异
    
4.  使用ptdbg工具dump从训练开始到loss出现明显异常的数据
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/6b2e2743-c37b-48b8-b09f-0394941d27a1.png)

13.以下不属于模型迁移开发全流程的是哪一项?C（确定）

1.  迁移评估
    
2.  模型代码迁移
    
3.  模型可视化
    
4.  精度性能调优
    

原因：模型迁移开发全流程包括迁移评估、模型代码迁移和精度性能调优，但不包括模型可视化。

14.神经网络的训练，基本都是采用梯度下降 (gradient descent)算法，而它又分为多种方法，如下关于梯度下降算法的描述中错误的是哪一项?B（确定）

1.  全局梯度下降算法使用整个训练数据集来计算梯度，适用于样本量较小的场景
    
2.  随机梯度下降算法在每轮迭代时随机选取1个样本点，对噪声不敏感，容易收敛到极值
    
3.  小批量梯度下降算法每次随机选取一小部分训练数据参与计算，兼顾了效率和稳定性
    
4.  小批量梯度下降算法中引入了batch size的概念，成为神经网络训练中的重要超参数之一
    

原因：随机梯度下降算法对噪声敏感，容易发散，不易收敛到全局最优解。

15.池化(pooling)是神经网络中的常用操作，以下关于池化操作的作用描述错误的是哪一项?D（确定）

1.  池化后特征图的尺寸缩小了，可以降低模型的参数量
    
2.  最大池化操作保留了图像最显著的特征
    
3.  卷积之后接上池化，相当于获得了更大的感受野
    
4.  模型参数量的减少，可以进一步降低欠拟合的概率
    

原因：池化操作减少了模型参数量，有助于降低过拟合的风险，而非降低欠拟合的概率。

16.客户是一家购物平台，需要实现智能客服系统，回答顾客在售前、售中、售后等阶段的咨询问题。请问以上任务描述主要属于人工智能的哪个领域应用?B（确定）

1.  计算机视觉
    
2.  自然语言处理
    
3.  语音信号处理
    
4.  决策规划系统
    

原因：智能客服系统主要涉及自然语言处理技术。

17.如下关于计算图的描述，错误的是哪一项?B（确定）

1.  动态图的核心特点是图的构建和计算同时发生
    
2.  动态图对全局的信息掌握更丰富，可做的优化也会更多
    
3.  静态图在计算阶段，根据输入数据执行编译好的图得到计算结果
    
4.  静态图无法实时拿到中间计算结果，中间过程对于用户来说是个黑盒
    

原因：静态图相比于动态图更能掌握全局信息，可做的优化更多。

18.假如用户A和用户B不在同一个主账号下，A想要在ModelArts的开发环境中使用B的自定义镜像，正确的操作步骤是哪一项?B（确定）D(许腾飞，共享的不能直接使用，想被地址直接使用需要公开，自己测试一下就知道了)

1.用户A在ModelArts控制台的镜像管理页面，使用镜像的SWR(容器镜像服务)地址进行镜像注册

2.用户B在SWR(容器镜像服务)控制台中将镜像共享给A

3.用户A使用安装了容器引擎的计算机将共享镜像Pull下来

4.用户A使用安装了容器引擎的计算机将共享镜像Push到SWRR(容器镜像服务)

1.  1
    
2.  2，1
    
3.  2，4，1
    
4.  2，3，4，1
    

原因：用户B需要先将镜像共享给用户A，然后用户A在ModelArts控制台注册镜像。

1.  ：提供一系列适配过昇腾算力的模型，用户可以在平台上进行部署、微调、训练等操作，也就是"模型即服务"B（确定）
    
1.  云化算力
    
2.  模型开发
    
3.  模型托管
    
4.  模型生态
    

原因：模型托管主要侧重于对模型的存储和管理；模型生态则更侧重于整个模型相关的生态系统，包括开发者、使用者、模型的交流与共享等方面；云化算力则主要指云计算提供的强大计算能力。而这里着重描述的是针对模型的开发相关服务，所以是模型开发。

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a39aef12-6bc2-4fb2-969a-485fb63cd9b0.png)

20.如下MindFormers的组件中，哪一项提供了大模型的推理加速能力?B          D

1.  MindSpore PET
    
2.  MindSpore Serving
    
3.  MindSpore Interence
    
4.  MindSpore Lite
    

原因：MindSpore Serving提供了大模型的推理加速能力。

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/7505dd56-fd98-43a6-82bb-ee5ef6b01b1c.png)

## 多选题

1.在模型推理性能优化分析中，性能瓶颈主要来自如下哪几项?AE（确定）

1.  Host算子下发
    
2.  Host算子执行
    
3.  Host算子编译
    
4.  Device算子下发
    
5.  Device算子执行
    
6.  Device算子编译
    

原因：性能瓶颈通常出现在Host算子下发和Device算子执行的过程中。

2.算子融合是一种常见的模型优化方法，将多个算子融合为一个算子，可以减少内存访问和计算的开销，如下选项中哪些是常见的算子融合操作?ABCDE

1.  conv + relu
    
2.  conv + bn
    
3.  conv + bn + relu
    
4.  bias add + layer norm
    
5.  gemm + elementwise
    

原因：

conv + relu：将卷积操作（convolution）和激活函数ReLU融合在一起。这种融合可以减少内存访问次数，并加速计算。

conv + bn：将卷积操作与批量归一化（batch normalization, BN）融合。BN操作通常紧跟在卷积操作之后，融合可以减少内存访问和计算开销。

conv + bn + relu：将卷积操作、批量归一化和ReLU激活函数融合在一起。这是一种常见的组合，可以进一步减少内存访问和计算开销。

bias add + layer norm：将偏置添加（bias add）和层归一化（layer normalization, LN）融合在一起。这种融合可以减少内存访问次数，并加速计算。

gemm + elementwise：这里的`gemm`通常指的是通用矩阵乘法（General Matrix Multiplication），而`elementwise`操作指的是逐元素操作，如逐元素加法。这种融合可以减少内存访问次数，并加速计算。

3.pytorch框架训练性能调优，获取到训练的profiling数据后，应该从以下哪些维度展开分析?ABCD（确定）

1.  cpu侧任务下发
    
2.  通信
    
3.  计算
    
4.  数据加载
    

原因：

CPU侧任务下发：查看 CPU 任务调度的效率，是否存在过多的等待时间或不必要的任务切换。

通信：检查数据交换的时间消耗，尤其是分布式训练时的通信延迟，以及是否有效地利用了可用带宽。

计算：分析 GPU 或其他计算设备的利用率，检查是否存在计算资源的空闲时间，以及计算任务的执行效率。

数据加载：检查数据加载和预处理的效率，包括数据读取时间、数据预处理时间以及是否有效地利用了多线程或多进程技术。

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/fc2a7cb6-999f-4393-bbfe-6a12d56298da.png)

4.在PyTorchGPU训练迁移到NPU训练的迁移环境搭建中，需要环境具备如下哪些内容?ABCD（确定）

1.  昇腾驱动、固件
    
2.  CANN
    
3.  PyTorch
    
4.  昇腾适配的PyTorch NPU
    

原因：迁移环境搭建需要具备昇腾驱动、固件、CANN、PyTorch和昇腾适配的PyTorch NPU

5.目前已知的不支持的迁移场景包括以下哪几项?ABCD（？）（排除法选AB 许腾飞）

1.  Ascend Extension for PyTorch (即 torch-npu)1.11.0版本不支持单进程多卡； Ascend Extension for PyTorch(即 torch-npu))2.1.0及以上版本支持单进程多卡
    
2.  不支持使用DP(distributed parallel)模式的模型迁移，需要手动改为DDP接口
    
3.  不支持cuda接口自动迁移至npu接口
    
4.  不支持NCCL相关代码自动迁移至HCCL
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/56a12a06-c4e6-4f64-b8b6-1a0cf009e654.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/43f256d1-e2ca-49c5-a4d2-e4281066cb16.png)

6.以下哪些选项属于精度偏差的来源?ABCD（确定）

1.  算子计算BUG
    
2.  算法迁移适配不当
    
3.  确定性计算未开启
    
4.  硬件差异，芯片架构差异
    

原因：精度偏差可能来源于算子计算BUG、算法迁移适配不当、确定性计算未开启以及硬件差异

7.Ascend Insight是一款主要针对大模型集群场景的调优可视化工具。它支持的平台有哪些?ABCD

1.  windows
    
2.  linux
    
3.  mac
    
4.  ModelArts
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/9272fb54-6c36-4156-a8b1-fc959300dc5b.png)

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/c2e94d58-a34f-4c52-90a9-ee6542f1cd8f.png)

8.在进行模型迁移前，需要保证选定的模型能在已有的AI硬件上正常运行，并输出哪些方面的测试基线?AC（？）

1.  精度
    
2.  功耗
    
3.  性能
    
4.  内存占用率
    

原因：模型迁移前需要输出精度和性能方面的测试基线。

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/727b7120-e817-491e-9e46-a7834495e6a5.png)

9.pytorch框架动态图训练，llm类模型可能涉及的并行模式有哪些?ABCD（？）

1.  张量并行
    
2.  流水线并行
    
3.  数据并行
    
4.  专家并行
    

原因：

数据并行（Data Parallelism）：将数据集分割到多个设备上，每个设备上运行相同的模型副本。每个设备处理数据的一个子集，并行地进行前向传播和反向传播。随后，所有的设备将梯度进行汇总并更新模型参数。

张量并行（Tensor Parallelism）：将模型的权重张量在多个设备上进行分割，以便并行执行计算。张量并行可以按不同的维度来分割张量，例如，将权重矩阵的行或列分割到不同的设备上。

流水线并行（Pipeline Parallelism）：将模型的不同层或模块放置在不同的设备上，形成一个流水线。在前向传播时，数据沿着流水线顺序流动，而在反向传播时则逆序流动。这种方法可以利用模型的不同部分同时进行计算，提高计算资源的利用率。

专家并行（Expert Parallelism）：在混合专家模型（Mixture of Experts, MoE）中使用的一种并行策略。在这种模型中，数据被路由到一组专家中的一个，每个专家可以在不同的设备上。通过这种方式，可以利用多个设备来并行处理数据，同时每个专家可以处理更多的数据。

 [https://www.hiascend.com/document/detail/zh/Pytorch/60RC2/modthirdparty/asdevguide/mindspeed\_0032.html](https://www.hiascend.com/document/detail/zh/Pytorch/60RC2/modthirdparty/asdevguide/mindspeed_0032.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/8cdc60e6-aea7-45e6-8c7a-a26b3ac8e45a.png)

10.以下哪些现象代表大模型可能存在精度问题?ABC（？）

1.  训练Loss上扬不收敛
    
2.  训练Loss值出现INF/NAN等异常值
    
3.  推理结果不正确
    
4.  推理响应速度很慢
    

原因：训练Loss上扬不收敛、训练Loss值出现INF/NAN等异常值以及推理结果不正确都是大模型可能存在精度问题的表现。

11.卷积神经网络(CNN)发展过程中，研究者提出过很多经典的模型，如下关于各个模型描述正确的有哪些?ABC（？）

1.  VGGNet使用连续的3\*3卷积核替代大卷积核，通过增加网络深度提高网络学习能力
    
2.  GoogLeNet中使用了1\*1卷积核，增加非线性特征的同时又可以达到降维的效果
    
3.  ResNet提出的残差结构，很好的解决了深度网络的退化问题，使得网络可以通过加深提高准确率
    
4.  DenseNet使用SE(Sequeeze-and-Excitation)模块学习不同通道之间的依赖关系，提高了模型的表现能力
    

原因：VGGNet通过连续的33卷积核替代大卷积核，增加网络深度提高学习能力；GoogLeNet_使用1_1卷积核增加非线性特征同时降维；ResNet提出的残差结构解决了深度网络的退化问题，允许网络通过加深提高准确率。而DenseNet的特性是密集连接，并不是SE模块的学习通道间的依赖关系。

12.LLM (large language model， 大语言模型)兴起后，在各个领域的应用越来越多，受到越来越大的关注，但是LLM的训练是一个复杂的过程，如下关于LLM训练过程的描述正确的有哪些?ABCD（确定）

1.  预训练(Pretraining)阶段，模型通过学习大量无标签文本数据来学习语言的基础知识
    
2.  有监督微调(Supervised Finetuning)阶段，模型使用特定任务的标签数据进行训练，以更好地适应真实场景
    
3.  奖励建模(Reward Modeling)阶段，通过人工标注数据学习什么样的生成文本是"好"的文本
    
4.  强化学习(Reinforcement Learning)阶段，利用奖励模型让LLM的行为与人类"对齐”
    

原因：LLM训练过程通常包括四个主要阶段：预训练阶段、有监督微调阶段、奖励建模阶段和强化学习阶段。这些阶段分别对应模型通过学习大量无标签文本数据来学习语言的基础知识、使用特定任务的标签数据进行训练以更好地适应真实场景、通过人工标注数据学习什么样的生成文本是"好"的文本，以及利用奖励模型让LLM的行为与人类"对齐"。

13.使用ModelArts的开发环境，创建Notebook实例时需要选择一种AI引擎的镜像，可以选择的镜像类型包括如下哪几项?ABCD

1.  预置在ModelArts内部的公共镜像
    
2.  Al Gallery社区发布的镜像
    
3.  基于公共镜像创建的实例保存下来的自定义镜像
    
4.  在ECS(Elastic Cloud Server)上构建的自定义镜像
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b95ee991-0142-4e04-bf37-3926befaefe0.png)

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b8948f5a-b049-4174-83bd-a888be8a4e75.png)

14.神经网络模型分为训练和推理两套流程，如下关于组件和流程的描述中，属于模型推理流程的有哪些?ABE（？）

1.  dataset：用于获取数据，包含网络的输入，标签等
    
2.  network：网络模型实现，MindSpore中一般使用Cell包装
    
3.  loss： 损失函数，用于衡量预测值与真实值差异的程度
    
4.  optimizer：优化器，用于计算和更新网络参数
    
5.  metrics：评价指标，用于评估模型的好坏
    

原因：在模型推理流程中，需要使用dataset来获取数据，network来进行预测，以及metrics来评估预测结果的质量。而loss和optimizer主要用于模型训练阶段，用来计算损失和更新参数。

15.ModelArts支持用户将自己在其他环境开发好的模型迁移到平台上进行部署，在创建AI应用时，如下哪些文件必选包含在模型包中?ABD（确定）

1.  模型文件，如PyTorch框架的pt文件
    
2.  模型配置文件，固定为config.json
    
3.  三方依赖包安装文件，如requirements.txt
    
4.  模型推理代码文件，固定为customize\_service.py
    

原因：在ModelArts创建AI应用时，模型包中必须包含模型文件（如PyTorch框架的.pt文件）、模型配置文件（固定为config.json）以及模型推理代码文件（固定为customize\_service.py）。而三方依赖包安装文件（如requirements.txt）虽然很重要，但并不是强制性的。 关键字：ModelArts、模型迁移、部署、模型文件、模型配置文件、三方依赖包、模型推理代码。

# 题目六（袁志成）

## 判断题

1、Ptdbg工具提供了模块级dump功能.T（确定）

原因：PDF文档中提到“昇腾AI处理器支持多种调试工具，如... Ptdbg支持模块级dump功能。” 

2、API精度预检主要分为三步:整网dump、multi\_run\_ut、api\_precision\_compare。T（确定）

原因：PDF文档中描述了API精度预检的过程，包括“整网dump”，“multi\_run\_ut”，最后是“api\_precision\_compare”

3、分布式训练的本质是解决单设备内存不足或者单个设备计算能力不足问题,T（确定）

原因：PDF文档中明确指出“分布式训练的本质是解决单设备内存不足或者单个设备计算能力不足的问题。”

4、grad\_tool主要用于监控GPU和NPU训练过程中的梯度差异和监控NPU训练过程中的确定性问题。T(确定)

原因：PDF文档中提到“grad\_tool用于监控GPU和NPU训练过程中的梯度差异和监控NPU训练过程中的确定性问题。

5、使用api\_precision\_compare比对的结果中，某AP|最大绝对误差<0.001,余弦相似度=0.95，该API精度不达标,F（确定）

原因：PDF文档中没有直接提到具体的精度标准，但通常情况下，如果API的最大绝对误差小于0.001且余弦相似度达到0.95，则一般认为精度是达标的。因此，这个判断题的答案应该是错误的，因为这样的误差范围通常被认为是可接受的

6、AOE(Ascend Optimization Engine)优化成功的.mindir模型，在使用时不可以删除AOE知识库，否则会影响该模型的性能。F（确定）

原因：PDF文档中提到“AOE(Ascend Optimization Engine)优化生成的.mindir模型依赖于AOE知识库，因此在使用过程中不能删除AOE知识库，否则会影响模型性能

7、torch\_npu.npu.set\_compile\_mode(it\_compile=False)配置下，会根据当前获得的算子信息，进行融合和优化，在线编译出运行性能更优的算子。F（确定）

原因：PDF文档中描述了torch\_npu.npu.set\_compile\_mode(it\_compile=True)表示在线编译，而it\_compile=False则表示不进行在线编译，而是使用已有的算子。因此设置为False不会触发在线编译和优化

8、converter\_lite是MindSpore Lite提供离线转换模型工具，目前支持的输入模型类型有:MindSpore、TensorflowLite、Caffe、TensorFlow、PaddlePaddle、ONNX、PyTorch.F（确定）

原因：PaddlePaddle不支持

9、模型容易产生过拟合的原因之一是没有太好的抗能力，也就是说如果输入数据经过微小的变动，就可能得到完全不一样的结果。因此，防止模型过拟合的方法之一，就是在训练过程中加入随机噪声帮助训练。T（确定）

10、ModelArts训练作业的运行过程中，如果需要安装第三方依赖包，可以在训练代码目录下放置安装文件，文件内容格式为"包名==版本号“，如“click==6.6”，训练后台会自动下载安装依赖包;目前不支持安装用户自己编译的whl包。F（）

 [https://support.huaweicloud.com/modelarts\_faq/modelarts\_05\_0063.html](https://support.huaweicloud.com/modelarts_faq/modelarts_05_0063.html)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/29d12756-86df-4cdb-9e46-e0319b361d4c.png)

11、单层感知机只能处理线性教据，为了解决非线性分类问题，我们可以使用多层感知机，在输入层和输出层之间多加一些隐藏层。多层感知机中添加的隐藏层数越多，整个网络的分类能力就越强，可以提取的目标特征层次也越高。F(确定)

12、CPU的架构中需要大量的空间去放置续存单元(cache)和控制单元(control)，相比之下计算单元(即算术逻辑单元 Arithmetic Logic Unit,ALU)只占据了很小的一部分，所以CPU在进行大规模并行计算方面受到限制，相对而言更擅长千复杂逻组运算,T（确定）

13、在神经网络中，算子对应网络中层或者节点的计算逻辑，其在数学中的定义是:一个的数空间到的数空间上的映射。卷积操作conv2d最大池化操作maxpooling、大模型中常用的FlashAttention操作等，都是常见的算子:但是激活函数ReLU/softmax等等，并不能成为算子。T（？）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/02b0631a-aa24-4439-9f5a-ac27c2581e06.png)

## 单选题

1.混合精度(Mix Precision)训练是指在训练时，对神经网络不同的运算采用不同的数值精度，MindSpore的哪个模块提供了自动混合精度接口?B（确定）

1.  jt
    
2.  amp
    
3.  trainer
    
4.  Confiq
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b3f4c85a-67c6-4e2f-802c-88d79a053605.png)

2.Mindspore的Cell类是构建所有网络的基类，当用户需要自定义网络时，需要继承Cell类，其中网络的执行需要重写Cel类的哪个方法?A（确定）

1.  construct
    
2.  inference
    
3.  forward
    
4.  Call
    

3.如下场最描述的是昇腾云服务的哪一层核心竞争力:提供一系列适配过异腾算力的模型，用户可以在平台上进行部署、微调、训练等操作，也就是“模型即服务”。B（确定）

1.  云化算力
    
2.  模型开发
    
3.  模型托管
    
4.  模型生态
    

4.如下场景描述的是哪一种机器学习方法:根据数据本身之间的属性对数据进行聚类，相似相近的数据聚在同一类;不相似或不相近的数据分在不同的类中。B（确定）

1.  监督学习
    
2.  无监督学习
    
3.  半监督学习
    
4.  强化学习
    

聚类是无监督学习的一种方法

5.在神经网络训练过程中，如果出现损失函数(loss function)在极值处不停震荡不收敛，那么最可能的原因是哪一项?B（确定）

1.  学习率(learning rate)太小
    
2.  学习率(learning rate)太大
    
3.  隐藏层层数太少
    
4.  隐藏层层数太多
    
5.  激活函数选择了线性函数
    
6.  batch size过大
    

6.以下不属于Deepspeed分布式并行技术的是哪一项?D（确定）

1.  ZeRO1-3
    
2.  3D并行
    
3.  CPU offloading
    
4.  Page Attension
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/72d2863f-deae-4929-bbbe-42120987b305.png)

7.大模型推理全量性能测试不需要覆盖下述哪个维度?A（确定）

1.  profiling-step
    
2.  batch\_size
    
3.  input\_seq\_len
    
4.  out seq\_len
    

在进行大模型推理的全量性能测试时，通常需要考虑多个维度以确保全面评估模型的性能。这些维度包括但不限于不同的批大小（`batch_size`）、输入序列长度（`input_seq_len`）、输出序列长度（`output_seq_len`）等。然而，“profiling-step”并不是一个直接用于性能测试的维度，而是性能分析（profiling）过程中的一种机制或步骤，用于收集性能数据。

8.使用benchmark工具对模型进行精度测试时，二进制输入数据通过哪个参数设置?B（确定）

1.  inData
    
2.  inDataFile
    
3.  benchmarkData
    
4.  BenchmarkDataFile
    

 ![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/23f6ad8d-dd08-45e6-aea2-7e443af57f05.png)

9.以下关于集合通信原语说法错误的是哪项?B（确定）

1.  broadcast是一对多操作
    
2.  scatter是多对多操作
    
3.  gather是多对一操作
    
4.  ReduceScatter是多对多操作
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2b7f396c-8443-437d-aa6c-fd67049ac2d6.png)

10.在使用MindFormers进行大语言模型的文本生成时，可以配置不同的采样策略，如下描述的是哪一种策略:每个时间步，按照token出现的概率由高到底排序，当概率之和大于某个阈值时，就不取后面的样本了:然后对取到的这些token的概率重新归一化后，进行采样。B（确定）

1.  贪心采样
    
2.  Top-p 采样
    
3.  Top-k 采样
    
4.  Beam Search 采样
    

11.通常来讲，算子下发瓶颈识别可以通过搜索观察哪个接口间隙来判断，间隙越多说明存在算子下发瓶颈，间隙越少说明算子下发状态良好。B（确定）

Enqueue

Dequeue

Enstack

Destack

12.AIT(Ascend Inference Toal)是昇腾推理一体化开发工具，其中的debug任务包含多项功能，如果需要基于ONNX进行插入、删除、修改节点等改图功能，应该使用debug任务的哪一项subtask类型?A（确定）

1.  surgeon
    
2.  compare
    
3.  analyze
    
4.  Modify
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/2fa2f338-64e5-4d91-a908-57570e482ea4.png)

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/3c401ee7-362f-4cd9-9778-528a595928e6.png)

13.使用Ascend PyTorch Profiler接口开启PyTorch训练时的性能数据采集，采集CANN软件桟及NPU数据的activities是什么?B（确定）

1.  torch\_npu.profiler.ProfilerActivity.CPU
    
2.  torch\_npu.profiler.ProfilerActivity.NPU
    
3.  torch.profiler.ProfilerActivity.CPU
    
4.  torch.profiler.ProfilerActivity.NPU
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/876f6eed-32d2-48a2-9528-b244e5152fe1.png)

???14.使用benchmark工具对某个图片分类模型进行精度测试时，需要获取一份标准输入数据并保存成二进制文件，通常建议将什么样的数据制作成标准数据?C（确定）

1.  原始的图片数据
    
2.  使用图像处理库(如OpenCV、Image等)读取的图片数据
    
3.  经过预处理后的图片数据![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c3b5966c-5319-486f-88e3-a0a6cb6d60d4.png)
    

15.以下哪个命令可以检查NPU环境中PyTorch环境的基本功能是否正常?A（确定）

1.  python3 -c "import torch;import torch\_npu; a = torch.randn(3, 4).npu(); print(a + a);
    
2.  python3 -c "import torch;a = torch.randn(3, 4).npu(); print(a + a);"
    
3.  python3 -c"import torch\_npu;a = torch.randn(3, 4).npu(); print(a + a);"
    
4.  以上都不对![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/66be7ab2-6edf-4842-910c-cf2b61229513.png)
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a8b2073c-760d-4856-9777-55d42e4b1ba6.png)

16.以下关于梯度监控工具说法错误的是哪项?B（没有关于B的描述，B应该是api对比工具）

1.  通过 torch.nn.Module 提供的 named parameters()方法拿到所有命名参数的张量
    
2.  获取整网中每个pytorch计算API的输入真实张量数值分布
    
3.  用register\_hook给所将参数张量挂上钩子函数
    
4.  通过钩子回调函数可以访问到Module参数每一次训练选代步的梯度数据
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b21075fa-8e00-4026-a1df-f4bb747feeea.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/3cef9968-8283-4f3c-bc60-bcd04fcb5104.png)

17.昇腾性能比对工具compare\_to0ls支持比较GPU与NPU之间、NPU与NPU之间的性能差异，通过对训练耗时和内存占用的比对分析，定位到具体劣化的算子，帮助用户提升性能调优的效率。开启总体性能比对的参数是哪项?B（确定）

1.  enable operator compare
    
2.  enable profiling\_compare
    
3.  enable communication compare
    
4.  enable memory compare
    

[mstt: 针对训练&大模型场景，提供端到端命令行&可视化调试调优工具，帮助用户快速提高模型开发效率 - Gitee.com](https://gitee.com/ascend/mstt/tree/master/profiler/compare_tools)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b32b6d62-510b-497d-a9af-7c29fcd92124.png)

18.以下哪种现象可以说明PyTorch确定性计算开关开启成功且生效: A（？）

1.  多次运行训练脚本，loss曲线趋势保持一致(在同一时刻下降和上升，目偏差幅度始终保持一致)
    
2.  多次运行训练脚本，lo55曲线的值必须保持完全一致，任何差异都是不可以接受的
    
3.  开启确定性开关前后的loss曲线趋势保持一致(在同一时刻下降和上升，且偏差幅度始终保持一致
    
4.  由于集合通信的累加顺序不一致，因此即使打开确定性计算，也无法保证最终的输出
    

19.卷积神经网络(CNN)在计算机视觉领域取得了极大成功，这是因为卷积运算的两大核心思想--局部感知与参数共享--非常适合图像处理，那么如下关于这两个思想的描述中错误的是哪一项?A（确定）

1.  局部感知指的是每个神经元仅与输入层的一小块区域连接，这块局部区域称作感受野(receptive field)
    
2.  局部感知是通过小尺寸卷积核实现的，即卷积核尺寸远小于输入图像尺寸，只探索局部信息
    
3.  参数共亨指的是卷积过程中卷积核的权重不会改变，通过相同的卷积核提取了不同位置的特征
    
4.  参数共享的优点是可以减少计算量，降低内存/显存需求，而局部感知没有这个效果
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/847fb8c7-8600-4f79-9a97-068856f23576.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/15b54649-df88-43d8-8afc-f751867d74b3.png)

## 多选题

1.以下哪些指标是精度对齐时需要关注的?ABCD（？）

1.  loss值
    
2.  grad norm值
    
3.  初始学习率
    
4.  batch size
    

2.通用模型迁移适配过程可以分为哪几个阶段?ABCD（？）

1.  迁移分析
    
2.  迁移适配
    
3.  精度调试
    
4.  性能调优
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f7d739c4-2523-4a7f-8a7e-47372bfcaf0b.png)

3.开发者想在昇腾云服务上使用深度学习框架进行模型训练和推理，如下哪些框架可以满足需求?ABCD（确定）

1.  MindSpore
    
2.  PyTorch
    
3.  Caffe
    
4.  TensorFlow
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/0732fcd5-a05c-4c6a-9395-d2b8a9426db9.png)

4.基于昇腾芯片的集合通信HCCL(Huawei Collective Communication Library)，支持的通信操作包括哪些?ABCD（确定）

1.  AllReduce
    
2.  AllGather
    
3.  broadcast
    
4.  ReduceScatter
    

[HCCL接口简介-集合通信接口-CANN社区版8.0.RC3.alpha001开发文档-昇腾社区 (hiascend.com)](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC3alpha001/apiref/hcclapiref/hcclcpp_07_0001.html)

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/97b00ce7-3e2e-4955-a369-993f96e0edaf.png)

5.ModelArts支持训练模型过程中安装第三方依赖包，其中依赖包安装文件的命名支持以下哪几种格式?ABCD（确定）

1.  pip-requirement.txt
    
2.  pip-requirements.txt
    
3.  requirement.txt
    
4.  reguirements.txt
    

6.模型迁移完成后进行性能调优时，以下哪些是常用的调优方法?ABCD（？）

1.  使能NPU亲和融合API算子与优化器
    
2.  使能二进制编译调优
    
3.  打开确定性计算开关
    
4.  增大模型参数batch size
    

7.Transformer架构提出以来，在自然语言处理(NLP)、计算机视觉(CV)等领域都得到了广泛应用，如下模型中有哪些使用了Transformer架构?ABCE（？）

1.  BERT
    
2.  ViT
    
3.  DETR
    
4.  SENet
    
5.  GPT
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2b1728b6-6220-44cc-89f9-919e2c07f692.png)

8.对于迁移前的训练是基于PyTorch+FSDP的场量，推荐采用哪种方式进行迁移?（BC）

1.  自行编写训练脚本
    
2.  切换到PyTorch2.1及以上版本
    
3.  使用自动迁移工具进行迁移
    
4.  切换成其他框架
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/66e7cd9c-e11c-45fd-ba10-9d571366e3ad.png)

9.GPU环境下确定性计算打开的方式是什么? （BD）

1.  torch.use\_deterministic\_algorithms(True)
    
2.  expOrt HCCL DETERMINISTIC=TRUE
    
3.  expOrt NCCL\_DETERMINISTIC=TRUE
    
4.  expOrt INF NAN\_MODE ENABLE=1
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/0077186b-cdba-44cb-8e85-e150825ddcc1.png)

10.算子融合是一种常见的模型优化方法，将多个算子融合为一个算子，可以减少内存访问和计算的开销，如下选项中哪些是常见的算子融合操作?ABCDE（？）

1.  conv + relu
    
2.  conv + bn
    
3.  conv+ bn + relu
    
4.  bias add + layer norm
    
5.  gemm + elementwise
    

11.在性能调优过程中，通过分析采集profiling数据的timeline发现free time呈现少次大块的特征，在以下原因中可能导致该情况的是哪些项?（ABC）

1.  机器中其他程序抢占CPU资源
    
2.  橙型正在等待数据集加载
    
3.  集群多节点机器读写日志导致频繁抢占I0资源
    
4.  在与其他卡进行卡间通信
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2069cfe0-91f2-443a-a44f-a0703ed21dda.png)

12.客户是一家手机厂商，需要实现智能相册系统，对相册中的图片按照人物、地点、场景等进行分类归档，并且支持使用自然语言搜索图片，如“公园放风筝”、“巴黎旅游”。请问以上任务可能会涉及哪些人工智能技术?ABCDE（确定）

1.  情感分析
    
2.  人脸识别
    
3.  图像描还生成
    
4.  多标签分类
    
5.  视频动作分类
    

13.关于ModelArts提供的昇腾迁移环境，以下说法正确的是哪几项?ABD（确定）

ModelArts提供了配套昇腾硬件环境的基础容器镜像

在昇腾环境上启动容器镜像时，可以使用ASCENDVISIBLE DEVICES指定容器要使用的卡号

容器内无法查看昇腾卡信息，宿主机上可以查看卡信息

ModelArts基础镜像内的PyTorch/MindSpore等AI框架包均安装在Conda环境内

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/291b884a-7b51-4df7-baee-92250c676845.png)

[https://support.huaweicloud.com/usermanual-server-modelarts/usermanual-server-0011.html#section2](https://support.huaweicloud.com/usermanual-server-modelarts/usermanual-server-0011.html#section2)

14.使用ModelArts的开发环境进行模型训练时，如果需要将本地12 GB左右的数据集上传到Notebook，如下哪些操作可以实现该功能?CD（）

1.  直接将文件拖拽到Notebook窗口左边的空白处
    
2.  单击导航栏的Upload Files按钮，打开文件上传界而进行上传
    
3.  将本地文件上传至OBS桶中，然后使用ModelArtsSDK从OBS下载文件至Notebook本地
    
4.  将本地文件上传至OBS桶中，然后使用Moxing接口从OBS下载文件至Notebook本地
    

 ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/d8c68503-ea6b-47c4-811a-79cf07d2b95a.png)

15.使用MindSpore Lite转换工具进行模型转换时，如果出现如下报错，可能的原因有哪些?CD（？）

\[WARNING LITE(1 1979,7fbdc90a8ec0,converter lite):2021-12-13-16:20:49.506.071 \[mindspore/lite/tools/common/protobuf utils.c

c:94\]ReadProtoFromBinaryFile\]Parse \*\*\*.onnx failed.

\[ERROR LITE(11979,7fbdc90a8ec0,converter lite):2021-12-13-16:20:49.506.122 \[mindspore/lite/build/tools/converter/parser/onnx/

onnx op\_parser.cc:3079\] initOriginModel\] Read onnx model file failed, model path: .ml audio kit vocals resunet.onnx

\[ERROR\] LITE(1 1979,7fbdc90a8ec0,converter lite):2021-12-13-16:20:49,.506,131 (mindspore/lite/build/tools/converter/parser/onnx/

onnx op parsercc:3026\]Parse\]init origin model failed

1.  存在转换工具不支持的算子
    
2.  转换工旦不支持该算子的某种特殊属性或参数
    
3.  模型路径错误
    
4.  模型文件损坏
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/dde3f594-d85f-4b74-8887-96769f69a548.png)

[https://www.mindspore.cn/lite/docs/zh-CN/master/troubleshooting\_guide.html#%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%A4%B1%E8%B4%A5](https://www.mindspore.cn/lite/docs/zh-CN/master/troubleshooting_guide.html#%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E5%A4%B1%E8%B4%A5)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a93983af-3485-46f8-8a57-ed8999536cfc.png)

# 题目七（绪其军）

## 判断题

36、性能优化的总体原则为:减少Device算子下发时间、减少Host算子执行时间。F（确定）

37、converter lite是Mindspore Lite提供离线转换模型工具，目前支持的输入模型类型有:Mindspore、Tensorflow Lite、Caffe、TensorFlow、PaddlePaddle、ONNX和PyTorch. F（确定）

38、NPU和GPU芯片对浮点计算指令npu\_exp(x)=gpu\_exp(x)。F（确定）

39、使用compare tools比对性能数据，结果包含了算子在执行耗时、通信耗时、内存占用的优劣，内存使用数据分析前提是Profiling信息采集时打开profile\_memory=True开关。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/8d14f8bc-3419-4011-90e0-f87707c6d167.png)

40、迁移过程的精度问题一般包括:在汗移正确的前提下，发生loss曲线与CPU/GPU差异不符合预期，下游任务评测结果准确度与CPU/GPU差异不符合预期的情况。

41、模型的超参大致可以分为学习率，batch-size，并行切分策略，学习率warm-up，模型参数，FA配置等，用户在进行NPU精度和GPU精度比对前，需要保证两边的配置一致。T

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/902f4c3e-5d56-4f65-8adf-d97fef179c72.png)

42、模型并行的好处是，省去了多个设备之间的梯度 AlReduce;但由于每个设备都需要完整的教据输入，数据会在多个设备之间进行广播，产生通信代价。

43、Ptdbg工具提供了模块级dump功能。T（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/11d0fd35-6936-4d4b-acba-67c469a21bb0.png)

44、在fp16混合精度训练场景下，如果Loss scale在连续的50个step没有持续降低，这种情况可以判定为正常溢出。F（确定）

45、性能问题通常出现在算子下发和执行的异步过程中，因此性能优化的总体原则为:减少Host算子下发时间和减少Device算子执行时问。T（确定）

46、模型容易产生过拟合的原因之一是没有太好的抗噪能力，也就是说如果输入数据经过微小的变动，就可能得到完全不一样的结果。因此，防止模型过拟合的方法之一，就是在训练过程中加入随机声帮助训练。T（确定）

47、提前终止(early stop)是一种防止欠拟合的方法，即在模型对训练数据集完全收敛之前停止迭代来防止欠拟合。可能的做法是，在每一个Epoch结束时计算验证集的loss或准确率，当发现loss上升或者准确率不再提高时，就提前停止训练。F（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b80f25f4-4f1f-4f4a-a871-a5b7910639d1.png)

48、单层感知机只能处理线性数据，为了解决非线性分类问题，我们可以使用多层感知机，在输入层和输出层之间多加一些隐藏层。多层感知机中添加的隐藏层数越多，整个网络的分类能力就越强，可以提取的目标特征层次也越高。F（确定）

49、ModelArts不支持跨站点访问OBS桶，通过0BS下载文件到Notebook中时，请确保读取的OBS桶和Notebook处于同一站点区域.T（确定）  T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2f60d7b3-155c-485a-8f19-a1a0e2c99105.png)

50、为了在昇腾上使用PyTorch框架，当前推荐的方式是通过侵入式修改源码实现对昇腾NPU设备的支持，使用的时候需要编译安装patch后的PyTorch源码，如此可获得最好的扩展性。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4cc83717-9a79-4c10-bbe8-486b5cbf4603.png)

## 单选题

16、以下关于离线模型转换评估工具Tailor描述错误的是哪一项?B（？）

1.  Tailor是用于模型转换(ONNX到MindIR)和性能分析的辅助工具
    
2.  Tailor的主要功能包括:模型转换,性能测试&精度测试、Profiling性能分析、ONNX网络修改
    
3.  Tailor在分析过程可以开启AOE优化
    
4.  Tailor可以查询ONNX模型的输入输出信息
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/9e753be2-a755-4433-a480-e28084a44578.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b2366b9c-6edd-40bf-a9af-3b5a79ef104e.png)

17、如下信息是使用哪一条命令执行得到的?+---------pu-smi23.0.rc2.2 Version:23.0.rc22|+--------U Name | Health | Power(W) Temp(C) Hugepages-Usage(page)llChipBus-ld AlCore(96) Memory-Usage(MB) HBM-Usage(M8)|+=====-===:=====H4 910B4|OK|84.239 0/01010000:81:00.0100/03170/32768|+=======p|Process id |Process name | Process memory(MB)|+=============二二二三二ニ二ニニニ二二二二二========================+ No running processes found in NPÚ 4 +=================+====================+===================+

A（？）

1.  npu-smi info
    
2.  npu-smi info watch
    
3.  npu-smi info -l
    
4.  npu-smi info-m
    

[https://www.hiascend.com/document/detail/zh/Atlas%20200I%20A2/24.1.RC2/re/npu/npusmi\_007.html](https://www.hiascend.com/document/detail/zh/Atlas%20200I%20A2/24.1.RC2/re/npu/npusmi_007.html)

18、使用benchmark工具对模型进行精度测试时，二进制输入数据通过哪个参数设置?B

1.  inData
    
2.  inDataFile
    
3.  benchmarkData
    
4.  benchmarkDataFile
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e26cc11e-75f2-420b-8cef-1591957cd2c2.png)

19、以下关于PTAdapter说法错误的是哪一项?D

1.  使用时需要在训练任务启动入口添加import torch\_npu
    
2.  基于monkey-patch的原理实现自动迁移
    
3.  可以将cuda和nccl操作映射到npu和hcdl对应操作
    
4.  可以自动迁移GPU高阶自定义融合算子
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0f5129a4-13f6-4c43-a17e-bc6bf20131f9.png)

20、模型脚本迁移推荐使用如下哪种方式?A

1.  自动迁移
    
2.  手动迁移
    
3.  复制粘贴
    
4.  分析工具扫描
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f6d6f8a7-d828-4bcc-ae92-68719b856053.png)

21、以下哪种现象可以说明PyTorch确定性计算开关开启成功且生效: A（？）

1.  多次运行训练脚本，loss曲线趋势保持一致(在同一时刻下降和上升，且差幅度始终保持一致)
    
2.  多次运行训练脚本，loss曲线的值必须保持完全一致，任何差异都是不可以接受的
    
3.  开启确定性开关前后的loss曲线趋势保持一致(在同一时刻下降和上升，且偏差幅度始终保持一致)
    
4.  由于集合通信的累加顺序不一致，因此即使打开确定性计算，也无法保证最终的输出是完全一致的
    

22、针对于常稳训练的精度问题(前期loss收敛趋势和标杆一致，后期在某几个step之后loss逐渐偏离标杆)，以下那种手段最适合进行问题定位?B（？）

1.  记录loss偏差开始的step，重新训练模型，并在对应step通过工具dump数据进行分析
    
2.  记录loss偏差开始的step，加载距离异常发生点最近的ckpt，并在对应step通过工具dump数据进行分析
    
3.  加载距离异常发生点最近的ckpt，打开确定性计算开关，观察是在哪个step稳定出现偏差，重新运行后在对应step通过工具dump数据进行分析
    
4.  打开确定性计算开关，重新训练模型，观察是在哪个step稳定出现偏差，重新运行后在对应step通过工具dump数据进行分析
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d5713cbd-9c00-4f0c-aaa8-84e1d3039d6c.png)

23、下述哪个方法可以用来处理神经网络中的过拟合现象?D（确定）

1.  Dropout
    
2.  Batch Normalization
    
3.  正则化
    
4.  都可以
    

24、以下关于分布式数据并行DDP的说法正确的是哪项?C（确定）

1.  DDP采用单进程，一台机器上运行一个进程
    
2.  DDP通信开销大，server要和每一个worker进行梯度传输，当server和worker不在同一台机器时，server带宽会成为瓶颈
    
3.  DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长
    
4.  DDP通过收集梯度到 device\[0\]，在device\[0\]更新参数，然后其他设备复制 device\[0\]的参数实现各个模型同步
    

25、在性能调优过程中，通过分析采集profiling数据的timeline发现free time呈现多次小块的特征，但是相对标杆性能耗时较大，可考虑使用什么方法进行性能调优?

1.  增大模型参数batch size
    
2.  增大模型参数number workers
    
3.  使用AOE算子调优
    
4.  将数据集文件转移至节点本地磁盘
    

26、以下关于NPU融合算子说法正确的是:C（？）

1.  NPU上的融合算子性能一定比对应小算子性能更好
    
2.  NPU上的融合算子都能够找到对应的cuda融合算子进行对标
    
3.  训练场景中，使用融合算子能够缓解小算子造成的算子性能下发瓶颈
    
4.  融合算子在使用上相比于小算子来说是完全等价的，即小算子上能够支持的输入，融合算子也能够支持
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/82609189-fed2-4802-878b-726fa5b2ad8e.png)

27、定位AI CPU算子时，通过修改dtype类型消除AI CPU算子可能引起什么问题?C（？）

1.  模型显存占用问题
    
2.  数据类型转换导致下发算子变少
    
3.  数据类型转换导致的精度问题
    
4.  数据类型转换同步操作，打断异步下发
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/de66bb24-441a-420b-a786-7d6af829d272.png)

28、客户是一家购物平台，需要实现智能客服系统，回答顾客在售前、售中、售后等阶段的咨询问题。请问以上任务描述主要属于人工智能的哪个领域应用?B

1.  计算机视觉
    
2.  自然语言处理
    
3.  语音信号处理
    
4.  决策规划系统
    

29、在卷积神经网络(CNN)中，感受野(receptive field)指的是神经网络中神经元“看到的"输入区域，越深层的神经元看到的输入区域越大。假设在某个模型中，所有卷积核的尺寸均为3"3，步长(stride)均为1，laver1是输入层，则第二层layer2中每个神经元可看到ayer1上3\*3大小的区域，那么第四层layer4中每个神经元可以看到的layer1上区域是多大? D

1.  4\*4
    
2.  5\*5
    
3.  6\*6
    
4.  7\*7
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0450aa09-ddd9-4b30-a2bb-c250c7eb97e7.png)

30、过拟合是机器学习中需要避免的现象，在其它条件不变的前提下，以下哪种做法容易引起过拟合问题?C

1.  增加训练数据集的样本量
    
2.  减少神经网络中隐藏层的节点数
    
3.  减少或不做数据增强
    
4.  使用dropout等正则化方法
    

31、如下关于计算图的描述，错误的是哪一项?B（确定）

1.  动态图的核心特点是图的构建和计算同时发生
    
2.  动态图对全局的信息掌握更丰富，可做的优化也会更多
    
3.  静态图在计算阶段，根据输入数据执行编译好的图得到计算结果
    
4.  静态图无法实时拿到中间计算结果，中间过程对于用户来说是个黑盒
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/cea68326-4b7f-4812-92a3-20c504ad352a.png)

32、如下场景描述的是昇腾云服务的哪一层核心竞争力:提供一系列适配过昇腾算力的模型，用户可以在平台上进行部署、微调、训练等操作，也就是“模型即服务"。B（确定）

1.  云化算力
    
2.  模型开发
    
3.  模型托管
    
4.  模型生态
    

原因：模型托管主要侧重于对模型的存储和管理；模型生态则更侧重于整个模型相关的生态系统，包括开发者、使用者、模型的交流与共享等方面；云化算力则主要指云计算提供的强大计算能力。

而这里着重描述的是针对模型的开发相关服务，所以是模型开发。

33、某客户的AI业务上线后，其业务流量曲线显示，每天18点到0点流量都有很大幅度上升，昇腾云服务通过资源共池、多种计费模式等功能，帮助客户进行了灵活的资源配置，降低了50%的资源成本。以上幸例体现的是昇腾云服务的哪一项关键能力?C

1.  立等可取，即开即用
    
2.  集群优化，释放性能
    
3.  全栈优势，高效诊断
    
4.  弹性灵活，按需使用
    
5.  安全可靠，上云无忧
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5690f3ae-1c85-4120-8d77-5e993be96487.png)

34、在使用ModelArts开发环境时，云硬盘的存储路径默认挂载在某个目录下，用户在Notebook实例中的所有文件读写操作都是针对该存储目录下的内容操作，该存储目录是如下哪一项?C

1.  /home/work
    
2.  /home/workspce
    
3.  /home/ma-user/work
    
4.  /home/ma-user/workspce
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/3c3842ba-044d-4ef0-ada9-905173673006.png)

35、采用converter\_lite工具进行模型转换时，可在配置文件中通过precision\_mode参数指定精度模式，该参数的默认设置为如下哪一项?D（？）

1.  enforce fp16
    
2.  enforce fp32
    
3.  preferred fp32
    
4.  enforce origin
    
5.  preferred optimal
    

## 多选题

1、模型训练时，在ModelArts管理控制台可以査看资源利用率，如果发现GPU/NPU的平均利用率较低，如下做法中哪些可以提升计算单元利用率?AB（？）

1.  适当增大算法的batch size超参数
    
2.  提升数据读取效率、数据增强性能
    
3.  控制模型保存的频率
    
4.  尽呈减少日志打印的频率
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/825a188d-f63d-4ba3-a4ed-1c8a5c901f47.png)

2、开发者想在昇腾云服务上使用深度学习框架进行模型训练和推理，如下哪些框架可以满足需求?ABD

1.  Mindspore
    
2.  PyTorch
    
3.  Caffe
    
4.  TensorFlow
    

3、MindFormers提供了text generator(文本生成)方法，旨在让用户能够使捷地使用生成类语言模型进行文本生成任务，该方法支持的推理能力有哪些?ABC（？）

1.  增量推理
    
2.  Batch推理
    
3.  流式推理
    
4.  分布式推理
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/fe9aafc0-46ca-4e48-8697-58ae952ad5e4.png)

4、客户是一家手机厂商，需要实现智能相册系统，对相册中的图片按照人物、地点、场景等进行分类归档，并且支持使用自然语言搜索图片，如“公园放风筝”、“巴黎旅游”。请问以上任务可能会涉及哪些人工智能技术?。BCD

1.  情感分析
    
2.  人脸识别
    
3.  图像描述生成
    
4.  多标签分类
    
5.  视频动作分类
    

5、目前在AI社区里，很多厂商都发布了开源LM(large language model，大语言模型)，这些模型通常分为两种类别:base模型、chat模型，关于这两类模型的描述正确的有哪些?ABCD（？）

1.  base模型一般只经历了预训练阶段，使用海呈无标签的文本数据进行了无监督学
    
2.  base模型更适合文本补全等基础任务，具有更强的泛化能力
    
3.  chat模型在base模型基础上，X经历了有监督微调等阶段，更适合多轮对话任务
    
4.  如果需要应用到特定领域的下游任务，且拥有大星的有标签数据，更建议在chat模型上做微调
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/33ba804c-0c2e-4514-88fa-73b399551980.png)

6、如果迁移前发现昇腾机器上的固件驱动版本过老，需要重新安装，以下说法正确的是哪几项?ABCD（？）

1.  固件安装完后需要reboot重启机器才能生效
    
2.  安装驱动的命令为./Ascend-hdk-型号-npu-driver\_版本号\_linux-aarch64.run --full --install-for-all
    
3.  覆盖安装的场景下，安装顺序应该为先固件再驱动的顺序
    
4.  安装固件的命令为./Ascend-hdk-型号-npu-firmware 版本号.run --full
    

[安装NPU驱动固件-昇腾软件安装指南-Atlas 800I A2 推理服务器-推理部署指南-快速部署8.0.RC1开发文档-昇腾社区 (hiascend.com)](https://www.hiascend.com/document/detail/zh/quick-installation/24.0.RC1/quickinstg/800I_A2/quickinstg_800I_A2_0007.html)

7、下列哪些手段可能消除AICPU算子?ABCD（？）

1.  尝试修改对应代码，通过矩阵计算的方式重写代码逻辑
    
2.  修改输入数据的dtype
    
3.  尝试升级cann包
    
4.  升级pytorch版本
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/511d1875-95c1-4e90-803a-467e6259cebe.png)

8、在无标杆性能数据的情况下，可考虑什么方式进行性能调优?BCD（？）

1.  使用权威网站的性能数据作为目标
    
2.  替换NPU亲和api算子
    
3.  尝试使用apex优化库
    
4.  定位ai cpu算子并尝试使能ai core
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/dab816a3-aab3-4d73-9773-79dc6d1d689f.png)

9、昇腾大模型精度定位常用的手段有哪些?CD（？）

1.  减小模型层数
    
2.  减小集群节点
    
3.  关闭大kernel融合算子
    
4.  减小TP切分策略
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/505e0e70-9e73-4f57-ba82-082cba294032.png)

10、在迁移到昇腾后以及在昇腾调测模型时的精度对齐中，通常需要与标杆实现进行精度结果比对，以下哪些是常用的标杆内容?ABCD（？）

1.  CPU
    
2.  GPU
    
3.  融合算子的小算子实现
    
4.  历史已有的正常的NPU结果
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/78eac138-e97f-4aca-b70c-f739075473d0.png)

11、关于Ascendspeed仓，下列说法正确的是哪几项?ABCD（？）

1.  Ascendspeed是基于Megatron-LM仓库做的昇腾适配
    
2.  Ascendspeed是针对华为异腾设备的大模型加速库
    
3.  使用时，需要在训练脚本前增加import ascendspeed.megatron\_adaptor
    
4.  该仓库早期也包含模型代码、下游任务评测等解决方案内容，目前该部分内容已迁移至ModelLink仓库
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4c333072-e1ba-4c54-8be6-7a45d8609546.png)

12、精度对比工具ptdbg的seed\_all接囗能够固定哪些随机性?ABCD（？）

1.  固定random模块的随机生成器种子
    
2.  固定numpy中随机生成器种子
    
3.  固定torch随机种子
    
4.  固定数据集dataloader加载顺序
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f1bfae32-319b-4f81-b45c-6ea926101850.png)

13、基于昇腾芯片的集合通信HCCl(Huawei Collective Communication Library)，支持的通信操作包括哪些?ABCD

1.  AllReduce
    
2.  AllGather
    
3.  broadcast
    
4.  ReduceScatter
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e9c5ba95-edfd-4466-98dc-8f9caae15af0.png)

14、在模型推理性能优化分析中，性能瓶颈主要来自如下哪几项?AEF（？）

1.  Host算子下发
    
2.  Host算子执行
    
3.  Host算子编译
    
4.  Device算子下发
    
5.  Device算子执行
    
6.  Device算子编译
    

15、msprof命令行工具采集到的timeline数据，包含如下哪几项内容?ABC

1.  应用层数据
    
2.  CANN数据
    
3.  底层NPU数据
    
4.  算子可选优化项
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f1dcbb13-fc07-4314-9664-1c53973f867b.png)

# 题目八（万超）

## 判断题

1.converter lite是MindSpore lite提供离线转换模型工具，日前支持的输入模型类型有:MindSpore、TensorFlow Lite、Cafe、TensorFow、PaddlePaddle、ONNX和PyTorch. F

2.性能优化的总体原则为:减少Device算子下发时间、减少Host算子执行时间。F（确定）

3.Ptdbg工具提供了模块级dump功能。T（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/8371a5f4-55b6-4648-86de-569b307c6882.png)

4.分布式训练的本质是解决单设备内存不足或者单个设备计算能力不足问题,T（确定）

5.部分NPU硬件对FP32的限制，导致混合精度问题，造成精度损失，在训练过程中避免开启混合精度方式。F

6.在fD16混合精度训练场景下，如果Loss scale在连续的50个step没有持续降低，这种情况可以判定为正常溢出。

7.MA-Advisor是一款迁移辅助工具，提供了profiing分析并给出专家调优建议，包含调度性能分析、AICPU调优、亲和api替换建议等功能。

8.集合通信中AllReduce操作是将多个线程的数据聚合再分发到每一个节点，但每个节点数据不会相同。F（确定）

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclpython\_07\_0018.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/apiref/hcclapiref/hcclpython_07_0018.html)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/582a1562-cd98-470a-a9f1-51df632d8fc8.png)

9.优化器并行-ZeRO主要思想是在训练过程中去除冗余数据，ZeRO有三个不同优化级别，对模型状态进行不同程度的分片。T

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/33f5e57c-a81f-4e2a-af7d-519718ffb0e5.png)

10.当神经网络非常巨大，甚至网络可能巨大到无法存放到单一计算设备中，这时候，可以采用模型并行策略省去多个设备之间的梯度AlIReduce操作，从而优化梯度同步和教据通信开销。F

11.神经网络的训练过程，就是通过对训练数据集的学习，调整神经网络中每个神经元的参数，使得损失函数的值取得最高或者相对较高的值。因此，训练的目标就是要让损失函数的值尽可能的大。 F

12.深度学习与传统机器学习算法之间的区别在于，后者无需进行手工特征提取工作，也就是说，我们建议在进行深度学习之前要首先完成特征提取的工作。F

13.神经网络中如果不使用激活函数(activation function)，那么每一层节点的输入都是上层输出的线性函数，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，网络的表达能力就相当有限。因此，引入非线性激活函数主要就是为了添加非线性因素，增强深层神经网络的表达能力。T（确定）

14.ModelArts训练作业的运行过程中，如果需要安装第三方依赖包，可以在训练代码目录下放置安装文件，文件内容格式为“包名==版本号”，如"click=-6.6”，训练后台会自动下载安装依赖包;目前不支持安装用户自己编译的whl包。F（？）

15.MindSpore支持使用面向对象编程范式，不提供纯函数式编程的支持 F

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c6d36ea7-b1c1-4dca-96f9-70160f4d14bb.png)

## 单选题

1.AIT(Ascend nference Tool)是昇腾推理一体化开发工具，可执行多项任务，如果需要分析昇腾推理设备对输入模型的支持度情况，包括算子支持情况、算子定义、算子输入等，应该使用如下哪一项task类型?C

A. benchmark

B. transplt

C. analyze

D.profile

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/cbb0e9f9-16ac-458d-a461-be672a7def74.png)

2.使用benchmark工具对模型进行精度测试时，如果输出了如下信息，那么执行命令时设定了哪个参数?----------------------------------------------------

\------opType avg(ms) percent calledTimess opTotalTime Activation 0.006900 0.002510 100.069000 BiasAdd 0.012800 0.004657 20 0.128000 Comv2D 2.488500 0.905401 20 24.885004 MatMU1 0.137400 0.049991 20 1.374000 Nchw2Nhwc 0.017400 0.006331 20 0.174000 Pooling 0.049400 0.017973 20 0 494000 Reshape 0,.000900 0.000327 10 0.009000 shape 0.002300 0.000837 10 0.023000 SoftMax 0.013300 0.004839 10 0.133000 stack 0.009900 0.003602 10 0.099000 stridedslce 0.009700 0.003529 10 0.097000 total time :2.90800 ms, kernel cost : 2.74851 ms  A

A. timeProfiling

B. operatorProfiling

C. layerProfiling

D. benchmarkProfiling

3.模型推理时，出现OOM(Out OfMemory)错误，则如下哪个改动有助于解决问题? D

1.  数据精度由fp16->bf16
    
2.  数据精度由 fp16 ->fp32
    
3.  数据精度由 bf16 ->fp32
    
4.  数据精度由 fp32 ->fp16
    

4.采用converter.lite工具进行模型转换时，可在配置文件中通过precision\_mode参数指定精度模式，该参数的默认设置为如下哪一项?D（？）A

1.  enforce fp16
    
2.  enforce fp32
    
3.  preferred fp32
    
4.  enforce origin
    
5.  preferred optimal
    

5.关于昇腾精度定位问题分析，以下说法正确的是: C（？）

1.  只要loss和标杆对齐(满足一定的偏差阈值)就说明精度已经没有问题了
    
2.  只要昇腾和GPU在相同输出时，API的输出结果不一致就可以认为是昇腾算子有问题
    
3.  算子的性能和精度存在此消彼长的关系，需要根据实际情况进行权衡
    
4.  GPU上同等精度输出可以作为真值参考，所以要保证所有NPU的输出需要尽可能地和GPU对齐
    

6.以下不属于MindSpore原生分布式并行策略的是哪一项?B（确定）

1.  数据井行
    
2.  算力并行
    
3.  自动井行
    
4.  半自动升行
    

[https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3.1/parallel/overview.html](https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3.1/parallel/overview.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/1f5a7a7e-2eb2-44e8-a7b9-737b4e90715f.png)

7.以下不属于DeepSpeed分布式并行技术的是哪一项?D（确定）

1.  ZeRO1-3
    
2.  3D并行
    
3.  CPU offloading
    
4.  Page Attension
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/994926cb-fff6-48ba-b05f-d0a8aa12b55e.png)

8.以下哪项不是常见的集合通信库实现? D（确定）

1.  OpenMPI & MPICH
    
2.  NCCL
    
3.  Gloo
    
4.  CuDNN
    

9.下面哪一项是昇腾AI处理器的计算核心，负责执行矩阵、向量、标量计算密集的算子任务? B（确定）

1.  AI CPU
    
2.  Al Core
    
3.  控制CPU
    
4.  任务调度器
    

10.以下不属于模型迁移开发全流程的是哪一项?C（确定）

1.  迁移评估
    
2.  模型代码迁移
    
3.  模型可视化
    
4.  精度性能调优
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5a000c76-5939-42eb-ae5f-6d85f9e71ae6.png)

11.NPU环境下对溢出行为的支持模式分为饱和模式和非饱和模式，其中非饱和模式是和 GPU一致的，在精度对齐阶段推荐将其打开，其打开的配置方式是什么?D（确定）

1.  eXPOrt ASCEND LAUNCH BLOCKING=1
    
2.  export HCCL DETERMINISTIC=TRUE
    
3.  exPOrt NCCL DETERMINISTIC=TRUE
    
4.  eXPOrt INF NAN\_MODE ENABLE=1
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4c3d57ae-7315-4011-b8cd-c16dbde79a04.png)

12.以下哪项不属于算子精度问题分析流程? C（？）

1.  溢出检测
    
2.  dump数据
    
3.  hccl检测
    
4.  通过预检工具比对数据
    

13.完成精度调试的标志是什么?B（？）

1.  Loss与标杆完全对齐
    
2.  采用常规数据集评估模型分数符合社区实践评分预期
    
3.  模型在验证集上的准确率达到一定水平
    
4.  以上都不是
    

14.客户是一家医院，需要开发一款应用辅助医生进行医学诊断，场景是CT影像，需要识别出其中的病灶区域并测量尺寸。请问以上任务最可能使用的人工智能技术是哪一项? C（确定）

1.  图像分类
    
2.  物体检测
    
3.  图像分割
    
4.  目标跟踪
    

15.在卷积神经网络(CNN)中，感受野(receptive feld)指的是神经网络中神经元"看到的”输入区域，越深层的神经元看到的输入区域越大。假设在某个模型中，所有卷积核的尺寸均为3“3，步长(stride)均为1，(ayer1是输入层，则第二层layer2中每个神经元可看到layer1上3\*3大小的区域，那么第四层\[ayer4中每个神经元可以看到的layer1上区域是多大? D（确定）

1.  4\*4
    
2.  5\*5
    
3.  6\*6
    
4.  7\*7
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/331d75ad-9ffc-4020-9f4d-22f2d8a26222.png)

16.循环神经网络(RNN)擅长处理类似自然语言语句这样的序列数据，根据输入输出不同它可以有多种不同的结构，如one-to-one，one-t0-many;many-to-one，many-to-many等，那么针对中文命名实体识别任务，应该使用哪种RNN结构? D（？）

1.  one-to-one
    
2.  one-to-many
    
3.  many-to-one
    
4.  many-to-many
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/4aa31974-b772-44a7-a3b0-aff9cdcfaef4.png)

17.ModelArts支持开发者使用本地IDE连接到Notebook开发环境进行远程开发，此时需要使用以下哪一项进行鉴权认证? A（确定）

1.  秘钥对
    
2.  AK/SK
    
3.  华为账号密码
    
4.  项目ID
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/223919ea-9b41-4d0c-8898-2df92bacba96.png)

18.Mindspore支持动态图和静态图两种模式，可以通过set\_context接口来设置运行环境，如果需要设置为动态图运行模式，该接口的mode参数应该如何设置? A（确定）

1.  PYNATIVE\_MODE
    
2.  GRAPH MODE
    
3.  DYNAMIC MODE
    
4.  ASCEND MODE
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/9fa64806-27c8-499f-9fa2-6de8b0ea9c0d.png)

19.在ModelArts中使用自定义算法进行模型训练时，如果训练数据集包含大量小文件，整体大小在20G左右，为了提升数据读取效率，推荐的做法是如下哪一项?B（确定）

1.  将训练数据集放在代码OBS日录下，随训练代码一起加载
    
2.  将训练数据集上传至OBS，训练代码中解析输入路径参数，创建算法时配置输入管道，创建训练作业时填写数据集OBS路径
    
3.  将训练数据集在本地压缩成zip文件，上传至OBS，训练代码中使用Moxing接口从OBS下载至训练作业的/cache路径下
    
4.  将训练数据集上传至云硬盘，挂载到训练服务器或集群下![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/17ea0208-1dda-4fd9-a8ee-83217068cb2a.png)
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/18f2b984-06fd-4d92-82dc-b7d4f8b91175.png)

20.视频监控任务，客户希望使用工地上部署的摄像头，检测画面中的工人是否佩戴了安全帽;此时我们已经训练好了一个检测模型，客户也搜集了一些测试图片，希望测试一下模型的效果。针对以上场景，建议使用ModelArts的哪一种AI应用部署方式进行测试:A（？）

1.  在线服务
    
2.  离线服务
    
3.  边缘服务
    
4.  批量服务
    

## 多选题

1.如下哪些工具可以将其他框架的模型转换为可在异腾设备上运行的模型? AB（？）

1.  Tailor
    
2.  converter lite
    
3.  ONNX-PTO
    
4.  Transfer2NPU
    

2.msprof命令行工具采集到的timeline数据，包含如下哪几项内容?ABC（确定）

1.  应用层数据
    
2.  CANN数据
    
3.  底层NPU数据
    
4.  算子可选优化顷
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/cedfe3e4-b6ad-4ed9-a68c-5d5d1a28a237.png)

3.迁移分析工具PyTorch Analyse支持哪几项内容的分析?ACD（确定）

1.  算子支持情况分析
    
2.  精度分析
    
3.  动态shape分析
    
4.  三方库API支持情况分析
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/a4acf368-70b8-4205-bb83-61c985be99ac.png)

4.在性能调优过程中，通过分析采集profling数据的timeline发现free time呈现少次大块的特征，在以下原因中可能导致该情况的是哪些项?（？）

1.  机器中其他程序抢占CPU资源
    
2.  模型正在等待数据集加载
    
3.  集群多节点机器读写日志导致频繁抢占I0资源
    
4.  在与其他卡进行卡间通信
    

5.pytorch框架动态图训练性能调优时，对于算子计算性能存在劣化的情况，开发者可以自行尝试哪些优化手段?BCD（？）

1.  AOE调优
    
2.  消除AICPU算子
    
3.  尝试升级CANN包
    
4.  增大batchsize
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/0dbaa718-dfd7-4727-97fd-b33e272533f1.png)

6.下列哪些手段可能消除AICPU算子?ABCD（？）

1.  尝试修改对应代码，通过矩阵计算的方式重写代码逻辑
    
2.  修改输入数据的dtype
    
3.  尝试升级cann包
    
4.  升级pytorch版本
    

7.pytorch框架训练性能调优，基于Ascendlnsight可视化Profiling数据后发现CPU侧dataloader任务耗时占比很高，可能的优化手段有哪些?ABCD（确定）

1.  排查数据所在磁盘是否存在I〇瓶颈
    
2.  设置pin\_memory=True参数
    
3.  调整num workers参数
    
4.  检查数据格式，避免使用zip， targz等数据格式，提前解压数据
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/88e7ae59-5aab-4b33-a820-f69962eebe58.png)

8.如果使能精度对比工具后模型精度异常现象消失，说明该型的精度异常的原因可能是什么?（？）ACD

1.  可能是模型训练时使用了drouout，且不等于零
    
2.  可能是算子下发的时序问题或者内存踩踏问题
    
3.  可能是模型训练的算子的确定性计算存在问题，导致精度异常
    
4.  可能是模型的算子存在累积偏差
    

9.pytorch框架动态图训练，CV类型小模型例如resnet,mibilenet等存在通信的场景有哪些?AD（？）

1.  反向传播过程中对多卡梯度聚合
    
2.  Relu激活函数导致多卡通信
    
3.  dataloader加载数据时数据分发
    
4.  前向传播过程中syncBatchNorm导致多卡通信
    

Relu激活函数本身不会导致多卡通信，因为它是一个逐元素的操作，不需要跨GPU交换数据 

10.在无标杆性能数据的情况下，可考虑什么方式进行性能调优?ABCD（？）

1.  使用权威网站的性能数据作为日标
    
2.  替换NPU亲和api算子
    
3.  尝试便用apex优化库
    
4.  定位ai cpu算子并尝试使能ai core![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/bada4aee-d569-4fcb-9cad-add610b8aaf5.png)
    

11.在Transformer架构提出之前，自然语言处理领域使用最多的是各种类型的循环神经网络(RNN)，如下关于RNN与Transformer的描述正确的有哪些?ABCD（？）

1.  虽然有LSTM/GRU等改进形态，但RNN处理长距离依赖的能力仍然不够好
    
2.  Transformer架构可以直接计算序列中任意两个位置之间的关系，使得模型能够有效地捕获长距离依赖信息
    
3.  RNN是时序结构，当前时刻的输入依赖前一时刻的输出，不太适合做并行化
    
4.  Transformer架构可以高效地并行处理整个序列，推理时也可以并行化输出完整的句子
    

12.在神经网络训练过程中，如果损失函数(loss function)出现NaN，那么可能的原因和解决方法有哪些?ABCDE（？）

1.  可能是学习率(learning rate)设置过高，需要降低
    
2.  可能是计算过程中用0作为了除数，需要排查
    
3.  可能是因为梯度爆炸的原因，可以使用梯度裁剪(gradient cipping)来解决
    
4.  可能是batch size设置得过大，可以调小一些试试
    
5.  可能涉及指数运算并得到无穷(INF)值，如softmax中在计算exp(x)末做特殊处理
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/04b61a04-0a57-4374-9e60-c6a0c89a390d.png)

13.开发者想在昇腾云服务上使用深度学习框架进行模型训练和推理，如下哪些框架可以满定需求?ABD（确定）

1.  MindSpore
    
2.  PyTorch
    
3.  Caffe
    
4.  TensorFlow
    

14.ModelArts支持训练模型过程中安装第三方依赖包，其中依赖包安装文件的命名支持以下哪几种格式?ABCD（确定）

1.  pip-requirement.txt
    
2.  pip-requirements.bxt
    
3.  reguirement.txt
    
4.  requirements.txt
    

15.MindFormers提供了text generator(文本生成)方法，旨在让用户能够便捷地使用生成类语言模型进行文本生成任务，该方法支持的推理能力有哪些?ABC（？）

1.  增量推理
    
2.  Batch推理
    
3.  流式推理
    
4.  分布式推理
    

# 题目九（钱壮）

## 判断题

1.AOE(Ascend Optimization Engine)优化成功的.mindir模型，在使用时不可以删除AOE知识库，否则会影响该模型的性能F（确定）

2.性能优化的总体原则为:减少Device算子下发时间、减少Host算子执行时间。F（确定）

3.torch\_npu.npu.set\_compile\_mode(jit\_compile=False)配置下，会根据当前获得的算子信息，进行融合和优化，在线编译出运行性能更优的算子。F（确定）

4.使用Ptdbg debugger方式分析精度问题时通常需要多轮dump分析比对，直到精度完全和标杆一致。T（？）***F***

5.Ptdbq工具提供了模块级dump功能T（确定）

6.当神经网络非常巨大，甚至网络可能巨大到无法存放到单一计算设备中，这时候，可以采用模型并行策略省去多个设备之间的梯度AIReduce操作，从而优化梯度同步和数据通信开销。F（确定）

7.使用compare tools比对性能数据，结果包含了算子在执行耗时、通信耗时、内存占用的优劣，内存使用数据分析前提是Profiling信息采集时打开profile\_memory=True开关。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5db41125-9553-4f71-8762-2e60a8f49b89.png)

8.Ascend nsight提供适配昇腾平台的框架Profiling可视化呈现，可根据Memory折线图找峰值拐点附近区域的算子明细分析算子内存占用。T（确定）![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/92c5bb67-5156-450d-b897-01e3ae5c2f80.png)

9.Deepspeed分布式训练加速工具，实现了内存优化算法，最新版本Deepspeed可以直接在Atlas 800T A2 昇腾设备上使用，无需deepspeed\_npu插件。T（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/539312cf-0ecf-449b-ba60-4f4034097cfe.png)

10.性能问题通常出现在算子下发和执行的异步过程中，因此性能优化的总体原则为:减少Host算子下发时间和减少Device算子执行时间。 T（确定）

11.单层感知机只能处理线性数据，为了解决非线性分类问题，我们可以使用多层感知机，在输入层和输出层之间多加一些隐藏层。多层感知机中添加的隐藏层数越多，整个网络的分类能力就越强，可以提取的目标特征层次也越高。F（确定）

12.神经网络中如果不使用激活函数(activation function)，那么每一层节点的输入都是上层输出的线性函数，无论神经网络有多少层输出都是输入的线性组合，与没有隐藏层效果相当，网络的表达能力就相当有限。因此，引入非线性激活函数主要就是为了添加非线性因素，增强深层神经网络的表达能力。T（确定）

13.提前终止(early stop)是一种防止欠拟合的方法，即在模型对训练数据集完全收敛之前停止迭代来防止欠拟合。可能的做法是，在每-个Epoch结束时计算验证集的loss或准确率，当发现loss上升或者准确率不再提高时，就提前停止训练。F（确定）

14.MindSpore支持使用面向对象编程范式，不提供纯函数式编程的支持 F（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/1de3e244-6746-498d-b48f-0acac85e0697.png)

15.为了在昇腾上使用PyTorch框架，当前推荐的方式是通过侵入式修改源码实现对昇腾NPU设备的支持，使用的时候需要编译安装patch后的PyTorch源码，如此可获得最好的扩展性。T（确定）

## 单选题

1.执行convert\_onnx\_to\_mindirsh进行模型转换时，转换后，除了生成.mindir模型外，还生成了以下哪种模型?D(?)

1.  .pt模型
    
2.  .pb模型
    
3.  .pth模型
    
4.  .om模型
    

2.使用benchmark工具对模型进行精度测试时，如果输出了如下信息，那么执行命令时设定了哪个参数?--- opType avg(ms) percent calledTimess opTotalTime Activation 0.006900 0.002510 10 0.069000 BiasAdd 0.012800 0.004657 20 0.128000 Conv2D 2.488500 0.905401 20 24.885004 MatMuL 0.137400 0.049991 '0 1.374000 Nchw2Nhwc 0.017400 0.006331 20 0.174000 Pooling 0.049400 0.017973 20 0.494000 Reshape 0.000900 0.000327 0 0.009000 shape 0.002300 0.000837 10 0.023000 SottMax 0.013300 0.004839 10 0.133000 stack 0.009900 0.003602 10 0.099000 Stridedslice 0,009700 0.003529 10 0.097000 total time : 2.90800 ms, kernel cost : 2.74851 ms   B(确定)

1.  timeProfiling
    
2.  operatorProfiling
    
3.  layerProfiling
    
4.  benchmarkProfiling
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/181af558-5b73-4eea-9032-ecf82affe952.png)

3.如下信息是使用哪一条命令执行得到的?+------tnpu-smi 23.0.rc2.2 Version: 23.0.rc2.2 |+----------+|NPU Name | Health | Power(w) Temp(C) Hugepages-Usage(page)l chip | Bus-ld | AlCore(%) Memory-Usage(MB) HBM-Usage(MB)|+====================+|4 910B4|OK|84.2 39 0/0|0 0000:81:00.0|00/0 3170/32768 |+======三三二三三三三三三三

\-ニニニニニニニニニニニニニ三-

p|Process id|Process name Process memory(MB)+=================+=====:

\----+I NPU Chi

无三三三三ニ三三三三三三3

\=======================+|No running processes found in NPU 4 +===

A（？）

1.  npu-smi info
    
2.  npu-smi info watch
    
3.  npu-smi info -l
    
4.  npu-smi info -m
    

4.对于动态分档场景，converterlite最多支持多少档?D(确定)

1.  20
    
2.  50
    
3.  80
    
4.  100
    

5.以下不属于Deepspeed分布式并行技术的是哪一项?D(确定)

1.  ZeRO1-3
    
2.  3D并行
    
3.  CPU offloading
    
4.  Page Attension
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/70577f12-7f53-49f4-8ed2-17ff7c486cff.png)

6.在迁移分析流程中，需要使用什么工具来分析模型在昇腾设备上的支持度? B(确定)

1.  AOE工具
    
2.  PyTorch Analyse工具
    
3.  Ptdbg Ascend工具
    
4.  Advisor工具
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/dff9068a-1eb6-4dbd-b542-cf0b87cfdf25.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e6f4c73c-a0f2-45df-a083-ee0f7618afa9.png)

7.大模型推理全量性能测试不需要覆盖下述哪个维度?A（确定）

1.  profiling-step
    
2.  batch\_size
    
3.  input\_seq\_len
    
4.  out\_seq\_len
    

8.pytorch框架训练性能调优时，大集群场景下profiling数据量很大，应该优先使用哪个工具进行初步分析?B（？）

1.  compare\_tools
    
2.  cluster\_analyse
    
3.  aoe
    
4.  tailor
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d5c76ee7-90eb-4c39-b486-7c992af1bec3.png)

[https://www.hiascend.com/document/detail/zh/mindstudio/70RC2/msinsightug/msascendinsightug/AscendInsight\_0101.html](https://www.hiascend.com/document/detail/zh/mindstudio/70RC2/msinsightug/msascendinsightug/AscendInsight_0101.html)

9.以下哪项不属于集合通信的最基础的操作?D（确定）

1.  send
    
2.  receive
    
3.  copy
    
4.  all2all
    

10.以下关于NPU融合算子说法正确的是:C（？）

1.  NPU上的融合算子性能一定比对应小算子性能更好
    
2.  NPU上的融合算子都能够找到对应的cuda融合算子进行对标
    
3.  训练场景中，使用融合算子能够缓解小算子造成的算子性能下发瓶颈
    
4.  融合算子在使用上相比于小算子来说是完全等价的，即小算子上能够支持的输入，融合算子也能够支持
    

11.以下不属于MindSpore原生分布式并行策略的是哪一项? B

1.  数据并行
    
2.  算力并行
    
3.  自动并行
    
4.  半自动并行
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/4d2dfb02-30d1-43a9-9d71-46a9f6617258.png)

12.定位精度问题时，首先要保证NPU和标杆设备上的模型初始状态保持一致，最方便且有效的做法是什么?（？）A

1.  固定随机种子进行随机初始化
    
2.  打开确定性计算开关后进行随机初始化
    
3.  固定随机性且打开确定性计算开关后进行随机初始化
    
4.  加载相同的初始权重进行初始化
    

13.昇腾性能比对工具compare\_tools支持比较GPU与NPU之间、NPU与NPU之间的性能差异，通过对训练耗时和内存占用的比对分析定位到具体劣化的算子，帮助用户提升性能调优的效率。开启总体性能比对的参数是哪项?B（确定）

1.  enable\_operator compare
    
2.  enable\_profiling\_compare
    
3.  enable\_communication\_compare
    
4.  enable\_memory\_compare
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/57db4a3f-b82f-4113-b602-f1cd55a87f31.png)

14.梯度下降算法的正确步骤是什么?D（？）

1.计算预测值和真实值之间的误差

2.重复迭代，直至得到网络权重的最佳值

3.把输入传入网络，得到输出值

4.用随机值初始化权重和偏差

5.调整权重以减小误差

1.  3,1,5,4,2
    
2.  4,1,3,5,2
    
3.  3,4,1,5,2
    
4.  4,3,1,5,2
    

15.卷积神经网络(CNN)发展过程中，出现了很多各具特色的模型，其中AlexNet的问世可谓是石破天惊，在2012年lmageNet竞赛中以绝对优势一举夺冠，使得全球范围内掀起了一波深度学习热潮，如下关于这一经典模型的描述中错误的是那一项?A（确定）

1.  AlexNet使用SE(Sequeeze-and-Excitation)模块学习不同通道之间的依赖关系，以提高模型的表现能力
    
2.  AlexNet使用dropout技术在训练过程中随机失活一部分神经元，以避免模型过拟合
    
3.  AlexNet使用ReLU代替传统的Siqmoid激活函数，训练速度更快
    
4.  AlexNet使用局部响应归一化(Local Response Normalization，LRN)，以提高模型泛化能力
    

16.神经网络的训练，基本都是采用梯度下降(gradient descent)算法，而它又分为多种方法，如下关于梯度下降算法的描述中错误的是哪一项?B（确定）

1.  全局梯度下降算法使用整个训练数据集来计算梯度，适用于样本量较小的场景
    
2.  随机梯度下降算法在每轮迭代时随机选取1个样本点，对声不敏感，容易收敛到极值
    
3.  小批量梯度下降算法每次随机选取一小部分训练数据参与计算，兼顾了效率和稳定性
    
4.  小批量梯度下降算法中引入了batch size的概念，成为神经网络训练中的重要超参数之一
    

17.ModelArts Lite提供了多种场景下的存储解决方案，如下场景描述的是哪种存储配置方案:提供高可靠、高性能、规格丰富并且可弹性扩展的块存储服务，其中存放的是二进制数据，无法直接存放文件，且只能在ECS(Elastic cloud server，弹性云服务器)、BMS(Bare Metal Server，裸金属服务器)中挂载使用，不能被操作系统应用直接访问。C（？）

1.  SFS(Scalable File Service)，弹性文件服务
    
2.  SFS Turbo
    
3.  EVS(Elastic Volume Service)，云硬盘
    
4.  OBS(Object Storage Service)，对象存储服务
    

18.ModelArts支持开发者使用本地IDE连接到Notebook开发环境进行远程开发，此时需要使用以下哪一项进行鉴权认证?A（确定）

1.  秘钥对
    
2.  AK/SK
    
3.  华为账号密码
    
4.  项目ID
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/48189a9e-123e-453f-8777-e64bdcd90957.png)

19.如下关于计算图的描述，错误的是哪一项? B

1.  动态图的核心特点是图的构建和计算同时发生
    
2.  动态图对全局的信息掌握更丰富，可做的优化也会更多
    
3.  静态图在计算阶段，根据输入数据执行编译好的图得到计算结果
    
4.  静态图无法实时拿到中间计算结果，中间过程对于用户来说是个黑盒
    

![image-20240910160256269](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240910160256269.png)

## 多选题

20.如下描述中，哪一项不属于CANN中AIPP(Al Pre-Processing)算子库的功能?BCD（确定）

1.  图像编解码
    
2.  图像尺寸变化
    
3.  图像色域转换
    
4.  图像数据归一化
    

[AIPP-专题-Ascend Graph开发-模型开发-CANN社区版8.0.RC3.alpha001开发文档-昇腾社区 (hiascend.com)](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC3alpha001/devguide/moddevg/graphdevg/atlasag_25_0044.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/a5120e40-2af7-4732-9883-ca429be4c68f.png)

1.调优工具AKG(Auto Kernel Generator)主要由如下哪几个优化模块组成？ABD（确定）

1.  规范化，主要包括自动运算符inline、自动循环融合和公共子表达式优化等。
    
2.  自动调度，主要包括自动向量化、自动切分、依赖分析和数据搬移等。
    
3.  前端优化，主要包括常量折叠、算子自动融合、循环重排序等。
    
4.  后端优化，主要包括Tensorcore使能、双缓冲区、内存展开和同步指令插入等
    

[MindSpore](https://www.mindspore.cn/docs/programming_guide/zh-CN/r1.6/graph_kernel_fusion_engine.html)![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/dce0e311-aada-4716-b986-50810e060eae.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/307a5d0c-1a7d-47d2-8e99-96cedee90145.png)

2.msprof命令行工具采集到的timeline数据，包含如下哪几项内容?ABC（确定）

1.  应用层数据
    
2.  CANN数据
    
3.  底层NPU数据
    
4.  算子可选优化项
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4cd7791b-946b-47c0-9946-ef42e528d687.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/8a13b344-0156-4dd9-9c00-10772f04f771.png)

3.在迁移可行性分析中如果存在平台未支持的算子，可通过下面哪些方式解决?  ACD（？）

1.  修改模型脚本，使用等价支持的算子替换
    
2.  将CANN版本降低
    
3.  联系华为工程师提出开发适配诉求
    
4.  参考文档进行算子适配
    

4.如果使能精度对比工具后模型精度异常现象消失，说明该模型的精度异常的原因可能是什么?（？）

1.  可能是模型训练时使用了drouout，且不等于零
    
2.  可能是算子下发的时序问题或者内存踩踏问题
    
3.  可能是模型训练的算子的确定性计算存在问题，导致精度异常
    
4.  可能是模型的算子存在累积偏差
    

5.在将模型从其他三方平台迁移到昇腾时，涉及到一系列底层到上层的适配操作。模型迁移至昇腾需要适配的原因主要为哪些方面?ABCD（确定）

1.  硬件实现差异
    
2.  计算架构差异
    
3.  模型来源差异
    
4.  深度学习框架差异，为了支持NPU硬件需要对PyTorch框架进行适配
    

6.GPU环境下确定性计算打开的方式是什么?AC（？）

1.  torch.use deterministic algorithms(True)
    
2.  export HCCL DETERMINISTIC=TRUE
    
3.  export NCCL DETERMINISTIC=TRUE
    
4.  expOrt INF NAN MODE ENABLE=1
    

7.大模型精度对齐场景，往往面临网络规模参数量巨大的限制，以下哪些方法可以缓解上述现象，且能够尽可能不影响原问题的定位? ABC（？）

1.  只dump API的统计量信息进行对比
    
2.  减小模型层数
    
3.  减小输入token的序列长度
    
4.  减小模型的学习率
    

8.以下哪些指标是精度对齐时需要关注的?ABCD（？）

1.  loss值
    
2.  grad norm值
    
3.  初始学习率
    
4.  batch size
    

9.关于ModelArts提供的昇腾迁移环境，以下说法正确的是哪几项?ABD（确定）

1.  ModelArts提供了配套昇腾硬件环境的基础容器镜像
    
2.  在昇腾环境上启动容器镜像时，可以使用ASCEND\_VISIBLE DEVICES指定容器要使用的卡号
    
3.  容器内无法查看昇腾卡信息，宿主机上可以查看卡信息
    
4.  ModelArts基础镜像内的PyTorch/MindSpore等AI框架包均安装在Conda环境内
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/6efb9d91-a13f-446c-9753-be4a038c2c0a.png)

10.以下哪些选项属于精度偏差的来源?ABCD（确定）

1.  算子计算BUG
    
2.  算法迁移适配不当
    
3.  确定性计算未开启
    
4.  硬件差异，芯片架构差异
    

11.在Transformer架构提出之前，自然语言处理领域使用最多的是各种类型的循环神经网络(RNN)，如下关于RNN与Transformer的描述正确的有哪些?ABCD（？）

1.  虽然有LSTM/GRU等改进形态，但RNN处理长距离依赖的能力仍然不够好
    
2.  Transformer架构可以直接计算序列中任意两个位置之间的关系，使得模型能够有效地捕获长距离依赖信息
    
3.  IRNN是时序结构，当前时刻的输入依赖前一时刻的输出，不太适合做并行化
    
4.  Transformer架构可以高效地并行处理整个序列，推理时也可以并行化输出完整的句子
    

12.目前在AI社区里，很多厂商都发布了开源LLM(large language model，大语言模型)，这些模型通常分为两种类别:base模型、chat模型，关于这两类模型的描述正确的有哪些?ABCD（？）

1.  base模型一般只经历了预训练阶段，使用海量无标签的文本数据进行了无监督学习
    
2.  base模型更适合文本补全等基础任务，具有更强的泛化能力
    
3.  chat模型在base模型基础上，又经历了有监督微调等阶段，更适合多轮对话任务
    
4.  如果需要应用到特定领域的下游任务，且拥有大量的有标签数据，更建议在chat模型上做微调
    

13.开发者想在昇腾云服务上使用深度学习框架进行模型训练和推理，如下哪些框架可以满足需求?ABD（确定）

1.  MindSpore
    
2.  PyTorch
    
3.  Caffe
    
4.  TensorFlow
    

14.使用ModelArts的开发环境，创建Notebook实例时需要选择一种A!引擎的镜像，可以选择的镜像类型包括如下哪几项?ABCD（？）

1.  预置在ModelArts内部的公共镜像
    
2.  AI Gallery社区发布的镜像
    
3.  基于公共镜像创建的实例保存下来的自定义镜像
    
4.  在ECS(Elastic cloud Server)上构建的自定义镜像
    

15.ModelArts支持训练模型过程中安装第三方依赖包，其中依赖包安装文件的命名支持以下哪几种格式?ABCD（确定）

1.  pip-requirement.txt
    
2.  pip-requirements.txt
    
3.  requirement.txt
    
4.  requirements.txt
    

# 题目十（张力升两套）

## 判断题

1.MindFormers支持ChatGLM、Llama、Baichuan、Qwen等热门的大模型系列，支持文本生成、问答、翻译、文本掩码等文本型的任务，当前还不支持如图像分割类的图像任务。T（？）

[三方应用: https://mindformers.readthedocs.io/zh-cn/r1.2.0/docs/model\_support\_list.html#translation](https://mindformers.readthedocs.io/zh-cn/r1.2.0/docs/model_support_list.html#translation)

2.CANN是华为针对A场景推出的异构计算架构，提供了多层次的编程接口，支持底层的算子开发与模型开发，但是不支持上层的AI应用开发。F

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/a3e65294-7a5d-4d80-a5b1-fcee397e93b5.png)

3.API精度预检主要分为三步:整网dump、multi\_run\_ut、api\_precision compare. T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/4221ce2e-38c7-4eb6-a4fb-8c1c6d53d0f9.png)

4.在Pytorch模型训练迁移过程中，精度对齐和性能调优是一个互相影响循环往复的过程.

5.torch\_npu.npu.set\_compile\_mode(jit\_compile=False)配置下，会根据当的获得的算子信息，进行融合和优化，在线编译出运行性能更优的算子。 F

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/25f4760a-3987-4c9f-ba34-3fefcb101e6d.png)

6.分布式训练的本质是解决单设备内存不足或者单个设备计算能力不足问题。T（确定）

7.神经网络的训练过程，就是通过对训练数据集的学习，调整神经网络中每个神经元的参数，使得损失函数的值取得最高或者相对较高的值。因此，训练的目标就是要让损失函数的值尽可能的大。 F（确定）

8.神经网络中如果不使用激活函数(activation function)，那么每一层节点的输入都是上层输出的线性函数，无论神经网络有多少层输出都是输入的线性组合，与没有隐藏层效果相当，网络的表达能力就相当有限。因此，引入非线性激活函数主要就是为了添加非线性因素，增强深层神经网络的表达能力。 T（确定）

9.GoogLeNet是一种经典的卷积神经网络，其中引入了Inception结构，代替单纯的卷积-池化-激活的传统操作，通过使用不同大小的卷积核来抓取不同大小的感要野，拓宽了网络的宽度。 T

10.迁移过程的精度问题一般包括:在迁移正确的前提下，发生loss曲线与CPU/GPU差异不符合预期，下游任务评测结果准确度与CPU/GPU差异不符合预期的情况。T![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/cf290b00-cc87-44f4-a80c-99393686c057.png)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/896b1ed6-3882-4118-b41e-f8369b0a5dde.png)

11.假设您对mindspore框架训练的大模型结构比较熟悉，知道哪些"关键算子"容易成为计算瓶颈，为“关键算子"配置合适的切分策略以获得更好的性能，您可以在初始化网络之前调用mindspore.set auto,paralel context(parallel mode=ParalelMode.SEMIL AUTO\_PARALLEL):设置半自动并行模式。 T（确定）

12.优化器并行-ZeRO主要思想是在训练过程中去除冗余数据，ZeRO有三个不同优化级别，对模型状态进行不同程度的分片。T（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/79298992-267b-4a37-b8c2-8705ef207455.png)

13.使用compare tools比对性能数据，结果包含了算子在执行耗时、通信耗时、内存占用的优劣，内存使用数据分析前提是Profiling信息采集时打开profile\_memory=True开关。T（确定）

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/cdeb5f0c-043d-471d-8191-766476dcd4ca.png)

14.compare一键式全流程精度比对工具适用于TensorFlow、PyTorch和ONNX 模型。T（？）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/fd4bc863-9d79-48a5-a584-044e079e7887.png)

15.converter lite是Mindspore Lite提供离线转换模型工具，目前支持的输入模型类型有:MindSpore、TensorflowLite、Cafe、TensorFlow、PaddlePaddle、ONNX和PyTorch. F（确定）

16.提前终止(early stop)是一种防止欠拟合的方法，即在模型对训练数据集完全收敛之前停止迭代来防止欠拟合。可能的做法是，在每一个Epoch结束时计算验证集的loss或准确率，当发现loss上升或者准确率不再提高时，就提前停止训练。F（确定）

防止过拟合

17.ModeArts不支持跨站点访问OBS桶，通过OBS下载文件到Notebook中时，请确保读取的OBS桶和Notebook处干同一站点区域 F（确定）

18.AOE(Ascend Optimization Engine) 优化成功的.mindir模型，在使用时不可以删除AOE知识库，否则会影响该模型的性能。F（确定）

19.精度校验是通过固定输入，对比模型推理结果和基准数据的相似度来完成的。 T(?)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e356ee6e-dfa3-43dd-8ea8-b066851999e5.png)

20.当神经网络非常巨大，甚至网络可能巨大到无法存放到单一计算设备中，这时候，可以采用模型并行策略省去多个设备之间的梯度AllReduce操作，从而优化梯度同步和数据通信开销。F

21.梯度裁剪是防止梯度消失与爆炸的一种方法，通常的使用方式是设置一个范围，更新梯度的时候，如果梯度超过这个阈值，那就将其强制限制在这个范围之内。T

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/2d14ebd8-f663-481c-8d8e-a6588a87295a.png)

22.在使用开发环境或者训练作业时，ModelArts会挂载硬盘至"/cache"目录，用户可以使用此目录来储存文件，此目录无法扩容，不同资源规格有不同的容量，且环境重启后数据将被清空无法恢复。F

23.算子的数值精度是计算过程的基础，通常认为算子精度问题是大模型精度问题的来源之一。T

24.Ascend Insight提供适配昇腾平台的框架Profiing可视化呈现，可根据Memory折线图找峰值拐点附近区域的算子明细分析算子内存占用。 T（确定）

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/19936329-4701-44a1-9e7b-75751f49ca7a.png)

25.部分NPU硬件对FP32的限制，导致混合精度问题，造成精度损失，在训练过程中避免开启混合精度方式。F

26.在机器学习中，过拟合与欠拟合都是需要避免的现象，其中过拟合指的是在训练集和测试集上的性能都较差，而欠拟合往往能较好地学习训练集数据的性质，但在测试集上的性能较差。F

27.算子精度问题分析思路通过比对标杆和NPU训练过程中API的输入输出张量粒度的对比，定位出异常api。T

28.假设您对mindspore架训练的大模型结构比较熟悉，知道哪些“关键算子"容易成为计算瓶颈，为'关键算子”配置合适的切分策略以获得更好的性能，您可以在初始化网络之前调用mindspore.set\_auto\_parallel\_context(parallel\_mod=ParallelMode.SEMI AUTO PARA千行模式。LLEL):设置半自并行模式 T

原因：通过设置mindspore的auto\_parallel\_context，可以指定半自动并行模式，这有助于优化关键算子的性能。

29.昇腾HCCL数据并行策略支持DDP模式和DP模式。T（确定）

[三方应用: https://www.hiascend.com/document/detail/zh/canncommercial/80RC2/developmentguide/hccl/hcclug/hcclug\_000001.html](https://www.hiascend.com/document/detail/zh/canncommercial/80RC2/developmentguide/hccl/hcclug/hcclug_000001.html)

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f56eee1f-8856-464b-b0a5-83fdcae871cc.png)

DP（Data Parallel）：在单机上使用多个GPU进行模型训练。（单机多卡）

DDP（Distributed Data Parallel）：在多台机器上使用多个GPU进行模型训练。（多机多卡）

30.在fp16混合精度训练场景下，如果Loss scale在连续的50个step没有持续降低，这种情况可以判定为正常溢出。F（确定）

![image-20240910144929289](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240910144929289.png)

## 单选题

1.在使用Mindformers进行大语言模型的文本生成时，可以配置不同的采样策略，如下描述的是哪一种策略:每个时间步，按照token出现的概率由高到底排序，当栅率之和大于某个阈值时，就不取后面的样本了;然后对取到的这些token的概率重新归一化后，进行采样。B

1.  贪心采样
    
2.  ToP-p 采样
    
3.  Top-k 采样
    
4.  Beam Search 采样
    

![image-20240910144552942](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240910144552942.png)

贪心采样总是选择概率最高的 token。

Top-k 采样是只在概率最高的前 k 个 token 中进行采样。

Beam Search 采样则是通过维护多个候选序列来搜索最优输出。

2.某客户在公有云上部署了AI业务，某天的15点5分业务量暴增，15点20分用户下扩容订单，，昇腾云服务在20分钟后即完成千卡资源护容上线，保障了用户业务的平稳运行。以上案例体现的是异腾云服务的哪一项关键能力? A

1.  立等可取，即开即用
    
2.  集群优化，释放性能
    
3.  全栈优势，高效诊断
    
4.  安全可靠，上云无忧
    
5.  百模千态，一键部署
    

4.Mindspore的Cell类是构建所有网络的基类，当用户需要自定义网络时，需要继承Cell类，其中网络的执行需要重写Cell类的哪个方法? A

1.  construct
    
2.  inference
    
3.  forward
    
4.  call
    

[https://www.mindspore.cn/doc/programming\_guide/zh-CN/r1.0/cell.html#:~:text=MindSpore%E7%9A%84%20Cell%20%E7%B1%BB%E6%98%AF%E6%9E%84%E5%BB%BA%E6%89%80%E6%9C%89%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E7%B1%BB%EF%BC%8C%E4%B9%9F%E6%98%AF%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%E3%80%82%20%E5%BD%93%E7%94%A8%E6%88%B7%E9%9C%80%E8%A6%81%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%E6%97%B6%EF%BC%8C%E9%9C%80%E8%A6%81%E7%BB%A7%E6%89%BF%20Cell,%E7%B1%BB%EF%BC%8C%E5%B9%B6%E9%87%8D%E5%86%99%20\_\_init\_\_%20%E6%96%B9%E6%B3%95%E5%92%8C%20contruct%20%E6%96%B9%E6%B3%95%E3%80%82](https://www.mindspore.cn/doc/programming_guide/zh-CN/r1.0/cell.html#:~:text=MindSpore%E7%9A%84%20Cell%20%E7%B1%BB%E6%98%AF%E6%9E%84%E5%BB%BA%E6%89%80%E6%9C%89%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E7%B1%BB%EF%BC%8C%E4%B9%9F%E6%98%AF%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83%E3%80%82%20%E5%BD%93%E7%94%A8%E6%88%B7%E9%9C%80%E8%A6%81%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%E6%97%B6%EF%BC%8C%E9%9C%80%E8%A6%81%E7%BB%A7%E6%89%BF%20Cell,%E7%B1%BB%EF%BC%8C%E5%B9%B6%E9%87%8D%E5%86%99%20__init__%20%E6%96%B9%E6%B3%95%E5%92%8C%20contruct%20%E6%96%B9%E6%B3%95%E3%80%82)

5.设置CPU绑核策略的作用是什么? A

1.  指定线程与CPU核绑定，减少切换耗时，优化性能
    
2.  绑定必要核数CPU,空闲CPU分配至性能较差线程，优化卡间不同步性能问题
    
3.  对输出使用CPU进行计算验证，定位算子精度问题
    
4.  线程绑定CPU小核用于下发API，性能较强的CPU大核用于计算复杂问题，优化模型训练性能
    

6.在开启确定性计算后，NPU多次训练的Loss保持一致。但是在长稳的训练过程中，和GPU的Loss存在差异并且慢慢扩大，甚至出现Loss上扬等严重问题，以下哪项不是正确的排查思路和操作? D

1.  由于已经开启了确定性计算开关，数据存在差异不再是问题，而只有到数据存在较大差异时才被判定为问题。因此高灵敏的md5不再适用，需要记录原始数据进行后续的差异分析
    
2.  此时的监控对象从模型的权重，转变为了每次选代步的权重梯度
    
3.  使用梯度监控工具监控GPU和NPU训练过程中的梯度方向差异
    
4.  使用ptdbq工具dump从训练开始到loss出现明显异常的数据
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c0c8a71f-913f-453b-91b2-d121c1480b54.png)

7.以下关于集合通信原语说法错误的是哪项? B

1.  broadcast是一对多操作
    
2.  scatter是多对多操作
    
3.  gather是多对一操作
    
4.  ReduceScatter是多对多操作
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/c48f4702-3321-413a-863b-f9a4728d174c.png)

8.以下关于精度预检工具的说法错误的是哪项? C

1.  支持随机生成输入和真实数据输入两种方式
    
2.  可以获取整网中每个API的输入数据的shape、dtype、数值分布等信息
    
3.  获取的数据会存在累积误差
    
4.  支持标杆比对法进行精度比对
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/664d7132-c279-4980-b5ec-b4bb4f6c4a72.png)

[https://gitee.com/ascend/mstt/blob/master/debug/accuracy\_tools/api\_accuracy\_checker/README.md](https://gitee.com/ascend/mstt/blob/master/debug/accuracy_tools/api_accuracy_checker/README.md)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/8acf1ea7-55a1-49c2-bd53-7a5b71dfb061.png)

9.在神经网络训练过程中，如果出现损失函数(loss function)在极值处不停震荡不收敛，那么最可能的原因是哪一项? B

1.  学习率(learning rate)太小
    
2.  学习率(learning rate)太大
    
3.  隐藏层层数太少
    
4.  隐藏层层数大多
    
5.  激活函数选择了线性函数
    
6.  batch size过大
    

10.循环神经网络(RNN)擅长处理类似自然语言语句这样的序列数据，根据输入输出不同它可以有多种不同的结构，如one-to-one，one-to-many，many-to-one，many-to-many等，那么针对中文命名实体识别任务，应该使用哪种RNN结构? D

1.  one-to-one
    
2.  one-to-many
    
3.  many-to-one
    
4.  many-to-many
    

11.在卷积神经网络(CNN)中，感受野(receptive field)指的是神经网络中神经元"看到的"输入区域，越深层的神经元看到的输入区域越大。假设在某个模型中，所有卷积核的尺寸均为3\*3，步长(stride)均为1，layer1是输入层，则第二层layer2中每个神经元可看到ayer1上3\*3大小的区域，那么第四层layer4中每个神经元可以看到的layer1上区域是多大? D

1.  4\*4
    
2.  5\*5
    
3.  6\*6
    
4.  7\*7
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b2daa81d-208b-4d2b-be50-c294063b086d.png)

12.以下不属于Megatron-LM分布式并行技术的是哪一项? A

1.  离线并行
    
2.  数据并行
    
3.  张量并行
    
4.  流水线并行
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/a52ecef3-7369-48f0-bf36-1e17f6b9f044.png)

13.使用Ascend PyTorch Profiler接口开启PyTorch训练时的性能数据采集，采集CANN软件栈及NPU数据的activities是什么? B

1.  torch npu.profilerProfilerActivity.CPU
    
2.  torch npu.profiler.ProfilerActivity.NPU
    
3.  torch.profiler.ProfilerActivity.CPU
    
4.  torch.profiler.ProfilerActivity.NPU
    

[三方应用: https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/devaids/auxiliarydevtool/atlasprofiling\_16\_0037.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/80RC2alpha001/devaids/auxiliarydevtool/atlasprofiling_16_0037.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d733c0f9-b025-42f8-adae-ffc488468bb3.png)

14.请问以下哪个仓库是异腾提供的大模型解决方案仓库? B

1.  DeepSpeed
    
2.  ModelLink
    
3.  AscendSpeed
    
4.  Megatron-LM
    

[三方应用: https://gitee.com/ascend/ModelLink](https://gitee.com/ascend/ModelLink)

15.以下哪种现象可以说明PyTorch确定性计算开关开启成功且生效: A

1.  多次运行训练脚本，loss曲线趋势保持一致(在同一时刻下降和上升，且偏差幅度始终保持一致)
    
2.  多次运行训练脚本，loss曲线的值必须保持完全一致，任何差异都是不可以接受的
    
3.  开启确定性开关前后的loss曲线趋势保持一致(在同一时刻下降和上升，且偏差幅度始终保持一致)
    
4.  由于集合通信的累加顺序不一致，因此即使打开确定性计算，也无法保证最终的输出是完全一致的
    

16.通过工具定位到疑似有问题的API时，下述处理方案中不正确的是哪项?

1.  进行标杆等价替换(替换为同功能，无精度问题的实现)，观测替换后Loss是否正常
    
2.  等价替换后，若Loss有好转但仍不达标，则说明该API对Loss有影响但不是唯一因素，需要继续排查问题
    
3.  等价替换后，若Loss无变化，说明该API对整网精度没有产生影响
    
4.  如果没有可等价替换的API，则需要使用梯度监控工具进一步监控训练梯度查找问题根因
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/b15fe22f-1763-4dbe-a2ed-c4b301288433.png)

17.对于动态分档场景，converter lite最多支持多少档? D

1.  20
    
2.  50
    
3.  80
    
4.  100
    

[三方应用: https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud\_infer/converter\_tool\_ascend.html](https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/converter_tool_ascend.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/01a41b46-4dd9-43b2-98a0-f2a94443b210.png)

18.使用Mindspore Lite进行模型推理时，如下哪个接口可以完成模型的加载与编译?D

1.  model.load\_model
    
2.  model.build\_model
    
3.  model.load\_from\_file
    
4.  model.build\_from\_file
    

[https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud\_infer/runtime\_distributed\_multicard\_python.html?highlight=%E5%8A%A0%E8%BD%BD](https://www.mindspore.cn/lite/docs/zh-CN/master/use/cloud_infer/runtime_distributed_multicard_python.html?highlight=%E5%8A%A0%E8%BD%BD)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/81f3d8bc-4676-43c9-a821-57332e2485a6.png)

19.AIT(Ascend Inference Tool)是昇腾推理一体化开发工具，可执行多项任务，如果需要分析昇腾推理设备对输入模型的支持度情况包括算子支持情况、算子定义、算子输入等，应该使用如下哪一项task类型? C

1.  benchmark
    
2.  transplt
    
3.  analyze
    
4.  profile
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f002b73b-8620-47c8-ad89-751a2e4a300e.png)

20.一个7B参数量的模型，使用fp16格式的数据精度进行推理，其显存占用最接近如下哪一项? C

1.  3.5 GB
    
2.  7 GB
    
3.  14 GB
    
4.  28 GB

21.以下关于分布式数据并行DDP的说法正确的是哪项?C

1.  DDP采用单进程，一台机器上运行一个进程
    
2.  DDP通信开销大，server要和每一个worker进行梯度传输，当server和worker不在同一台机器时，server带宽会成为瓶颈
    
3.  DDP采用Ring AllReduce的通信方式，通信成本不随XPU节点数增长而线性增长
    
4.  DDP通过收集梯度到 device\[0\]，在device\[0\]更新参数，然后其他设备复制 device\[0\]的参数实现各个模型同步
    

22.以下不属于DeepSpeed分布式并行技术的是哪一项?D

1.  ZeRO1-3
    
2.  3D并行
    
3.  CPU offloading
    
4.  Page Attension
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/479c1489-9cd0-4d29-9095-5519178ad3b1.png)

23.MindSpore的cel类是构建所有网络的基类，当用户重要自定义网络时，重要继承Cel类，其中网络的执行雲要重写Cel类的哪个方法? A

1.  construct
    
2.  inference
    
3.  forward
    
4.  call
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/2c545502-d1ad-4f12-b520-2d41571cfab3.png)

24.某客户在公有云上部署了AI业务，某天的15点5分业务量暴增，15点20分用户下扩容订单，昇腾云服务在20分钟后即完成千卡资源护容上线，保障了用户业务的平稳运行。以上案例体现的是异腾云服务的哪一项关键能力? A

1.  立等可取，即开即用
    
2.  集群优化，释放性能
    
3.  全栈优势，高效诊断
    
4.  安全可靠，上云无忧
    
5.  百模千态，一键部署
    

25.ModelArts支持开发者使用本地IDE连接到Notebook开发环境进行远程开发，此时需要使用以下哪一项进行鉴权认证? A

1.  秘钥对
    
2.  AK/SK
    
3.  华为账号密码
    
4.  项目ID
    

[https://support.huaweicloud.com/devtool-modelarts/devtool-modelarts\_0015.html](https://support.huaweicloud.com/devtool-modelarts/devtool-modelarts_0015.html)

26.某客户的AI业务上线后，其业务流量曲线显示，每天18点到0点流量都有很大幅度上升，昇腾云服务通过资源共池、多种计费模式等功能，帮助客户进行了灵活的资源配置，降低了50%的资源成本。以上案例体现的是昇腾云服务的哪一项关键能力? C

1.  立等可取，即开即用
    
2.  集群优化，释放性能
    
3.  全栈优势，高效诊断
    
4.  弹性灵活，按需使用
    
5.  安全可靠，上云无忧
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f40df0ee-9fcd-4233-a9e0-90dd42fa5e87.png)

27.客户是一家购物平台,需要实现智能客服系统，回答顾客在售前、售中、售后等阶段的咨询问题。请问以上任务描述主要属于人工智能的哪个领域应用? B

1.  计算机视觉
    
2.  自然语言处理
    
3.  语音信号处理
    
4.  决策规划系统
    

28.客户是一家医院，需要开发一款应用辅助医生进行医学诊断，场景是CT影像，需要识别出其中的病灶区域并测量尺寸。请问以上任务最可能使用的人工智能技术是哪一项? C

1.  图像分类
    
2.  物体检测
    
3.  图像分割
    
4.  目标跟踪
    

29.关于LLM模型训练过程中loss出现毛刺的现象，以下说法错误的是?   C

1.  可能是数据集中有脏数据
    
2.  可能是Adam优化器处于不稳定状态
    
3.  如果此时刻对应标杆的loss未出现毛刺现象，那么就可以认为是精度问题
    
4.  降低学习率可以在一定程度上缓解毛刺现象，但是缺点是训练时间会拉长
    

30.在卷积神经网络CNN中，卷积是最核心的操作，其输入输出都是多维向量，或是图像，或是特征图。假设某一个卷积操作中，输入图像大小为5\*5\*3(HWC，高\*宽\*通道数，不考虑批量大小batch size，下同)，卷积核尺寸为3\*3，通道数为5，卷积步长为1，边缘不做填充，则输出的特征图大小是多少(用HWC格式表示)? B

1.  3\*3\*3
    
2.  3\*3\*5
    
3.  5\*5\*3
    
4.  5\*5\*5
    

[https://www.cnblogs.com/yc096ay/p/14405724.html](https://www.cnblogs.com/yc096ay/p/14405724.html)

31.定位如千卡大集群场景的偶现性能问题时，为了减少需要分析的数据量，如下操作中应当首先尝试进行的是哪项?

     A（？）

1.  在小集群或单节点上复现性能问题
    
2.  采集性能异常场景大集群全量性能数据进行分析
    
3.  将数据集、日志等文件转移到节点本地，日志等文件保存在本地，排除网络I0性能问题
    
4.  采集性能正常场景的大集群全量性能数据作为对比,
    

32.在性能调优过程中，通过分析采集profiling数据的timeline发现free time呈现多次小块的特征，但是相对标杆性能耗时较大，可考虑使用什么方法进行性能调优?

1.  增大模型参数batch size
    
2.  增大模型参数number workers
    
3.  使用AOE算子调优
    
4.  将数据集文件转移至节点本地磁盘
    

33.大模型推理全量性能测试不需要覆盖下述哪个维度?A（确定）

1.  profiling-step
    
2.  batch\_size
    
3.  input\_seq\_len
    
4.  out\_seq\_len
    

34.在迁移分析流程中，需要使用什么工具来分析模型在昇腾设备上的支持度? B

1.  AOE工具
    
2.  PyTorch Analyse工具
    
3.  Ptdbg Ascend工具
    
4.  Advisor工具
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/dff9068a-1eb6-4dbd-b542-cf0b87cfdf25.png)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/e6f4c73c-a0f2-45df-a083-ee0f7618afa9.png)

35.使用Mindspore lite转换工具进行模型转换时，如果出现如下报错，可能的原因是哪一项?\[ERROR\]ME(103674,7fbdc90a8ec0,python):2021-12-13-16:20:49.506.131 \[mindspore/lite/src/extendrt/session/single op session.cc:242\] compileGraph\] Only support customAscend, but got Reshape, node Reshape 9\[ERROR\] ME(103674,7fbdc90a8ec0,python):2021-12-13-16:20:49.506.245 \[mindspore/lite/src/extendrt/cxx api/model/model impl.cc:280\] BuildByBufferlmpll compile graph failed.  C

1.  转换工具不支持模型中的Reshape算子
    
2.  转换工具不支持Reshape算子中的某些参数
    
3.  模型转换时未指定Ascend后端
    
4.  模型文件损坏
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/71e729c0-989f-494b-91fc-1cffdafcefbd.png)

36.AI编译器中，将计算图中预先可以确定输出值的节点提前计算好，并对计算图进行一些结构简化的操作，这属于哪一种性能优化方法?D

1.  子图调优
    
2.  模型裁剪
    
3.  算子融合
    
4.  常量折叠
    

37.进行精度对比时，如果发现出现数据计算的溢出，则如下哪个改动有助于解决问题? C

1.  数据精度由 fp16 ->bf16
    
2.  数据精度由 fp32 ->bf16
    
3.  数据精度由 fp32 ->fp16
    
4.  数据精度由 bf16 ->fp16
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/5e0546d1-7b71-4ecb-8862-c5feb810620e.png)

38.给定网络模型，构建包含自动调优策略生成、编译、运行环境验证的闭环反馈机制，利用A!算法在机器上不断迭代，最终得到最优的策略结果并将其写入知识库，从而达到在有限硬件资源上不断提升网络性能的效果。以上功能描述的是哪一款模型调优工具? B

1.  MA Advisor
    
2.  AOE(Ascend Optimization Engine)
    
3.  AKG (Auto Kernel Generator)
    
4.  Tailor
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/d0b8b357-0baa-4082-a919-0937363e5cd5.png)

[三方应用: https://www.hiascend.com/document/detail/zh/canncommercial/63RC2/devtools/auxiliarydevtool/aoe\_16\_001.html](https://www.hiascend.com/document/detail/zh/canncommercial/63RC2/devtools/auxiliarydevtool/aoe_16_001.html)

39.完成精度调试的标志是什么?B（？）

1.  Loss与标杆完全对齐
2.  采用常规数据集评估模型分数符合社区实践评分预期
3.  模型在验证集上的准确率达到一定水平
4.  以上都不是

![image-20240910112736283](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240910112736283.png)

[精度调试流程 (hiascend.com)](https://www.hiascend.com/document/detail/zh/Pytorch/60RC2/ptmoddevg/trainingmigrguide/LMaccuracy_0002.html)

40.NPU上Flash attention中(npu fusion attention)常提到的layout排布(B、S、N、D、H)中，以下说法错误的是C

1.  B表示batch size维度
    
2.  S表示序列长度
    
3.  N表示Query、Key、Value的num heads数，且三者长度必须一致  （成比例关系） 
    
4.  H=N\*D
    

[https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/700alpha002/ptmoddevg/ptmigr/ptaoplist\_246.html](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/700alpha002/ptmoddevg/ptmigr/ptaoplist_246.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/b0a0a434-a3e9-488d-a2c0-a08c88a4b355.png)

## 多选题

1.  PyTorch Adapter使用插件化方式在线对接适配昇腾AI处理器，这样做的优势有哪些?ABD
    
1.  最大限度的继承GPU在PyTorch上的使用方式，移植的时候，在开发方式和代码复用方便做到最小的改动
    
2.  最大限度的继承PyTorch原生的体系结构，保留框架本身出色的特性
    
3.  使用方便，插件内置在PyTorch安装包中，只需要一次pip安装即可完成
    
4.  扩展性好，对于新增的网络类型或结构，只需相关计算类算子的开发和实现
    

[https://www.hiascend.com/document/detail/zh/canncommercial/70RC1/modeldevpt/ptmigr/AImpug\_0004.html](https://www.hiascend.com/document/detail/zh/canncommercial/70RC1/modeldevpt/ptmigr/AImpug_0004.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f8959573-0f1e-4629-ac2b-d5e78f107944.png)

2.作为ModelArts系列中负责边缘部署和管理的服务，如下功能描述中，属于ModelArts Edge能力范畴的有哪几项? ABD

1.  支持纳管多种异构算力的边缘设备，方便业务集成与运维
    
2.  支持进程、容器等多种格式的AI应用部罢，方便应用的快速上线
    
3.  提供端到端的模型生产工具链，AI开发、训练、推理一站式服务
    
4.  提供多种调度方式，支持边云协同推理，高效利用边缘资源
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/f5116673-a010-49c5-a7dd-3cb7415b4f14.png)

3.卷积神经网络(CNN)发展过程中，研究者提出过很多经典的模型，如下关于各个模型描述正确的有哪些? ABC

1.  VGGNet使用连续的3\*3卷积核替代大卷积核，通过增加网络深度提高网络学习能力
    
2.  GoogLeNet中使用了1\*1卷积核，增加非线性特征的同时又可以达到降维的效果
    
3.  ResNet提出的残差结构，很好的解决了深度网络的退化问题，使得网络可以通过加深提高准确率
    
4.  DenseNet使用SE(Sequeeze-and-Excitation)模块学习不同通道之间的依赖关系，提高了模型的表现能力
    

使用 SE（Sequeeze-and-Excitation）模块学习不同通道之间依赖关系来提高模型表现能力的是 SENet，而不是 DenseNet

4.昇腾NPU包含成千上万个计算核心，适合逻辑简单且计算密集型高并发任务，如下场景中哪些适合使用NPU? AD

1.  人脸识别模型训练
    
2.  普通办公应用
    
3.  数据库应用
    
4.  大语言模型推理
    

5.假设我们训练好的一个机器学习模型，它在训练集、验证集、测过集上的错误率分别为30%、30%、30%，产生这种现象的原因可能有哪些? AC

1.  训练数据太复杂
    
2.  训练数据量太大
    
3.  模型复杂度低，表达能力弱
    
4.  模型复杂度高，表达能力强
    

6.pytorch框架动态图训练性能调优时，对于算子计算性能存在劣化的情况，开发者可以自行尝试哪些优化手段?BCD（？）

1.  AOE调优
    
2.  消除AICPU算子
    
3.  尝试升级CANN包
    
4.  增大batchsize
    

7.常见的浮点数精度类型有哪些? ABCD

1.  单精度浮点数(float32)
    
2.  双精度浮点数(float64)
    
3.  半精度浮点数(float16)
    
4.  压缩浮点数(bfloat16)
    

8.在进行模型迁移前，需要保证选定的模型能在已有的AI硬件上正常运行，并输出哪些方面的测试基线? AC

1.  精度
    
2.  功耗
    
3.  性能
    
4.  内存占用率
    

9.通常导致存在AICPU算子的原因是哪些?ACD

1.  昇腾计算芯片AICORE不支持该算子
    
2.  输入数据的dtype导致，如float32
    
3.  输入数据的shape导致
    
4.  pytorch版本过低导致
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/dbbfb3a9-6b18-40ac-b788-c816dc6e1c1a.png)

[https://support.huaweicloud.com/bestpractice-modelarts/modelarts\_10\_2517.html](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_10_2517.html)

10.pytorch框架训练性能调优，基于Ascendinsight可视化Profiling数据后发现CPU侧dataloader任务耗时占比很高，可能的优化手段有哪些?ABCD（确定）

1.  排查数据所在磁盘是否存在I0瓶颈
    
2.  设置pin\_memory=True参数
    
3.  调整num workers参数
    
4.  检查数据格式，避免使用zip，tar.gz等数据格式，提解压数据
    

11.性能调优前，一般需要搜集哪些信息用于性能分析?ACD

1.  CANN版本信息
    
2.  Docker版本信息
    
3.  训练代码框架及版本信息
    
4.  模型信息及数据集相关信息
    

12.以下哪些选项属于精度偏差的来源?ABCD（确定）

1.  算子计算BUG
    
2.  算法迁移适配不当
    
3.  确定性计算未开启
    
4.  硬件差异，芯片架构差异
    

13.算子融合是一种常见的模型优化方法，将多个算子融合为一个算子，可以减少内存访问和计算的开销，如下选项中哪些是常见的算子融合操作?ABCDE

1.  conv +.relu
    
2.  conv + bn
    
3.  conv + bn + relu
    
4.  bias add + layer norm
    
5.  gemm + elementwise
    

14.模型推理业务昇腾迁移前的迁移评估，主要包含哪些工作?ABCD

1.  算子支持度评估
    
2.  框架支持度评估
    
3.  三方依赖库支持度评估
    
4.  业务改造评估
    
5.  性能基线分析
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/abe00486-1ae3-43fe-b570-550373c8cece.png)

15.目前在AI社区里，很多厂商都发布了开源LLM(large language model，大语言模型)，这些模型通常分为两种类别:base模型、chat模型，关于这两类模型的描述正确的有哪些? ABC

1.  base模型一般只经历了预训练阶段，使用海量无标签的文本数据进行了无监督学习
    
2.  base模型更适合文本补全等基础任务，具有更强的泛化能力
    
3.  chat模型在base模型基础上，又经历了有监督微调等阶段，更适合多轮对话任务
    
4.  如果需要应用到特定领域的下游任务，且拥有大量的有标签数据，更建议在chat模型上做微调
    

16.在Transformer架构提出之前，自然语言处理领域使用最多的是各种类型的循环神经网络(RNN)，如下关于RNN与Transformer的描述正确的有哪些?ABCD

1.  虽然有LSTM/GRU等改进形态，但RNN处理长距离依赖的能力仍然不够好
    
2.  Transformer架构可以直接计算序列中任意两个位置之间的关系，使得模型能够有效地捕获长距离依赖信息
    
3.  RNN是时序结构，当前时刻的输入依赖前一时刻的输出，不太适合做并行化
    
4.  Transformer架构可以高效地并行处理整个序列，推理时也可以并行化输出完整的句子
    

17.ModelArts支持训练模型过程中安装第三方依赖包，其中依赖包安装文件的命名支持以下哪几种格式? ABCD

1.  pip-requirement.txt
    
2.  pip-requirements.txt
    
3.  requirement.txt
    
4.  requirements.txt
    

[三方应用: https://support.huaweicloud.com/modelarts\_faq/modelarts\_05\_0063.html](https://support.huaweicloud.com/modelarts_faq/modelarts_05_0063.html)

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BKa2bKoODQ4/img/cab63710-0639-47d8-8565-260b700548a3.png)

18.使用ModelArts的开发环境，创建Notebook实例时需要选择一种AI引擎的镜像，可以选择的镜像类型包括如下哪几项?ABCD

1.  预置在ModelArts内部的公共镜像
    
2.  Al Gallery社区发布的镜像
    
3.  基于公共镜像创建的实例保存下来的自定义镜像
    
4.  在ECS(Elastic Cloud Server)上构建的自定义镜像
    

19.ModelArts支持用户将自己在其他环境开发好的模型迁移到平台上进行部署，在创建A!应用时，如下哪些文件必选包含在模型包中?ABD

1.  模型文件，如PyTorch框架的pt文件
    
2.  模型配置文件，固定为config.json
    
3.  三方依赖包安装文件，如requirements.txt
    
4.  模型推理代码文件，固定为customize service.py
    

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/1GXn4BK2E9pkODQ4/img/2f50e620-adc7-4ec3-a31d-7e27ce76610a.png)

20.pytorch框架训练性能调优，获取到训练的profiling数据后，应该从以下哪些维度展开分析?ABCD

1.  cpu侧任务下发
    
2.  通信
    
3.  计算
    
4.  数据加载
    

原因：

**CPU侧任务下发**：查看 CPU 任务调度的效率，是否存在过多的等待时间或不必要的任务切换。

**通信**：检查数据交换的时间消耗，尤其是分布式训练时的通信延迟，以及是否有效地利用了可用带宽。

**计算**：分析 GPU 或其他计算设备的利用率，检查是否存在计算资源的空闲时间，以及计算任务的执行效率。

**数据加载**：检查数据加载和预处理的效率，包括数据读取时间、数据预处理时间以及是否有效地利用了多线程或多进程技术。

21.算子融合是一种常见的模型优化方法，将多个算子融合为一个算子，可以减少内存访问和计算的开销，如下选项中哪些是常见的算子融合操作?ABCDE

1.  cony + relu
    
2.  conv + bn
    
3.  conv + bn + relu
    
4.  bias add + layer norm
    
5.  gemm + elementwise
    

22.精度对比工具ptdbg支持以下哪些API dump模式?

1.  dump全量的API及堆栈信息
    
2.  dump指定列表中的API和堆栈信息
    
3.  dump指定某一类的API和堆栈信息
    
4.  只dump堆栈信息，不dump API的数据
    

23.GPU环境下确定性计算打开的方式是什么?AC（？）

1.  torch.use\_deterministic algorithms(True)
    
2.  export HCCL DETERMINISTIC=TRUE
    
3.  export NCCL DETERMINISTIC=TRUE
    
4.  expOrt INF\_NAN MODE ENABLE=1
    

24.进行模型迁移之前，需要做以下哪些工作? ABC

1.  选取合适的模型，在三方平台运行成功
    
2.  在昇腾设备上搭建环境
    
3.  使用迁移分析工具分析模型在昇腾设备上的支持度
    
4.  在昇腾设备上运行下游任务评测
    

25.pytorch框架动态图训练性能调优时，对于算子计算性能存在劣化的情况，开发者可以自行尝试哪些优化手段?BCD（？）

1.  AOE调优
    
2.  消除AICPU算子
    
3.  尝试升级CANN包
    
4.  增大batchsize
    

26.在无标杆性能数据的情况下，可考虑什么方式进行性能调优?

1.  使用权威网站的性能数据作为目标
    
2.  替换NPU亲和api算子
    
3.  尝试使用apex优化库
    
4.  定位ai cpu算子并尝试使能ai core
    

27.以下哪些现象代表大模型可能存在精度问题?ABC

1.  训练Loss上扬不收敛
    
2.  训练Loss值出现INF/NAN等异常值
    
3.  推理结果不正确
    
4.  推理响应速度很慢
    

28.在迁移可行性分析中如果存在平台未支持的算子，可通过下面哪些方式解决?  ACD（？）

1.  修改模型脚本，使用等价支持的算子替换
    
2.  将CANN版本降低
    
3.  联系华为工程师提出开发适配诉求
    
4.  参考文档进行算子适配
    

29.在模型推理性能优化分析中，性能瓶颈主要来自如下哪几项?AE??

1.  Host算子下发
    
2.  Host算子执行
    
3.  Host算子编译
    
4.  Device算子下发
    
5.  Device算子执行
    
6.  Device算子编译